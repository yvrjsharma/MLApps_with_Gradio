{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yvrjsharma/MLApps_with_Gradio/blob/main/Langchain_Gradio_Bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHuqwhw8SQ8u"
      },
      "outputs": [],
      "source": [
        "! pip install --q langchain==0.0.55 requests openai transformers faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install --q gradio"
      ],
      "metadata": {
        "id": "ljxY6xJ_BYSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oy_kniRPb3E"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
        "from langchain.docstore.document import Document\n",
        "import requests\n",
        "import gradio as gr \n",
        "\n",
        "import pathlib\n",
        "import subprocess\n",
        "import tempfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcjdgwO6V9ge"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"xx\"\n",
        "#os.environ[\"SERPAPI_API_KEY\"] = \"xx\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHC8AqGBgAz1"
      },
      "outputs": [],
      "source": [
        "# using a vector space for our search\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores.faiss import FAISS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXVK-UF9aV_Y"
      },
      "outputs": [],
      "source": [
        "#using this\n",
        "chain = load_qa_with_sources_chain(OpenAI(temperature=0))\n",
        "#chain = load_qa_with_sources_chain(OpenAI(temperature=0), chain_type=\"map_reduce\")\n",
        "\n",
        "def print_answer(question):\n",
        "    print(\n",
        "        chain(\n",
        "            {\n",
        "                \"input_documents\": search_index.similarity_search(question, k=4),\n",
        "                \"question\": question,\n",
        "            },\n",
        "            return_only_outputs=True,\n",
        "        )[\"output_text\"]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AANWL-S-mZYp"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "source_chunks = []\n",
        "splitter = CharacterTextSplitter(separator=\" \", chunk_size=1024, chunk_overlap=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npE1phC5l9vj"
      },
      "outputs": [],
      "source": [
        "#not atm\n",
        "for source in sources:\n",
        "    for chunk in splitter.split_text(source.page_content):\n",
        "        source_chunks.append(Document(page_content=chunk, metadata=source.metadata))\n",
        "\n",
        "search_index = FAISS.from_documents(source_chunks, OpenAIEmbeddings())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pypSBpePtst"
      },
      "outputs": [],
      "source": [
        "# https://github.com/gradio-app/gradio\n",
        "repo_owner, repo_name = 'gradio-app', 'gradio'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqZcp9aNJUHS"
      },
      "outputs": [],
      "source": [
        "#new github md func\n",
        "def get_github_docs(repo_owner, repo_name):\n",
        "    with tempfile.TemporaryDirectory() as d:\n",
        "        subprocess.check_call(\n",
        "            f\"git clone https://github.com/{repo_owner}/{repo_name}.git .\",\n",
        "            cwd=d,\n",
        "            shell=True,\n",
        "        )\n",
        "        git_sha = (\n",
        "            subprocess.check_output(\"git rev-parse HEAD\", shell=True, cwd=d)\n",
        "            .decode(\"utf-8\")\n",
        "            .strip()\n",
        "        )\n",
        "        repo_path = pathlib.Path(d)\n",
        "        markdown_files = list(repo_path.rglob(\"*.md\")) + list(\n",
        "            repo_path.rglob(\"*.mdx\")\n",
        "        )\n",
        "        for markdown_file in markdown_files:\n",
        "            try:\n",
        "                with open(markdown_file, \"r\") as f:\n",
        "                    relative_path = markdown_file.relative_to(repo_path)\n",
        "                    github_url = f\"https://github.com/{repo_owner}/{repo_name}/blob/{git_sha}/{relative_path}\"\n",
        "                    yield Document(page_content=f.read(), metadata={\"source\": github_url})\n",
        "            except FileNotFoundError:\n",
        "                print(f\"Could not open file: {markdown_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mxw5f_47QLc7"
      },
      "outputs": [],
      "source": [
        "sources = get_github_docs(\"gradio-app\", \"gradio\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-Ih6kwKcacy",
        "outputId": "083c3002-d9c0-406f-8e26-6f861d821ef4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<generator object get_github_docs at 0x7f9fa5700350>"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtelrzXIJhtI"
      },
      "outputs": [],
      "source": [
        "#not now\n",
        "for source in sources:\n",
        "  print(\"*****\")\n",
        "  print(source.page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9JUeh0brfpU"
      },
      "outputs": [],
      "source": [
        "#source_chunks = []\n",
        "#splitter = CharacterTextSplitter(separator=\" \", chunk_size=1024, chunk_overlap=0)\n",
        "for source in sources:\n",
        "    for chunk in splitter.split_text(source.page_content):\n",
        "        source_chunks.append(Document(page_content=chunk, metadata=source.metadata))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZNxzOGhKe_N"
      },
      "outputs": [],
      "source": [
        "search_index = FAISS.from_documents(source_chunks, OpenAIEmbeddings())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubl8ILwYKpeZ",
        "outputId": "4fb06c7f-243f-408e-f66f-3d1e4a7b05d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='<!-- DO NOT EDIT THIS FILE DIRECTLY. INSTEAD EDIT THE `readme_template.md` OR `guides/1)getting_started/1)quickstart.md` TEMPLATES AND THEN RUN `render_readme.py` SCRIPT. -->\\n\\n<div align=\"center\">\\n\\n  [<img src=\"readme_files/gradio.svg\" alt=\"gradio\" width=300>](https://gradio.app)<br>\\n  <em>Build & share delightful machine learning apps easily</em>\\n\\n  [![gradio-backend](https://github.com/gradio-app/gradio/actions/workflows/backend.yml/badge.svg)](https://github.com/gradio-app/gradio/actions/workflows/backend.yml)\\n  [![gradio-ui](https://github.com/gradio-app/gradio/actions/workflows/ui.yml/badge.svg)](https://github.com/gradio-app/gradio/actions/workflows/ui.yml)  \\n  [<img src=\"https://codecov.io/gh/gradio-app/gradio/branch/master/graph/badge.svg\" alt=\"codecov\">](https://app.codecov.io/gh/gradio-app/gradio)\\n  [![PyPI](https://img.shields.io/pypi/v/gradio)](https://pypi.org/project/gradio/)\\n  [![PyPI downloads](https://img.shields.io/pypi/dm/gradio)](https://pypi.org/project/gradio/)\\n  ![Python version](https://img.shields.io/badge/python-3.7+-important)\\n ', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/README.md'}, lookup_index=0),\n",
              " Document(page_content=' [![Twitter follow](https://img.shields.io/twitter/follow/gradio?style=social&label=follow)](https://twitter.com/gradio)\\n\\n  [Website](https://gradio.app)\\n  | [Documentation](https://gradio.app/docs/)\\n  | [Guides](https://gradio.app/guides/)\\n  | [Getting Started](https://gradio.app/getting_started/)\\n  | [Examples](demo/)\\n</div>\\n\\n# Gradio: Build Machine Learning Web Apps — in Python\\n\\nGradio is an open-source Python library that is used to build machine learning and data science demos and web applications.\\n\\nWith Gradio, you can quickly create a beautiful user interface around your machine learning models or data science workflow and let people \"try it out\" by dragging-and-dropping in their own images,\\npasting text, recording their own voice, and interacting with your demo, all through the browser.\\n\\n![Interface montage](readme_files/header-image.jpg)\\n\\nGradio is useful for:\\n\\n- **Demoing** your machine learning models for clients/collaborators/users/students.\\n\\n- **Deploying** your models quickly with automatic shareable links and getting feedback on model performance.\\n\\n- **Debugging** your model interactively during development', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/README.md'}, lookup_index=0),\n",
              " Document(page_content='using built-in manipulation and interpretation tools.\\n\\n## Quickstart\\n\\n**Prerequisite**: Gradio requires Python 3.7 or higher, that\\'s all!\\n\\n### What Does Gradio Do?\\n\\nOne of the *best ways to share* your machine learning model, API, or data science workflow with others is to create an **interactive app** that allows your users or colleagues to try out the demo in their browsers.\\n\\nGradio allows you to **build demos and share them, all in Python.** And usually in just a few lines of code! So let\\'s get started.\\n\\n### Hello, World\\n\\nTo get Gradio running with a simple \"Hello, World\" example, follow these three steps:\\n\\n1\\\\. Install Gradio using pip:\\n\\n```bash\\npip install gradio\\n```\\n\\n2\\\\. Run the code below as a Python script or in a Jupyter Notebook (or [Google Colab](https://colab.research.google.com/drive/18ODkJvyxHutTN0P5APWyGFO_xwNcgHDZ?usp=sharing)):\\n\\n```python\\nimport gradio as gr\\n\\ndef greet(name):\\n    return \"Hello \" + name + \"!\"\\n\\ndemo = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\\ndemo.launch()\\n```\\n\\n\\n3\\\\. The demo below will appear automatically within the Jupyter Notebook, or pop in a browser on [http://localhost:7860](http://localhost:7860) if running', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/README.md'}, lookup_index=0),\n",
              " Document(page_content='from a script:\\n\\n![`hello_world` demo](demo/hello_world/screenshot.gif)\\n\\n### The `Interface` Class\\n\\nYou\\'ll notice that in order to make the demo, we created a `gradio.Interface`. This `Interface` class can wrap any Python function with a user interface. In the example above, we saw a simple text-based function, but the function could be anything from music generator to a tax calculator to the prediction function of a pretrained machine learning model.\\n\\nThe core `Interface` class is initialized with three required parameters:\\n\\n- `fn`: the function to wrap a UI around\\n- `inputs`: which component(s) to use for the input (e.g. `\"text\"`, `\"image\"` or `\"audio\"`)\\n- `outputs`: which component(s) to use for the output (e.g. `\"text\"`, `\"image\"` or `\"label\"`)\\n\\nLet\\'s take a closer look at these components used to provide input and output.\\n\\n### Components Attributes\\n\\nWe saw some simple `Textbox` components in the previous examples, but what if you want to change how the UI components look or behave?\\n\\nLet\\'s say you want to customize the input text field — for example, you wanted it to be larger and have a text placeholder. If we use the actual class for `Textbox` instead of using the string shortcut,', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/README.md'}, lookup_index=0),\n",
              " Document(page_content='you have access to much more customizability through component attributes.\\n\\n```python\\nimport gradio as gr\\n\\ndef greet(name):\\n    return \"Hello \" + name + \"!\"\\n\\ndemo = gr.Interface(\\n    fn=greet,\\n    inputs=gr.Textbox(lines=2, placeholder=\"Name Here...\"),\\n    outputs=\"text\",\\n)\\ndemo.launch()\\n```\\n\\n![`hello_world_2` demo](demo/hello_world_2/screenshot.gif)\\n\\n### Multiple Input and Output Components\\n\\nSuppose you had a more complex function, with multiple inputs and outputs. In the example below, we define a function that takes a string, boolean, and number, and returns a string and number. Take a look how you pass a list of input and output components.\\n\\n```python\\nimport gradio as gr\\n\\ndef greet(name, is_morning, temperature):\\n    salutation = \"Good morning\" if is_morning else \"Good evening\"\\n    greeting = f\"{salutation} {name}. It is {temperature} degrees today\"\\n    celsius = (temperature - 32) * 5 / 9\\n    return greeting, round(celsius, 2)\\n\\ndemo = gr.Interface(\\n    fn=greet,\\n    inputs=[\"text\", \"checkbox\", gr.Slider(0, 100)],\\n    outputs=[\"text\", \"number\"],\\n)\\ndemo.launch()\\n```\\n\\n![`hello_world_3` demo](demo/hello_world_3/screenshot.gif)\\n\\nYou simply wrap the components in a list.', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/README.md'}, lookup_index=0),\n",
              " Document(page_content='Each component in the `inputs` list corresponds to one of the parameters of the function, in order. Each component in the `outputs` list corresponds to one of the values returned by the function, again in order.\\n\\n### An Image Example\\n\\nGradio supports many types of components, such as `Image`, `DataFrame`, `Video`, or `Label`. Let\\'s try an image-to-image function to get a feel for these!\\n\\n```python\\nimport numpy as np\\nimport gradio as gr\\n\\ndef sepia(input_img):\\n    sepia_filter = np.array([\\n        [0.393, 0.769, 0.189], \\n        [0.349, 0.686, 0.168], \\n        [0.272, 0.534, 0.131]\\n    ])\\n    sepia_img = input_img.dot(sepia_filter.T)\\n    sepia_img /= sepia_img.max()\\n    return sepia_img\\n\\ndemo = gr.Interface(sepia, gr.Image(shape=(200, 200)), \"image\")\\ndemo.launch()\\n```\\n\\n![`sepia_filter` demo](demo/sepia_filter/screenshot.gif)\\n\\nWhen using the `Image` component as input, your function will receive a NumPy array with the shape `(width, height, 3)`, where the last dimension represents the RGB values. We\\'ll return an image as well in the form of a NumPy array.\\n\\nYou can also set the datatype used by the component with the `type=` keyword argument. For example, if you wanted your function to take a file path to an', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/README.md'}, lookup_index=0),\n",
              " Document(page_content='image instead of a NumPy array, the input `Image` component could be written as:\\n\\n```python\\ngr.Image(type=\"filepath\", shape=...)\\n```\\n\\nAlso note that our input `Image` component comes with an edit button 🖉, which allows for cropping and zooming into images. Manipulating images in this way can help reveal biases or hidden flaws in a machine learning model!\\n\\nYou can read more about the many components and how to use them in the [Gradio docs](https://gradio.app/docs).\\n\\n### Blocks: More Flexibility and Control\\n\\nGradio offers two classes to build apps:\\n\\n1\\\\. **Interface**, that provides a high-level abstraction for creating demos that we\\'ve been discussing so far.\\n\\n2\\\\. **Blocks**, a low-level API for designing web apps with more flexible layouts and data flows. Blocks allows you to do things like feature multiple data flows and demos, control where components appear on the page, handle complex data flows (e.g. outputs can serve as inputs to other functions), and update properties/visibility of components based on user interaction — still all in Python. If this customizability is what you need, try `Blocks` instead!\\n\\n### Hello, Blocks\\n\\nLet\\'s take a look at a simple example. Note how the API', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/README.md'}, lookup_index=0),\n",
              " Document(page_content='here differs from `Interface`.\\n\\n```python\\nimport gradio as gr\\n\\ndef greet(name):\\n    return \"Hello \" + name + \"!\"\\n\\nwith gr.Blocks() as demo:\\n    name = gr.Textbox(label=\"Name\")\\n    output = gr.Textbox(label=\"Output Box\")\\n    greet_btn = gr.Button(\"Greet\")\\n    greet_btn.click(fn=greet, inputs=name, outputs=output)\\n\\ndemo.launch()\\n```\\n\\n![`hello_blocks` demo](demo/hello_blocks/screenshot.gif)\\n\\nThings to note:\\n\\n- `Blocks` are made with a `with` clause, and any component created inside this clause is automatically added to the app.\\n- Components appear vertically in the app in the order they are created. (Later we will cover customizing layouts!)\\n- A `Button` was created, and then a `click` event-listener was added to this button. The API for this should look familiar! Like an `Interface`, the `click` method takes a Python function, input components, and output components.\\n\\n### More Complexity\\n\\nHere\\'s an app to give you a taste of what\\'s possible with `Blocks`:\\n\\n```python\\nimport numpy as np\\nimport gradio as gr\\n\\ndef flip_text(x):\\n    return x[::-1]\\n\\ndef flip_image(x):\\n    return np.fliplr(x)\\n\\nwith gr.Blocks() as demo:\\n    gr.Markdown(\"Flip text or image files using this demo.\")\\n   ', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/README.md'}, lookup_index=0),\n",
              " Document(page_content='   with gr.Tabs():\\n        with gr.TabItem(\"Flip Text\"):\\n            text_input = gr.Textbox()\\n            text_output = gr.Textbox()\\n            text_button = gr.Button(\"Flip\")\\n        with gr.TabItem(\"Flip Image\"):\\n            with gr.Row():\\n                image_input = gr.Image()\\n                image_output = gr.Image()\\n            image_button = gr.Button(\"Flip\")\\n    \\n    text_button.click(flip_text, inputs=text_input, outputs=text_output)\\n    image_button.click(flip_image, inputs=image_input, outputs=image_output)\\n    \\ndemo.launch()\\n```\\n\\n![`blocks_flipper` demo](demo/blocks_flipper/screenshot.gif)\\n\\nA lot more going on here! We\\'ll cover how to create complex `Blocks` apps like this in the [building with blocks](https://github.com/gradio-app/gradio/tree/main/guides/3\\\\)building_with_blocks) section for you.\\n\\nCongrats, you\\'re now familiar with the basics of Gradio! 🥳 Go to our [next guide](https://gradio.app/key_features) to learn more about the key features of Gradio.\\n\\n\\n## Open Source Stack\\n\\nGradio is built with many wonderful open-source libraries, please support them as well!\\n\\n[<img src=\"readme_files/huggingface_mini.svg\" alt=\"huggingface\" height=40>](https://huggingface.co)\\n[<img src=\"readme_files/python.svg\"', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/README.md'}, lookup_index=0),\n",
              " Document(page_content='alt=\"python\" height=40>](https://www.python.org)\\n[<img src=\"readme_files/fastapi.svg\" alt=\"fastapi\" height=40>](https://fastapi.tiangolo.com)\\n[<img src=\"readme_files/encode.svg\" alt=\"encode\" height=40>](https://www.encode.io)\\n[<img src=\"readme_files/svelte.svg\" alt=\"svelte\" height=40>](https://svelte.dev)\\n[<img src=\"readme_files/vite.svg\" alt=\"vite\" height=40>](https://vitejs.dev)\\n[<img src=\"readme_files/pnpm.svg\" alt=\"pnpm\" height=40>](https://pnpm.io)\\n[<img src=\"readme_files/tailwind.svg\" alt=\"tailwind\" height=40>](https://tailwindcss.com)\\n\\n## License\\n\\nGradio is licensed under the Apache License 2.0 found in the [LICENSE](LICENSE) file in the root directory of this repository.\\n\\n## Citation\\n\\nAlso check out the paper *[Gradio: Hassle-Free Sharing and Testing of ML Models in the Wild](https://arxiv.org/abs/1906.02569), ICML HILL 2019*, and please cite it if you use Gradio in your work.\\n\\n```\\n@article{abid2019gradio,\\n  title = {Gradio: Hassle-Free Sharing and Testing of ML Models in the Wild},\\n  author = {Abid, Abubakar and Abdalla, Ali and Abid, Ali and Khan, Dawood and Alfozan, Abdulrahman and Zou, James},\\n ', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/README.md'}, lookup_index=0),\n",
              " Document(page_content=' journal = {arXiv preprint arXiv:1906.02569},\\n  year = {2019},\\n}\\n```\\n\\n## See Also\\n\\n* The [Gradio Discord Bot](https://github.com/gradio-app/gradio-discord-bot), a Discord bot that allows you to try any [Hugging Face Space](https://huggingface.co/spaces) that is running a Gradio demo as a Discord bot.\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/README.md'}, lookup_index=0),\n",
              " Document(page_content='# component-styles\\n\\n## Textbox\\n\\n| name        | type                                 | description                    |\\n| ----------- | ------------------------------------ | ------------------------------ |\\n| `rounded`   | `bool` or `(bool, bool, bool, bool)` | corners of text input          |\\n| `border`    | `bool` or `(bool, bool, bool, bool)` | borders of text input          |\\n| `container` | `bool`                               | show or hide the container box |\\n\\n## Number\\n\\n| name        | type                                 | description                    |\\n| ----------- | ------------------------------------ | ------------------------------ |\\n| `rounded`   | `bool` or `(bool, bool, bool, bool)` | corners of text input          |\\n| `border`    | `bool` or `(bool, bool, bool, bool)` | borders of text input          |\\n| `container` | `bool`                               | show or hide the container box |\\n\\n## Slider\\n\\n| name        | type   | description                    |\\n| ----------- | ------ | ------------------------------ |\\n| `container` | `bool` | show or hide the container box |\\n\\n## Checkbox\\n\\n| name        | type                                 | description                    |\\n| ----------- | ------------------------------------ | ------------------------------ |\\n| `rounded`   | `bool` or `(bool, bool, bool, bool)` | corners of checkbox            |\\n| `border`    | `bool` or `(bool, bool, bool, bool)` | borders of checkbox            |\\n| `container` | `bool`                               | show or hide the container box |\\n\\n##', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/style.md'}, lookup_index=0),\n",
              " Document(page_content='Checkbox Group\\n\\n| name             | type                                 | description                               |\\n| ---------------- | ------------------------------------ | ----------------------------------------- |\\n| `rounded`        | `bool` or `(bool, bool, bool, bool)` | corners of checkboxes                     |\\n| `container`      | `bool`                               | show or hide the container box            |\\n| `item_container` | `bool`                               | show or hide the checkbox container boxes |\\n\\n## Radio\\n\\n| name             | type   | description                            |\\n| ---------------- | ------ | -------------------------------------- |\\n| `container`      | `bool` | show or hide the container box         |\\n| `item_container` | `bool` | show or hide the radio container boxes |\\n\\n## Dropdown\\n\\n| name        | type                                 | description                    |\\n| ----------- | ------------------------------------ | ------------------------------ |\\n| `rounded`   | `bool` or `(bool, bool, bool, bool)` | corners of input               |\\n| `border`    | `bool` or `(bool, bool, bool, bool)` | borders of input               |\\n| `container` | `bool`                               | show or hide the container box |\\n\\n## Image\\n\\n| name      | type                                 | description         |\\n| --------- | ------------------------------------ | ------------------- |\\n| `rounded` | `bool` or `(bool, bool, bool, bool)` | corners of main box |\\n\\n## Video\\n\\n| name      | type                                 | description         |\\n| --------- |', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/style.md'}, lookup_index=0),\n",
              " Document(page_content='------------------------------------ | ------------------- |\\n| `rounded` | `bool` or `(bool, bool, bool, bool)` | corners of main box |\\n\\n## Audio\\n\\n| name      | type                                 | description         |\\n| --------- | ------------------------------------ | ------------------- |\\n| `rounded` | `bool` or `(bool, bool, bool, bool)` | corners of main box |\\n\\n## File\\n\\n| name      | type                                 | description         |\\n| --------- | ------------------------------------ | ------------------- |\\n| `rounded` | `bool` or `(bool, bool, bool, bool)` | corners of main box |\\n\\n## Dataframe\\n\\n| name      | type                                 | description         |\\n| --------- | ------------------------------------ | ------------------- |\\n| `rounded` | `bool` or `(bool, bool, bool, bool)` | corners of main box |\\n\\n## Timeseries\\n\\n| name      | type                                 | description         |\\n| --------- | ------------------------------------ | ------------------- |\\n| `rounded` | `bool` or `(bool, bool, bool, bool)` | corners of main box |\\n\\n## Label\\n\\n| name        | type   | description                    |\\n| ----------- | ------ | ------------------------------ |\\n| `container` | `bool` | show or hide the container box |\\n\\n## HighlightedText\\n\\n| name        | type                                 | description                    |\\n| ----------- | ------------------------------------ |', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/style.md'}, lookup_index=0),\n",
              " Document(page_content='------------------------------ |\\n| `rounded`   | `bool` or `(bool, bool, bool, bool)` | corners of labels              |\\n| `color_map` | `Dict[str, str]`                     | color map of labels and colors |\\n| `container` | `bool`                               | show or hide the container box |\\n\\n## JSON\\n\\n| name        | type   | description                    |\\n| ----------- | ------ | ------------------------------ |\\n| `container` | `bool` | show or hide the container box |\\n\\n## HTML\\n\\nNothing\\n\\n## Gallery\\n\\n| name        | type                                      | description                         |\\n| ----------- | ----------------------------------------- | ----------------------------------- |\\n| `rounded`   | `bool` or `(bool, bool, bool, bool)`      | corners of images                   |\\n| `grid`      | `int` or `(int, int, int, int, int, int)` | grid for images                     |\\n| `height`    | `\"auto\"`                                  | height of gallery (auto or default) |\\n| `container` | `bool`                                    | show or hide the container box      |\\n\\n## Chatbot\\n\\n| name        | type                                 | description                                      |\\n| ----------- | ------------------------------------ | ------------------------------------------------ |\\n| `rounded`   | `bool` or `(bool, bool, bool, bool)` | corners of chat bubbles                          |\\n| `color_map` | `Dict[str, str]`                     | color map of user and bot color for chat bubbles |\\n\\n## Model3D\\n\\n| name      | type                                 | description         |\\n| --------- |', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/style.md'}, lookup_index=0),\n",
              " Document(page_content='------------------------------------ | ------------------- |\\n| `rounded` | `bool` or `(bool, bool, bool, bool)` | corners of main box |\\n\\n## Plot\\n\\nNothing (yet)\\n\\n## Markdown\\n\\nNothing\\n\\n## Button\\n\\n| name         | type                                 | description                             |\\n| ------------ | ------------------------------------ | --------------------------------------- |\\n| `rounded`    | `bool` or `(bool, bool, bool, bool)` | corners of button                       |\\n| `border`     | `bool` or `(bool, bool, bool, bool)` | borders of button                       |\\n| `full_width` | `bool`                               | whether button expand to fill container |\\n\\n## Dataset\\n\\nNothing\\n\\n## Variable\\n\\nNothing\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/style.md'}, lookup_index=0),\n",
              " Document(page_content='<div align=\"center\">\\n\\n  [<img src=\"readme_files/gradio.svg\" alt=\"gradio\" width=300>](https://gradio.app)<br>\\n  <em>Build & share delightful machine learning apps easily</em>\\n\\n  [<img src=\"https://circleci.com/gh/gradio-app/gradio.svg?style=svg\" alt=\"circleci\">](https://circleci.com/gh/gradio-app/gradio)\\n  [<img src=\"https://codecov.io/gh/gradio-app/gradio/branch/master/graph/badge.svg\" alt=\"codecov\">](https://app.codecov.io/gh/gradio-app/gradio)\\n  [![PyPI](https://img.shields.io/pypi/v/gradio)](https://pypi.org/project/gradio/)\\n  [![PyPI downloads](https://img.shields.io/pypi/dm/gradio)](https://pypi.org/project/gradio/)\\n  ![Python version](https://img.shields.io/badge/python-3.7+-important)\\n  [![Twitter follow](https://img.shields.io/twitter/follow/gradio?style=social&label=follow)](https://twitter.com/gradio)\\n\\n  [Website](https://gradio.app)\\n  | [Documentation](https://gradio.app/docs/)\\n  | [Guides](https://gradio.app/guides/)\\n  | [Getting Started](https://gradio.app/getting_started/)\\n  | [Examples](demo/)\\n</div>\\n\\n# Gradio: Build Machine Learning Web Apps — in', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/readme_template.md'}, lookup_index=0),\n",
              " Document(page_content='Python\\n\\nGradio is an open-source Python library that is used to build machine learning and data science demos and web applications.\\n\\nWith Gradio, you can quickly create a beautiful user interface around your machine learning models or data science workflow and let people \"try it out\" by dragging-and-dropping in their own images,\\npasting text, recording their own voice, and interacting with your demo, all through the browser.\\n\\n![Interface montage](readme_files/header-image.jpg)\\n\\nGradio is useful for:\\n\\n- **Demoing** your machine learning models for clients/collaborators/users/students.\\n\\n- **Deploying** your models quickly with automatic shareable links and getting feedback on model performance.\\n\\n- **Debugging** your model interactively during development using built-in manipulation and interpretation tools.\\n\\n$getting_started\\n\\n## Open Source Stack\\n\\nGradio is built with many wonderful open-source libraries, please support them as well!\\n\\n[<img src=\"readme_files/huggingface_mini.svg\" alt=\"huggingface\" height=40>](https://huggingface.co)\\n[<img src=\"readme_files/python.svg\" alt=\"python\" height=40>](https://www.python.org)\\n[<img', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/readme_template.md'}, lookup_index=0),\n",
              " Document(page_content='src=\"readme_files/fastapi.svg\" alt=\"fastapi\" height=40>](https://fastapi.tiangolo.com)\\n[<img src=\"readme_files/encode.svg\" alt=\"encode\" height=40>](https://www.encode.io)\\n[<img src=\"readme_files/svelte.svg\" alt=\"svelte\" height=40>](https://svelte.dev)\\n[<img src=\"readme_files/vite.svg\" alt=\"vite\" height=40>](https://vitejs.dev)\\n[<img src=\"readme_files/pnpm.svg\" alt=\"pnpm\" height=40>](https://pnpm.io)\\n[<img src=\"readme_files/tailwind.svg\" alt=\"tailwind\" height=40>](https://tailwindcss.com)\\n\\n## License\\n\\nGradio is licensed under the Apache License 2.0 found in the [LICENSE](LICENSE) file in the root directory of this repository.\\n\\n## Citation\\n\\nAlso check out the paper *[Gradio: Hassle-Free Sharing and Testing of ML Models in the Wild](https://arxiv.org/abs/1906.02569), ICML HILL 2019*, and please cite it if you use Gradio in your work.\\n\\n```\\n@article{abid2019gradio,\\n  title = {Gradio: Hassle-Free Sharing and Testing of ML Models in the Wild},\\n  author = {Abid, Abubakar and Abdalla, Ali and Abid, Ali and Khan, Dawood and Alfozan, Abdulrahman and Zou, James},\\n  journal = {arXiv preprint arXiv:1906.02569},\\n  year =', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/readme_template.md'}, lookup_index=0),\n",
              " Document(page_content='{2019},\\n}\\n```\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/readme_template.md'}, lookup_index=0),\n",
              " Document(page_content='# Upcoming Release\\n\\n## New Features:\\nNo changes to highlight.\\n\\n## Bug Fixes:\\n- Fixes URL resolution on Windows by [@abidlabs](https://github.com/abidlabs) in [PR 3108](https://github.com/gradio-app/gradio/pull/3108) \\n\\n## Documentation Changes:\\n- Added a guide on the 4 kinds of Gradio Interfaces by [@yvrjsharma](https://github.com/yvrjsharma) and [@abidlabs](https://github.com/abidlabs) in [PR 3003](https://github.com/gradio-app/gradio/pull/3003) \\n\\n## Testing and Infrastructure Changes:\\nNo changes to highlight.\\n\\n## Breaking Changes:\\nNo changes to highlight.\\n\\n## Full Changelog:\\nNo changes to highlight.\\n\\n\\n## Contributors Shoutout:\\nNo changes to highlight.\\n\\n\\n# Version 3.17.1\\n\\n## New Features:\\n\\n### iOS image rotation fixed 🔄\\n\\nPreviously photos uploaded via iOS would be rotated after processing. This has been fixed by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 3089](https://github.com/gradio-app/gradio/pull/3091)\\n\\n#### Before\\n![image](https://user-images.githubusercontent.com/41651716/215846507-a36e9d05-1ac2-4867-8ab3-ce045a9415d9.png)\\n\\n####', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='After\\n![image](https://user-images.githubusercontent.com/41651716/215846554-e41773ed-70f0-491a-9952-6a18babf91ef.png)\\n\\n### Run on Kaggle kernels 🧪\\n\\nA share link will automatically be created when running on Kaggle kernels (notebooks) so that the front-end is properly displayed.\\n\\n![image](https://user-images.githubusercontent.com/41651716/216104254-2cf55599-449c-436c-b57e-40f6a83f9eee.png)\\n\\nBy [@freddyaboulton](https://github.com/freddyaboulton) in [PR 3101](https://github.com/gradio-app/gradio/pull/3101)\\n\\n## Bug Fixes:\\n- Fix bug where examples were not rendered correctly for demos created with Blocks api that had multiple input compinents by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 3090](https://github.com/gradio-app/gradio/pull/3090)\\n- Fix change event listener for JSON, HighlightedText, Chatbot by [@aliabid94](https://github.com/aliabid94) in [PR 3095](https://github.com/gradio-app/gradio/pull/3095)\\n- Fixes bug where video and file change event not working [@tomchang25](https://github.com/tomchang25) in [PR 3098](https://github.com/gradio-app/gradio/pull/3098)\\n- Fixes', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='bug where static_video play and pause event not working [@tomchang25](https://github.com/tomchang25) in [PR 3098](https://github.com/gradio-app/gradio/pull/3098)\\n- Fixed `Gallery.style(grid=...)` by by [@aliabd](https://github.com/aliabd) in [PR 3107](https://github.com/gradio-app/gradio/pull/3107)\\n\\n## Documentation Changes:\\n- Fix a broken link in the Quick Start guide, by [@cakiki](https://github.com/cakiki) in [PR 3109](https://github.com/gradio-app/gradio/pull/3109)\\n- Add a guide on using Gradio with [Comet](https://comet.com/), by [@DN6](https://github.com/DN6/) in [PR 3058](https://github.com/gradio-app/gradio/pull/3058)\\n\\n## Testing and Infrastructure Changes:\\nNo changes to highlight.\\n\\n## Breaking Changes:\\nNo changes to highlight.\\n\\n## Full Changelog:\\n* Set minimum `markdown-it-py` version to `2.0.0` so that the dollar math plugin is compatible by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 3102](https://github.com/gradio-app/gradio/pull/3102)\\n\\n## Contributors Shoutout:\\nNo changes to highlight.\\n\\n# Version 3.17.0\\n\\n## New Features:\\n\\n### Extended support for Interface.load! 🏗️\\n\\nYou can', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='now load `image-to-text` and `conversational` pipelines from the hub!\\n\\n### Image-to-text Demo\\n```python\\nio = gr.Interface.load(\"models/nlpconnect/vit-gpt2-image-captioning\",\\n                       api_key=\"<optional-api-key>\")\\nio.launch()\\n```\\n<img width=\"1087\" alt=\"image\" src=\"https://user-images.githubusercontent.com/41651716/213260197-dc5d80b4-6e50-4b3a-a764-94980930ac38.png\">\\n\\n### conversational Demo\\n```python\\nchatbot = gr.Interface.load(\"models/microsoft/DialoGPT-medium\",\\n                           api_key=\"<optional-api-key>\")\\nchatbot.launch()\\n```\\n![chatbot_load](https://user-images.githubusercontent.com/41651716/213260220-3eaa25b7-a38b-48c6-adeb-2718bdf297a2.gif)\\n\\n\\nBy [@freddyaboulton](https://github.com/freddyaboulton) in [PR 3011](https://github.com/gradio-app/gradio/pull/3011)\\n\\n### Download Button added to Model3D Output Component 📥\\n\\nNo need for an additional file output component to enable model3d file downloads anymore. We now added a download button to the model3d component itself.\\n\\n<img width=\"739\" alt=\"Screenshot 2023-01-18 at 3 52 45 PM\"', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='src=\"https://user-images.githubusercontent.com/12725292/213294198-5f4fda35-bde7-450c-864f-d5683e7fa29a.png\">\\n\\nBy [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 3014](https://github.com/gradio-app/gradio/pull/3014)\\n\\n### Fixing Auth on Spaces 🔑\\n\\nAuthentication on spaces works now! Third party cookies must be enabled on your browser to be able\\nto log in. Some browsers disable third party cookies by default (Safari, Chrome Incognito).\\n\\n![auth_spaces](https://user-images.githubusercontent.com/41651716/215528417-09538933-0576-4d1d-b3b9-1e877ab01905.gif)\\n\\n\\n## Bug Fixes:\\n* Fixes bug where interpretation event was not configured correctly by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2993](https://github.com/gradio-app/gradio/pull/2993)\\n* Fix relative import bug in reload mode by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2992](https://github.com/gradio-app/gradio/pull/2992)\\n* Fixes bug where png files were not being recognized when uploading images by [@abidlabs](https://github.com/abidlabs) in [PR 3002](https://github.com/gradio-app/gradio/pull/3002)\\n*', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='Fixes bug where external Spaces could not be loaded and used as functions if they returned files by [@abidlabs](https://github.com/abidlabs) in [PR 3004](https://github.com/gradio-app/gradio/pull/3004)\\n* Fix bug where file serialization output was not JSON serializable by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2999](https://github.com/gradio-app/gradio/pull/2999)\\n* Fixes bug where png files were not being recognized when uploading images by [@abidlabs](https://github.com/abidlabs) in [PR 3002](https://github.com/gradio-app/gradio/pull/3002)\\n* Fixes bug where temporary uploaded files were not being added to temp sets by [@abidlabs](https://github.com/abidlabs) in [PR 3005](https://github.com/gradio-app/gradio/pull/3005)\\n* Fixes issue where markdown support in chatbot breaks older demos [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 3006](https://github.com/gradio-app/gradio/pull/3006)\\n* Fixes the `/file/` route that was broken in a recent change in [PR 3010](https://github.com/gradio-app/gradio/pull/3010)\\n* Fix bug where the Image component could not serialize image urls by', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='[@freddyaboulton](https://github.com/freddyaboulton) in [PR 2957](https://github.com/gradio-app/gradio/pull/2957)\\n* Fix forwarding for guides after SEO renaming by [@aliabd](https://github.com/aliabd) in [PR 3017](https://github.com/gradio-app/gradio/pull/3017)\\n* Switch all pages on the website to use latest stable gradio by [@aliabd](https://github.com/aliabd) in [PR 3016](https://github.com/gradio-app/gradio/pull/3016)\\n* Fix bug related to deprecated parameters in `huggingface_hub` for the HuggingFaceDatasetSaver in [PR 3025](https://github.com/gradio-app/gradio/pull/3025)\\n* Added better support for symlinks in the way absolute paths are resolved by [@abidlabs](https://github.com/abidlabs) in [PR 3037](https://github.com/gradio-app/gradio/pull/3037)\\n* Fix several minor frontend bugs (loading animation, examples as gallery) frontend [@aliabid94](https://github.com/3026) in [PR 2961](https://github.com/gradio-app/gradio/pull/3026).\\n* Fixes bug that the chatbot sample code does not work with certain input value by [@petrov826](https://github.com/petrov826) in [PR', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='3039](https://github.com/gradio-app/gradio/pull/3039).\\n* Fix shadows for form element and ensure focus styles more visible in dark mode   [@pngwn](https://github.com/pngwn) in [PR 3042](https://github.com/gradio-app/gradio/pull/3042).\\n* Fixed bug where the Checkbox and Dropdown change events were not triggered in response to other component changes by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 3045](https://github.com/gradio-app/gradio/pull/3045)\\n* Fix bug where the queue was not properly restarted after launching a `closed` app by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 3022](https://github.com/gradio-app/gradio/pull/3022)\\n* Adding missing embedded components on docs by [@aliabd](https://github.com/aliabd) in [PR 3027](https://github.com/gradio-app/gradio/pull/3027)\\n* Fixes bug where app would crash if the `file_types` parameter of `gr.File` or `gr.UploadButton` was not a list by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 3048](https://github.com/gradio-app/gradio/pull/3048)\\n* Ensure CSS mounts correctly regardless of how many Gradio instances are on the page', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content=\"[@pngwn](https://github.com/pngwn) in [PR 3059](https://github.com/gradio-app/gradio/pull/3059).\\n* Fix bug where input component was not hidden in the frontend for `UploadButton` by  [@freddyaboulton](https://github.com/freddyaboulton) in [PR 3053](https://github.com/gradio-app/gradio/pull/3053)\\n* Fixes issue where after clicking submit or undo, the sketch output wouldn't clear. [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 3047](https://github.com/gradio-app/gradio/pull/3047)\\n* Ensure spaces embedded via the web component always use the correct URLs for server requests and change ports for testing to avoid strange collisions when users are working with embedded apps locally by [@pngwn](https://github.com/pngwn) in [PR 3065](https://github.com/gradio-app/gradio/pull/3065)\\n* Preserve selected image of Gallery through updated by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 3061](https://github.com/gradio-app/gradio/pull/3061)\\n* Fix bug where auth was not respected on HF spaces by [@freddyaboulton](https://github.com/freddyaboulton) and [@aliabid94](https://github.com/aliabid94) in [PR\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='3049](https://github.com/gradio-app/gradio/pull/3049)\\n* Fixes bug where tabs selected attribute not working if manually change tab by [@tomchang25](https://github.com/tomchang25) in [3055](https://github.com/gradio-app/gradio/pull/3055)\\n* Change chatbot to show dots on progress, and fix bug where chatbot would not stick to bottom in the case of images by [@aliabid94](https://github.com/aliabid94) in [PR 3067](https://github.com/gradio-app/gradio/pull/3079)\\n\\n## Documentation Changes:\\n* SEO improvements to guides by[@aliabd](https://github.com/aliabd) in [PR 2915](https://github.com/gradio-app/gradio/pull/2915)\\n* Use `gr.LinePlot` for the `blocks_kinematics` demo by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2998](https://github.com/gradio-app/gradio/pull/2998)\\n* Updated the `interface_series_load` to include some inline markdown code by [@abidlabs](https://github.com/abidlabs) in [PR 3051](https://github.com/gradio-app/gradio/pull/3051)\\n\\n## Testing and Infrastructure Changes:\\n* Adds a GitHub action to test if any large files (> 5MB) are present by [@abidlabs](https://github.com/abidlabs)', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='in [PR 3013](https://github.com/gradio-app/gradio/pull/3013)\\n\\n## Breaking Changes:\\nNo changes to highlight.\\n\\n## Full Changelog:\\n* Rewrote frontend using CSS variables for themes by [@pngwn](https://github.com/pngwn) in [PR 2840](https://github.com/gradio-app/gradio/pull/2840)\\n* Moved telemetry requests to run on background threads by [@abidlabs](https://github.com/abidlabs) in [PR 3054](https://github.com/gradio-app/gradio/pull/3054)\\n\\n\\n## Contributors Shoutout:\\nNo changes to highlight.\\n\\n\\n# Version 3.16.2\\n\\n## New Features:\\nNo changes to highlight.\\n\\n## Bug Fixes:\\n* Fixed file upload fails for files with zero size by [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 2923](https://github.com/gradio-app/gradio/pull/2923)\\n* Fixed bug where `mount_gradio_app` would not launch if the queue was enabled in a gradio app by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2939](https://github.com/gradio-app/gradio/pull/2939)\\n* Fix custom long CSS handling in Blocks by [@anton-l](https://github.com/anton-l) in [PR 2953](https://github.com/gradio-app/gradio/pull/2953)\\n* Recovers the dropdown change', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='event by [@abidlabs](https://github.com/abidlabs) in [PR 2954](https://github.com/gradio-app/gradio/pull/2954).\\n* Fix audio file output by [@aliabid94](https://github.com/aliabid94) in [PR 2961](https://github.com/gradio-app/gradio/pull/2961).\\n* Fixed bug where file extensions of really long files were not kept after download by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2929](https://github.com/gradio-app/gradio/pull/2929)\\n* Fix bug where outputs for examples where not being returned by the backend by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2955](https://github.com/gradio-app/gradio/pull/2955)\\n* Fix bug in `blocks_plug` demo that prevented switching tabs programmatically with python [@TashaSkyUp](https://github.com/https://github.com/TashaSkyUp) in [PR 2971](https://github.com/gradio-app/gradio/pull/2971).\\n\\n## Documentation Changes:\\nNo changes to highlight.\\n\\n## Testing and Infrastructure Changes:\\nNo changes to highlight.\\n\\n## Breaking Changes:\\nNo changes to highlight.\\n\\n## Full Changelog:\\nNo changes to highlight.\\n\\n## Contributors Shoutout:\\nNo changes to', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='highlight.\\n\\n\\n# Version 3.16.1\\n\\n## New Features:\\n\\nNo changes to highlight.\\n\\n## Bug Fixes:\\n* Fix audio file output by [@aliabid94](https://github.com/aliabid94) in [PR 2950](https://github.com/gradio-app/gradio/pull/2950).\\n\\n## Documentation Changes:\\nNo changes to highlight.\\n\\n## Testing and Infrastructure Changes:\\nNo changes to highlight.\\n\\n## Breaking Changes:\\nNo changes to highlight.\\n\\n## Full Changelog:\\nNo changes to highlight.\\n\\n## Contributors Shoutout:\\nNo changes to highlight.\\n\\n# Version 3.16.0\\n\\n## New Features:\\n\\n### Send custom progress updates by adding a `gr.Progress` argument after the input arguments to any function. Example:\\n\\n```python\\ndef reverse(word, progress=gr.Progress()):\\n    progress(0, desc=\"Starting\")\\n    time.sleep(1)\\n    new_string = \"\"\\n    for letter in progress.tqdm(word, desc=\"Reversing\"):\\n        time.sleep(0.25)\\n        new_string = letter + new_string\\n    return new_string\\n\\ndemo = gr.Interface(reverse, gr.Text(), gr.Text())\\n```\\n\\nProgress indicator bar by [@aliabid94](https://github.com/aliabid94) in [PR 2750](https://github.com/gradio-app/gradio/pull/2750).\\n\\n* Added `title` argument to `TabbedInterface` by', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='@MohamedAliRashad in [#2888](https://github.com/gradio-app/gradio/pull/2888)\\n* Add support for specifying file extensions for `gr.File` and `gr.UploadButton`, using `file_types` parameter (e.g  `gr.File(file_count=\"multiple\", file_types=[\"text\", \".json\", \".csv\"])`) by @dawoodkhan82 in [#2901](https://github.com/gradio-app/gradio/pull/2901)\\n* Added `multiselect` option to `Dropdown` by @dawoodkhan82 in [#2871](https://github.com/gradio-app/gradio/pull/2871)\\n\\n### With `multiselect` set to `true` a user can now select multiple options from the `gr.Dropdown` component.\\n\\n```python\\ngr.Dropdown([\"angola\", \"pakistan\", \"canada\"], multiselect=True, value=[\"angola\"])\\n```\\n<img width=\"610\" alt=\"Screenshot 2023-01-03 at 4 14 36 PM\" src=\"https://user-images.githubusercontent.com/12725292/210442547-c86975c9-4b4f-4b8e-8803-9d96e6a8583a.png\">\\n\\n\\n## Bug Fixes:\\n* Fixed bug where an error opening an audio file led to a crash by [@FelixDombek](https://github.com/FelixDombek) in [PR 2898](https://github.com/gradio-app/gradio/pull/2898)\\n* Fixed bug where setting `default_enabled=False` made it so that the entire queue did not', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='start by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2876](https://github.com/gradio-app/gradio/pull/2876)\\n* Fixed bug where csv preview for DataFrame examples would show filename instead of file contents by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2877](https://github.com/gradio-app/gradio/pull/2877)\\n* Fixed bug where an error raised after yielding iterative output would not be displayed in the browser by\\n[@JaySmithWpg](https://github.com/JaySmithWpg) in [PR 2889](https://github.com/gradio-app/gradio/pull/2889)\\n* Fixed bug in `blocks_style` demo that was preventing it from launching by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2890](https://github.com/gradio-app/gradio/pull/2890)\\n* Fixed bug where files could not be downloaded by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2926](https://github.com/gradio-app/gradio/pull/2926)\\n* Fixed bug where cached examples were not displaying properly by [@a-rogalska](https://github.com/a-rogalska) in [PR 2974](https://github.com/gradio-app/gradio/pull/2974)\\n\\n## Documentation Changes:\\n* Added a', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content=\"Guide on using Google Sheets to create a real-time dashboard with Gradio's `DataFrame` and `LinePlot` component, by [@abidlabs](https://github.com/abidlabs) in [PR 2816](https://github.com/gradio-app/gradio/pull/2816)\\n* Add a components - events matrix on the docs by [@aliabd](https://github.com/aliabd) in [PR 2921](https://github.com/gradio-app/gradio/pull/2921)\\n\\n## Testing and Infrastructure Changes:\\n* Deployed PRs from forks to spaces by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2895](https://github.com/gradio-app/gradio/pull/2895)\\n\\n## Breaking Changes:\\nNo changes to highlight.\\n\\n## Full Changelog:\\n* The `default_enabled` parameter of the `Blocks.queue` method has no effect by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2876](https://github.com/gradio-app/gradio/pull/2876)\\n* Added typing to several Python files in codebase by [@abidlabs](https://github.com/abidlabs) in [PR 2887](https://github.com/gradio-app/gradio/pull/2887)\\n* Excluding untracked files from demo notebook check action by [@aliabd](https://github.com/aliabd) in [PR\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='2897](https://github.com/gradio-app/gradio/pull/2897)\\n* Optimize images and gifs by [@aliabd](https://github.com/aliabd) in [PR 2922](https://github.com/gradio-app/gradio/pull/2922)\\n* Updated typing by [@1nF0rmed](https://github.com/1nF0rmed) in [PR 2904](https://github.com/gradio-app/gradio/pull/2904)\\n\\n## Contributors Shoutout:\\n* @JaySmithWpg for making their first contribution to gradio!\\n* @MohamedAliRashad for making their first contribution to gradio!\\n\\n# Version 3.15.0\\n\\n## New Features:\\n\\nGradio\\'s newest plotting component `gr.LinePlot`! 📈\\n\\nWith this component you can easily create time series visualizations with customizable\\nappearance for your demos and dashboards ... all without having to know an external plotting library.\\n\\nFor an example of the api see below:\\n\\n```python\\ngr.LinePlot(stocks,\\n            x=\"date\",\\n            y=\"price\",\\n            color=\"symbol\",\\n            color_legend_position=\"bottom\",\\n            width=600, height=400, title=\"Stock Prices\")\\n```\\n![image](https://user-images.githubusercontent.com/41651716/208711646-81ae3745-149b-46a3-babd-0569aecdd409.png)\\n\\n\\nBy [@freddyaboulton](https://github.com/freddyaboulton) in [PR', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='2807](https://github.com/gradio-app/gradio/pull/2807)\\n\\n## Bug Fixes:\\n* Fixed bug where the `examples_per_page` parameter of the `Examples` component was not passed to the internal `Dataset` component by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2861](https://github.com/gradio-app/gradio/pull/2861)\\n* Fixes loading Spaces that have components with default values by [@abidlabs](https://github.com/abidlabs) in [PR 2855](https://github.com/gradio-app/gradio/pull/2855)\\n* Fixes flagging when `allow_flagging=\"auto\"` in `gr.Interface()` by [@abidlabs](https://github.com/abidlabs) in [PR 2695](https://github.com/gradio-app/gradio/pull/2695)\\n* Fixed bug where passing a non-list value to `gr.CheckboxGroup` would crash the entire app by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2866](https://github.com/gradio-app/gradio/pull/2866)\\n\\n## Documentation Changes:\\n* Added a Guide on using BigQuery with Gradio\\'s `DataFrame` and `ScatterPlot` component,\\nby [@abidlabs](https://github.com/abidlabs) in [PR 2794](https://github.com/gradio-app/gradio/pull/2794)\\n\\n## Testing and', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='Infrastructure Changes:\\nNo changes to highlight.\\n\\n## Breaking Changes:\\nNo changes to highlight.\\n\\n## Full Changelog:\\n* Fixed importing gradio can cause PIL.Image.registered_extensions() to break by `[@aliencaocao](https://github.com/aliencaocao)` in `[PR 2846](https://github.com/gradio-app/gradio/pull/2846)`\\n* Fix css glitch and navigation in docs by [@aliabd](https://github.com/aliabd) in [PR 2856](https://github.com/gradio-app/gradio/pull/2856)\\n* Added the ability to set `x_lim`, `y_lim` and legend positions for `gr.ScatterPlot` by  [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2807](https://github.com/gradio-app/gradio/pull/2807)\\n* Remove footers and min-height the correct way by [@aliabd](https://github.com/aliabd) in [PR 2860](https://github.com/gradio-app/gradio/pull/2860)\\n\\n## Contributors Shoutout:\\nNo changes to highlight.\\n\\n# Version 3.14.0\\n\\n## New Features:\\n\\n### Add Waveform Visual Support to Audio\\nAdds a `gr.make_waveform()` function that creates a waveform video by combining an audio and an optional background image by [@dawoodkhan82](http://github.com/dawoodkhan82) and', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content=\"[@aliabid94](http://github.com/aliabid94) in [PR 2706](https://github.com/gradio-app/gradio/pull/2706. Helpful for making audio outputs much more shareable.\\n\\n![waveform screenrecording](https://user-images.githubusercontent.com/7870876/206062396-164a5e71-451a-4fe0-94a7-cbe9269d57e6.gif)\\n\\n### Allows Every Component to Accept an `every` Parameter\\n\\nWhen a component's initial value is a function, the `every` parameter re-runs the function every `every` seconds. By [@abidlabs](https://github.com/abidlabs) in [PR 2806](https://github.com/gradio-app/gradio/pull/2806). Here's a code example:\\n\\n```py\\nimport gradio as gr\\n\\nwith gr.Blocks() as demo:\\n    df = gr.DataFrame(run_query, every=60*60)\\n\\ndemo.queue().launch()\\n```\\n\\n## Bug Fixes:\\n* Fixed issue where too many temporary files were created, all with randomly generated\\nfilepaths. Now fewer temporary files are created and are assigned a path that is a\\nhash based on the file contents by [@abidlabs](https://github.com/abidlabs) in [PR 2758](https://github.com/gradio-app/gradio/pull/2758)\\n\\n## Documentation Changes:\\nNo changes to highlight.\\n\\n## Testing and Infrastructure\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='Changes:\\nNo changes to highlight.\\n\\n## Breaking Changes:\\nNo changes to highlight.\\n\\n## Full Changelog:\\nNo changes to highlight.\\n\\n## Contributors Shoutout:\\nNo changes to highlight.\\n\\n\\n# Version 3.13.2\\n\\n## New Features:\\nNo changes to highlight.\\n\\n## Bug Fixes:\\nNo changes to highlight.\\n\\n## Documentation Changes:\\n* Improves documentation of several queuing-related parameters by [@abidlabs](https://github.com/abidlabs) in [PR 2825](https://github.com/gradio-app/gradio/pull/2825)\\n\\n## Testing and Infrastructure Changes:\\n* Remove h11 pinning by [@ecederstrand]([https://github.com/abidlabs](https://github.com/ecederstrand)) in [PR 2820]([https://github.com/gradio-app/gradio/pull/2808](https://github.com/gradio-app/gradio/pull/2820))\\n\\n## Breaking Changes:\\nNo changes to highlight.\\n\\n## Full Changelog:\\nNo changes to highlight.\\n\\n## Contributors Shoutout:\\nNo changes to highlight.\\n\\n# Version 3.13.1\\n\\n## New Features:\\n\\n### New Shareable Links\\n\\nReplaces tunneling logic based on ssh port-forwarding to that based on `frp` by [XciD](https://github.com/XciD) and [Wauplin](https://github.com/Wauplin) in [PR', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content=\"2509](https://github.com/gradio-app/gradio/pull/2509)\\n\\nYou don't need to do anything differently, but when you set `share=True` in `launch()`,\\nyou'll get this message and a public link that look a little bit different:\\n\\n```bash\\nSetting up a public link... we have recently upgraded the way public links are generated. If you encounter any problems, please downgrade to gradio version 3.13.0\\n.\\nRunning on public URL: https://bec81a83-5b5c-471e.gradio.live\\n```\\n\\nThese links are a more secure and scalable way to create shareable demos!\\n\\n## Bug Fixes:\\n* Allows `gr.Dataframe()` to take a `pandas.DataFrame` that includes numpy array and other types as its initial value, by [@abidlabs](https://github.com/abidlabs) in [PR 2804](https://github.com/gradio-app/gradio/pull/2804)\\n* Add `altair` to requirements.txt by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2811](https://github.com/gradio-app/gradio/pull/2811)\\n* Added aria-labels to icon buttons that are built into UI components by [@emilyuhde](http://github.com/emilyuhde) in [PR 2791](https://github.com/gradio-app/gradio/pull/2791)\\n\\n## Documentation Changes:\\n* Fixed some\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='typos in the \"Plot Component for Maps\" guide by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2811](https://github.com/gradio-app/gradio/pull/2811)\\n\\n## Testing and Infrastructure Changes:\\n* Fixed test for IP address by [@abidlabs](https://github.com/abidlabs) in [PR 2808](https://github.com/gradio-app/gradio/pull/2808)\\n\\n## Breaking Changes:\\nNo changes to highlight.\\n\\n## Full Changelog:\\n* Fixed typo in parameter `visible` in classes in `templates.py` by [@abidlabs](https://github.com/abidlabs) in [PR 2805](https://github.com/gradio-app/gradio/pull/2805)\\n* Switched external service for getting IP address from `https://api.ipify.org` to `https://checkip.amazonaws.com/` by [@abidlabs](https://github.com/abidlabs) in [PR 2810](https://github.com/gradio-app/gradio/pull/2810)\\n\\n## Contributors Shoutout:\\nNo changes to highlight.\\n\\n* Fixed typo in parameter `visible` in classes in `templates.py` by [@abidlabs](https://github.com/abidlabs) in [PR 2805](https://github.com/gradio-app/gradio/pull/2805)\\n* Switched external service for getting IP address from `https://api.ipify.org` to', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='`https://checkip.amazonaws.com/` by [@abidlabs](https://github.com/abidlabs) in [PR 2810](https://github.com/gradio-app/gradio/pull/2810)\\n\\n\\n# Version 3.13.0\\n\\n## New Features:\\n\\n### Scatter plot component\\n\\nIt is now possible to create a scatter plot natively in Gradio!\\n\\nThe `gr.ScatterPlot` component accepts a pandas dataframe and some optional configuration parameters\\nand will automatically create a plot for you!\\n\\nThis is the first of many native plotting components in Gradio!\\n\\nFor an example of how to use `gr.ScatterPlot` see below:\\n\\n```python\\nimport gradio as gr\\nfrom vega_datasets import data\\n\\ncars = data.cars()\\n\\nwith gr.Blocks() as demo:\\n    gr.ScatterPlot(show_label=False,\\n                   value=cars,\\n                   x=\"Horsepower\",\\n                   y=\"Miles_per_Gallon\",\\n                   color=\"Origin\",\\n                   tooltip=\"Name\",\\n                   title=\"Car Data\",\\n                   y_title=\"Miles per Gallon\",\\n                   color_legend_title=\"Origin of Car\").style(container=False)\\n\\ndemo.launch()\\n```\\n\\n<img width=\"404\" alt=\"image\" src=\"https://user-images.githubusercontent.com/41651716/206737726-4c4da5f0-dee8-4f0a-b1e1-e2b75c4638e9.png\">\\n\\n\\nBy [@freddyaboulton](https://github.com/freddyaboulton) in [PR', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='2764](https://github.com/gradio-app/gradio/pull/2764)\\n\\n\\n### Support for altair plots\\n\\nThe `Plot` component can now accept altair plots as values!\\nSimply return an altair plot from your event listener and gradio will display it in the front-end.\\nSee the example below:\\n\\n```python\\nimport gradio as gr\\nimport altair as alt\\nfrom vega_datasets import data\\n\\ncars = data.cars()\\nchart = (\\n    alt.Chart(cars)\\n    .mark_point()\\n    .encode(\\n        x=\"Horsepower\",\\n        y=\"Miles_per_Gallon\",\\n        color=\"Origin\",\\n    )\\n)\\n\\nwith gr.Blocks() as demo:\\n    gr.Plot(value=chart)\\ndemo.launch()\\n```\\n\\n<img width=\"1366\" alt=\"image\" src=\"https://user-images.githubusercontent.com/41651716/204660697-f994316f-5ca7-4e8a-93bc-eb5e0d556c91.png\">\\n\\nBy [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2741](https://github.com/gradio-app/gradio/pull/2741)\\n\\n### Set the background color of a Label component\\n\\nThe `Label` component now accepts a `color` argument by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2736](https://github.com/gradio-app/gradio/pull/2736).\\nThe `color` argument should either be a valid css color name or hexadecimal', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='string.\\nYou can update the color with `gr.Label.update`!\\n\\nThis lets you create Alert and Warning boxes with the `Label` component. See below:\\n\\n```python\\nimport gradio as gr\\nimport random\\n\\ndef update_color(value):\\n    if value < 0:\\n        # This is bad so use red\\n        return \"#FF0000\"\\n    elif 0 <= value <= 20:\\n        # Ok but pay attention (use orange)\\n        return \"#ff9966\"\\n    else:\\n        # Nothing to worry about\\n        return None\\n\\ndef update_value():\\n    choice = random.choice([\\'good\\', \\'bad\\', \\'so-so\\'])\\n    color = update_color(choice)\\n    return gr.Label.update(value=choice, color=color)\\n\\n\\nwith gr.Blocks() as demo:\\n    label = gr.Label(value=-10)\\n    demo.load(lambda: update_value(), inputs=None, outputs=[label], every=1)\\ndemo.queue().launch()\\n```\\n\\n![label_bg_color_update](https://user-images.githubusercontent.com/41651716/204400372-80e53857-f26f-4a38-a1ae-1acadff75e89.gif)\\n\\n### Add Brazilian Portuguese translation\\n\\nAdd Brazilian Portuguese translation (pt-BR.json) by [@pstwh](http://github.com/pstwh) in [PR 2753](https://github.com/gradio-app/gradio/pull/2753):\\n\\n<img width=\"951\" alt=\"image\"', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='src=\"https://user-images.githubusercontent.com/1778297/206615305-4c52031e-3f7d-4df2-8805-a79894206911.png\">\\n\\n## Bug Fixes:\\n* Fixed issue where image thumbnails were not showing when an example directory was provided\\nby [@abidlabs](https://github.com/abidlabs) in [PR 2745](https://github.com/gradio-app/gradio/pull/2745)\\n* Fixed bug loading audio input models from the hub by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2779](https://github.com/gradio-app/gradio/pull/2779).\\n* Fixed issue where entities were not merged when highlighted text was generated from the\\ndictionary inputs [@payoto](https://github.com/payoto) in [PR 2767](https://github.com/gradio-app/gradio/pull/2767)\\n* Fixed bug where generating events did not finish running even if the websocket connection was closed by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2783](https://github.com/gradio-app/gradio/pull/2783).\\n\\n## Documentation Changes:\\nNo changes to highlight.\\n\\n## Testing and Infrastructure Changes:\\nNo changes to highlight.\\n\\n## Breaking Changes:\\nNo changes to highlight.\\n\\n## Full Changelog:\\n* Images in the', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content=\"chatbot component are now resized if they exceed a max width by [@abidlabs](https://github.com/abidlabs) in [PR 2748](https://github.com/gradio-app/gradio/pull/2748)\\n* Missing parameters have been added to `gr.Blocks().load()` by [@abidlabs](https://github.com/abidlabs) in [PR 2755](https://github.com/gradio-app/gradio/pull/2755)\\n* Deindex share URLs from search by [@aliabd](https://github.com/aliabd) in [PR 2772](https://github.com/gradio-app/gradio/pull/2772)\\n* Redirect old links and fix broken ones by [@aliabd](https://github.com/aliabd) in [PR 2774](https://github.com/gradio-app/gradio/pull/2774)\\n\\n## Contributors Shoutout:\\nNo changes to highlight.\\n\\n# Version 3.12.0\\n\\n## New Features:\\n\\n### The `Chatbot` component now supports a subset of Markdown (including bold, italics, code, images)\\n\\nYou can now pass in some Markdown to the Chatbot component and it will show up,\\nmeaning that you can pass in images as well! by [@abidlabs](https://github.com/abidlabs) in [PR 2731](https://github.com/gradio-app/gradio/pull/2731)\\n\\nHere's a simple example that references a local image `lion.jpg` that is in the same\\nfolder as the Python\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='script:\\n\\n```py\\nimport gradio as gr\\n\\nwith gr.Blocks() as demo:\\n    gr.Chatbot([(\"hi\", \"hello **abubakar**\"), (\"![](/file=lion.jpg)\", \"cool pic\")])\\n\\ndemo.launch()\\n```\\n\\n![Alt text](https://user-images.githubusercontent.com/1778297/204357455-5c1a4002-eee7-479d-9a1e-ba2c12522723.png)\\n\\nTo see a more realistic example, see the new demo `/demo/chatbot_multimodal/run.py`.\\n\\n\\n### Latex support\\nAdded mathtext (a subset of latex) support to gr.Markdown. Added by [@kashif](https://github.com/kashif) and [@aliabid94](https://github.com/aliabid94) in [PR 2696](https://github.com/gradio-app/gradio/pull/2696).\\n\\nExample of how it can be used:\\n\\n```python\\ngr.Markdown(\\n    r\"\"\"\\n    # Hello World! $\\\\frac{\\\\sqrt{x + y}}{4}$ is today\\'s lesson.\\n    \"\"\")\\n```\\n\\n### Update Accordion properties from the backend\\n\\nYou can now update the Accordion `label` and `open` status with `gr.Accordion.update` by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2690](https://github.com/gradio-app/gradio/pull/2690)\\n\\n```python\\nimport gradio as gr\\n\\nwith gr.Blocks() as demo:\\n    with gr.Accordion(label=\"Open for greeting\", open=False) as accordion:\\n       ', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='       gr.Textbox(\"Hello!\")\\n    open_btn = gr.Button(value=\"Open Accordion\")\\n    close_btn = gr.Button(value=\"Close Accordion\")\\n    open_btn.click(\\n        lambda: gr.Accordion.update(open=True, label=\"Open Accordion\"),\\n        inputs=None,\\n        outputs=[accordion],\\n    )\\n    close_btn.click(\\n        lambda: gr.Accordion.update(open=False, label=\"Closed Accordion\"),\\n        inputs=None,\\n        outputs=[accordion],\\n    )\\ndemo.launch()\\n```\\n\\n![update_accordion](https://user-images.githubusercontent.com/41651716/203164176-b102eae3-babe-4986-ae30-3ab4f400cedc.gif)\\n\\n## Bug Fixes:\\n* Fixed bug where requests timeout is missing from utils.version_check() by [@yujiehecs](https://github.com/yujiehecs) in [PR 2729](https://github.com/gradio-app/gradio/pull/2729)\\n* Fixed bug where so that the `File` component can properly preprocess files to \"binary\" byte-string format by [CoffeeVampir3](https://github.com/CoffeeVampir3) in [PR 2727](https://github.com/gradio-app/gradio/pull/2727)\\n* Fixed bug to ensure that filenames are less than 200 characters even for non-English languages by [@SkyTNT](https://github.com/SkyTNT) in [PR', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='2685](https://github.com/gradio-app/gradio/pull/2685)\\n\\n## Documentation Changes:\\n* Performance improvements to docs on mobile by  [@aliabd](https://github.com/aliabd) in [PR 2730](https://github.com/gradio-app/gradio/pull/2730)\\n\\n## Testing and Infrastructure Changes:\\nNo changes to highlight.\\n\\n## Breaking Changes:\\nNo changes to highlight.\\n\\n## Full Changelog:\\n* Make try examples button more prominent by [@aliabd](https://github.com/aliabd) in [PR 2705](https://github.com/gradio-app/gradio/pull/2705)\\n* Fix id clashes in docs by [@aliabd](https://github.com/aliabd) in [PR 2713](https://github.com/gradio-app/gradio/pull/2713)\\n* Fix typos in guide docs by [@andridns](https://github.com/andridns) in [PR 2722](https://github.com/gradio-app/gradio/pull/2722)\\n* Add option to `include_audio` in Video component. When `True`, for `source=\"webcam\"` this will record audio and video, for `source=\"upload\"` this will retain  the audio in an uploaded video by [@mandargogate](https://github.com/MandarGogate) in [PR 2721](https://github.com/gradio-app/gradio/pull/2721)\\n\\n## Contributors Shoutout:\\n*', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='[@andridns](https://github.com/andridns) made their first contribution in [PR 2722](https://github.com/gradio-app/gradio/pull/2722)!\\n\\n\\n# Version 3.11.0\\n\\n## New Features:\\n\\n### Upload Button\\nThere is now a new component called the `UploadButton` which is a file upload component but in button form! You can also specify what file types it should accept in the form of a list (ex: `image`, `video`, `audio`, `text`, or generic `file`). Added by [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 2591](https://github.com/gradio-app/gradio/pull/2591).\\n\\nExample of how it can be used:\\n\\n```python\\nimport gradio as gr\\n\\ndef upload_file(files):\\n    file_paths = [file.name for file in files]\\n    return file_paths\\n\\nwith gr.Blocks() as demo:\\n    file_output = gr.File()\\n    upload_button = gr.UploadButton(\"Click to Upload a File\", file_types=[\"image\", \"video\"], file_count=\"multiple\")\\n    upload_button.upload(upload_file, upload_button, file_output)\\n\\ndemo.launch()\\n```\\n### Revamped API documentation page\\n\\nNew API Docs page with in-browser playground and updated aesthetics. [@gary149](https://github.com/gary149) in [PR', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='2652](https://github.com/gradio-app/gradio/pull/2652)\\n\\n### Revamped Login page\\n\\nPreviously our login page had its own CSS, had no dark mode, and had an ugly json message on the wrong credentials. Made the page more aesthetically consistent, added dark mode support, and a nicer error message. [@aliabid94](https://github.com/aliabid94) in [PR 2684](https://github.com/gradio-app/gradio/pull/2684)\\n\\n### Accessing the Requests Object Directly\\n\\nYou can now access the Request object directly in your Python function by [@abidlabs](https://github.com/abidlabs) in [PR 2641](https://github.com/gradio-app/gradio/pull/2641). This means that you can access request headers, the client IP address, and so on. In order to use it, add a parameter to your function and set its type hint to be `gr.Request`. Here\\'s a simple example:\\n\\n```py\\nimport gradio as gr\\n\\ndef echo(name, request: gr.Request):\\n    if request:\\n        print(\"Request headers dictionary:\", request.headers)\\n        print(\"IP address:\", request.client.host)\\n    return name\\n\\nio = gr.Interface(echo, \"textbox\", \"textbox\").launch()\\n```\\n\\n## Bug Fixes:\\n* Fixed bug that limited files from being sent over websockets to 16MB. The', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='new limit\\nis now 1GB  by [@abidlabs](https://github.com/abidlabs) in [PR 2709](https://github.com/gradio-app/gradio/pull/2709)\\n\\n## Documentation Changes:\\n* Updated documentation for embedding Gradio demos on Spaces as web components by\\n[@julien-c](https://github.com/julien-c) in [PR 2698](https://github.com/gradio-app/gradio/pull/2698)\\n* Updated IFrames in Guides to use the host URL instead of the Space name to be consistent with the new method for embedding Spaces, by\\n[@julien-c](https://github.com/julien-c) in [PR 2692](https://github.com/gradio-app/gradio/pull/2692)\\n * Colab buttons on every demo in the website! Just click open in colab, and run the demo there.\\n\\n\\n\\nhttps://user-images.githubusercontent.com/9021060/202878400-cb16ed47-f4dd-4cb0-b2f0-102a9ff64135.mov\\n\\n## Testing and Infrastructure Changes:\\nNo changes to highlight.\\n\\n## Breaking Changes:\\nNo changes to highlight.\\n\\n## Full Changelog:\\n* Better warnings and error messages for `gr.Interface.load()` by [@abidlabs](https://github.com/abidlabs) in [PR 2694](https://github.com/gradio-app/gradio/pull/2694)\\n* Add open in colab buttons to demos in docs and /demos', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content=\"by [@aliabd](https://github.com/aliabd) in [PR 2608](https://github.com/gradio-app/gradio/pull/2608)\\n* Apply different formatting for the types in component docstrings by [@aliabd](https://github.com/aliabd) in [PR 2707](https://github.com/gradio-app/gradio/pull/2707)\\n\\n## Contributors Shoutout:\\nNo changes to highlight.\\n\\n# Version 3.10.1\\n\\n## New Features:\\nNo changes to highlight.\\n\\n## Bug Fixes:\\n* Passes kwargs into `gr.Interface.load()` by [@abidlabs](https://github.com/abidlabs) in [PR 2669](https://github.com/gradio-app/gradio/pull/2669)\\n\\n## Documentation Changes:\\nNo changes to highlight.\\n\\n## Testing and Infrastructure Changes:\\nNo changes to highlight.\\n\\n## Breaking Changes:\\nNo changes to highlight.\\n\\n## Full Changelog:\\n* Clean up printed statements in Embedded Colab Mode by [@aliabid94](https://github.com/aliabid94) in [PR 2612](https://github.com/gradio-app/gradio/pull/2612)\\n\\n## Contributors Shoutout:\\nNo changes to highlight.\\n\\n\\n# Version 3.10.0\\n\\n* Add support for `'password'` and `'email'` types to `Textbox`. [@pngwn](https://github.com/pngwn) in [PR\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='2653](https://github.com/gradio-app/gradio/pull/2653)\\n* `gr.Textbox` component will now raise an exception if `type` is not \"text\", \"email\", or \"password\" [@pngwn](https://github.com/pngwn) in [PR 2653](https://github.com/gradio-app/gradio/pull/2653). This will cause demos using the deprecated `gr.Textbox(type=\"number\")` to raise an exception.\\n\\n## Bug Fixes:\\n* Updated the minimum FastApi used in tests to version 0.87 by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2647](https://github.com/gradio-app/gradio/pull/2647)\\n* Fixed bug where interfaces with examples could not be loaded with `gr.Interface.load` by [@freddyaboulton](https://github.com/freddyaboulton) [PR 2640](https://github.com/gradio-app/gradio/pull/2640)\\n* Fixed bug where the `interactive` property of a component could not be updated by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2639](https://github.com/gradio-app/gradio/pull/2639)\\n* Fixed bug where some URLs were not being recognized as valid URLs and thus were not\\nloading correctly in various components by [@abidlabs](https://github.com/abidlabs) in [PR', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='2659](https://github.com/gradio-app/gradio/pull/2659)\\n\\n\\n## Documentation Changes:\\n* Fix some typos in the embedded demo names in \"05_using_blocks_like_functions.md\" by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2656](https://github.com/gradio-app/gradio/pull/2656)\\n\\n## Testing and Infrastructure Changes:\\nNo changes to highlight.\\n\\n## Breaking Changes:\\nNo changes to highlight.\\n\\n## Full Changelog:\\n* Add support for `\\'password\\'` and `\\'email\\'` types to `Textbox`. [@pngwn](https://github.com/pngwn) in [PR 2653](https://github.com/gradio-app/gradio/pull/2653)\\n\\n## Contributors Shoutout:\\nNo changes to highlight.\\n\\n\\n# Version 3.9.1\\n\\n## New Features:\\nNo changes to highlight.\\n\\n## Bug Fixes:\\n* Only set a min height on md and html when loading by [@pngwn](https://github.com/pngwn) in [PR 2623](https://github.com/gradio-app/gradio/pull/2623)\\n\\n## Documentation Changes:\\n* See docs for the latest gradio commit to main as well the latest pip release:\\n\\n![main-vs-pip](https://user-images.githubusercontent.com/9021060/199607887-aab1ae4e-a070-4527-966d-024397abe15b.gif)\\n\\n* Modified the \"Connecting To a Database', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='Guide\" to use `pd.read_sql` as opposed to low-level postgres connector by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2604](https://github.com/gradio-app/gradio/pull/2604)\\n\\n## Testing and Infrastructure Changes:\\nNo changes to highlight.\\n\\n## Breaking Changes:\\nNo changes to highlight.\\n\\n## Full Changelog:\\n* Dropdown for seeing docs as latest or main by [@aliabd](https://github.com/aliabd) in [PR 2544](https://github.com/gradio-app/gradio/pull/2544)\\n* Allow `gr.Templates` to accept parameters to override the defaults by [@abidlabs](https://github.com/abidlabs) in [PR 2600](https://github.com/gradio-app/gradio/pull/2600)\\n* Components now throw a `ValueError()` if constructed with invalid parameters for `type` or `source` (for components that take those parameters) in [PR 2610](https://github.com/gradio-app/gradio/pull/2610)\\n* Allow auth with using queue by [@GLGDLY](https://github.com/GLGDLY) in [PR 2611](https://github.com/gradio-app/gradio/pull/2611)\\n\\n## Contributors Shoutout:\\nNo changes to highlight.\\n\\n\\n# Version 3.9\\n\\n## New Features:\\n* Gradio is now embedded directly in colab without requiring the', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='share link by [@aliabid94](https://github.com/aliabid94) in [PR 2455](https://github.com/gradio-app/gradio/pull/2455)\\n\\n### Calling functions by api_name in loaded apps\\n\\nWhen you load an upstream app with `gr.Blocks.load`, you can now specify which fn\\nto call with the `api_name` parameter.\\n\\n```python\\nimport gradio as gr\\nenglish_translator = gr.Blocks.load(name=\"spaces/gradio/english-translator\")\\ngerman = english_translator(\"My name is Freddy\", api_name=\\'translate-to-german\\')\\n```\\n\\nThe `api_name` parameter will take precendence over the `fn_index` parameter.\\n\\n## Bug Fixes:\\n* Fixed bug where None could not be used for File,Model3D, and Audio examples by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2588](https://github.com/gradio-app/gradio/pull/2588)\\n* Fixed links in Plotly map guide + demo by [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 2578](https://github.com/gradio-app/gradio/pull/2578)\\n* `gr.Blocks.load()` now correctly loads example files from Spaces [@abidlabs](https://github.com/abidlabs) in [PR 2594](https://github.com/gradio-app/gradio/pull/2594)\\n* Fixed bug when image clear', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='started upload dialog [@mezotaken](https://github.com/mezotaken) in [PR 2577](https://github.com/gradio-app/gradio/pull/2577)\\n\\n## Documentation Changes:\\n* Added a Guide on how to configure the queue for maximum performance by [@abidlabs](https://github.com/abidlabs) in [PR 2558](https://github.com/gradio-app/gradio/pull/2558)\\n\\n\\n## Testing and Infrastructure Changes:\\nNo changes to highlight.\\n\\n## Breaking Changes:\\nNo changes to highlight.\\n\\n## Full Changelog:\\n* Add `api_name` to `Blocks.__call__` by  [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2593](https://github.com/gradio-app/gradio/pull/2593)\\n* Update queue with using deque & update requirements by [@GLGDLY](https://github.com/GLGDLY) in [PR 2428](https://github.com/gradio-app/gradio/pull/2428)\\n\\n\\n## Contributors Shoutout:\\nNo changes to highlight.\\n\\n\\n# Version 3.8.2\\n\\n## Bug Fixes:\\n\\n* Ensure gradio apps embedded via spaces use the correct endpoint for predictions. [@pngwn](https://github.com/pngwn) in [PR 2567](https://github.com/gradio-app/gradio/pull/2567)\\n* Ensure gradio apps embedded via spaces use the correct websocket protocol.', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='[@pngwn](https://github.com/pngwn) in [PR 2571](https://github.com/gradio-app/gradio/pull/2571)\\n\\n## New Features:\\n\\n### Running Events Continuously\\nGradio now supports the ability to run an event continuously on a fixed schedule. To use this feature,\\npass `every=# of seconds` to the event definition. This will run the event every given number of seconds!\\n\\nThis can be used to:\\n* Create live visualizations that show the most up to date data\\n* Refresh the state of the frontend automatically in response to changes in the backend\\n\\nHere is an example of a live plot that refreshes every half second:\\n```python\\nimport math\\nimport gradio as gr\\nimport plotly.express as px\\nimport numpy as np\\n\\n\\nplot_end = 2 * math.pi\\n\\n\\ndef get_plot(period=1):\\n    global plot_end\\n    x = np.arange(plot_end - 2 * math.pi, plot_end, 0.02)\\n    y = np.sin(2*math.pi*period * x)\\n    fig = px.line(x=x, y=y)\\n    plot_end += 2 * math.pi\\n    return fig\\n\\n\\nwith gr.Blocks() as demo:\\n    with gr.Row():\\n        with gr.Column():\\n            gr.Markdown(\"Change the value of the slider to automatically update the plot\")\\n            period = gr.Slider(label=\"Period of plot\", value=1, minimum=0, maximum=10, step=1)\\n            plot = gr.Plot(label=\"Plot (updates every half', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='second)\")\\n\\n    dep = demo.load(get_plot, None, plot, every=0.5)\\n    period.change(get_plot, period, plot, every=0.5, cancels=[dep])\\n\\ndemo.queue().launch()\\n```\\n\\n![live_demo](https://user-images.githubusercontent.com/41651716/198357377-633ce460-4e31-47bd-8202-1440cdd6fe19.gif)\\n\\n\\n## Bug Fixes:\\nNo changes to highlight.\\n\\n## Documentation Changes:\\nNo changes to highlight.\\n\\n## Testing and Infrastructure Changes:\\nNo changes to highlight.\\n\\n## Breaking Changes:\\nNo changes to highlight.\\n\\n## Full Changelog:\\n* Allows loading private Spaces by passing an an `api_key` to `gr.Interface.load()`\\nby [@abidlabs](https://github.com/abidlabs) in [PR 2568](https://github.com/gradio-app/gradio/pull/2568)\\n\\n## Contributors Shoutout:\\nNo changes to highlight.\\n\\n\\n# Version 3.8\\n\\n## New Features:\\n* Allows event listeners to accept a single dictionary as its argument, where the keys are the components and the values are the component values. This is set by passing the input components in the event listener as a set instead of a list. [@aliabid94](https://github.com/aliabid94) in [PR 2550](https://github.com/gradio-app/gradio/pull/2550)\\n\\n## Bug Fixes:\\n*', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='Fix whitespace issue when using plotly. [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 2548](https://github.com/gradio-app/gradio/pull/2548)\\n* Apply appropriate alt text to all gallery images. [@camenduru](https://github.com/camenduru) in [PR 2358](https://github.com/gradio-app/gradio/pull/2538)\\n* Removed erroneous tkinter import in gradio.blocks by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2555](https://github.com/gradio-app/gradio/pull/2555)\\n\\n## Documentation Changes:\\nNo changes to highlight.\\n\\n## Testing and Infrastructure Changes:\\nNo changes to highlight.\\n\\n## Breaking Changes:\\nNo changes to highlight.\\n\\n## Full Changelog:\\n* Added the `every` keyword to event listeners that runs events on a fixed schedule by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2512](https://github.com/gradio-app/gradio/pull/2512)\\n* Fix whitespace issue when using plotly. [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 2548](https://github.com/gradio-app/gradio/pull/2548)\\n* Apply appropriate alt text to all gallery images. [@camenduru](https://github.com/camenduru) in [PR', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='2358](https://github.com/gradio-app/gradio/pull/2538)\\n\\n## Contributors Shoutout:\\nNo changes to highlight.\\n\\n\\n# Version 3.7\\n\\n## New Features:\\n\\n### Batched Functions\\n\\nGradio now supports the ability to pass *batched* functions. Batched functions are just\\nfunctions which take in a list of inputs and return a list of predictions.\\n\\nFor example, here is a batched function that takes in two lists of inputs (a list of\\nwords and a list of ints), and returns a list of trimmed words as output:\\n\\n```py\\nimport time\\n\\ndef trim_words(words, lens):\\n    trimmed_words = []\\n    time.sleep(5)\\n    for w, l in zip(words, lens):\\n        trimmed_words.append(w[:l])\\n    return [trimmed_words]\\n```\\n\\nThe advantage of using batched functions is that if you enable queuing, the Gradio\\nserver can automatically *batch* incoming requests and process them in parallel,\\npotentially speeding up your demo. Here\\'s what the Gradio code looks like (notice\\nthe `batch=True` and `max_batch_size=16` -- both of these parameters can be passed\\ninto event triggers or into the `Interface` class)\\n\\n```py\\nimport gradio as gr\\n\\nwith gr.Blocks() as demo:\\n    with gr.Row():\\n        word = gr.Textbox(label=\"word\", value=\"abc\")\\n        leng =', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='gr.Number(label=\"leng\", precision=0, value=1)\\n        output = gr.Textbox(label=\"Output\")\\n    with gr.Row():\\n        run = gr.Button()\\n\\n    event = run.click(trim_words, [word, leng], output, batch=True, max_batch_size=16)\\n\\ndemo.queue()\\ndemo.launch()\\n```\\n\\nIn the example above, 16 requests could be processed in parallel (for a total inference\\ntime of 5 seconds), instead of each request being processed separately (for a total\\ninference time of 80 seconds).\\n\\n### Upload Event\\n\\n`Video`, `Audio`, `Image`, and `File` components now support a `upload()` event that is triggered when a user uploads a file into any of these components.\\n\\nExample usage:\\n\\n```py\\nimport gradio as gr\\n\\nwith gr.Blocks() as demo:\\n    with gr.Row():\\n        input_video = gr.Video()\\n        output_video = gr.Video()\\n\\n     # Clears the output video when an input video is uploaded\\n    input_video.upload(lambda : None, None, output_video)\\n```\\n\\n\\n## Bug Fixes:\\n* Fixes issue where plotly animations, interactivity, titles, legends, were not working properly. [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 2486](https://github.com/gradio-app/gradio/pull/2486)\\n* Prevent requests to the `/api` endpoint from skipping the', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='queue if the queue is enabled for that event by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2493](https://github.com/gradio-app/gradio/pull/2493)\\n* Fixes a bug with `cancels` in event triggers so that it works properly if multiple\\nBlocks are rendered by [@abidlabs](https://github.com/abidlabs) in [PR 2530](https://github.com/gradio-app/gradio/pull/2530)\\n* Prevent invalid targets of events from crashing the whole application. [@pngwn](https://github.com/pngwn) in [PR 2534](https://github.com/gradio-app/gradio/pull/2534)\\n* Properly dequeue cancelled events when multiple apps are rendered by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2540](https://github.com/gradio-app/gradio/pull/2540)\\n\\n## Documentation Changes:\\n* Added an example interactive dashboard to the \"Tabular & Plots\" section of the Demos page by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2508](https://github.com/gradio-app/gradio/pull/2508)\\n\\n## Testing and Infrastructure Changes:\\nNo changes to highlight.\\n\\n## Breaking Changes:\\nNo changes to highlight.\\n\\n## Full Changelog:\\n* Fixes the error message if a user', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='builds Gradio locally and tries to use `share=True` by [@abidlabs](https://github.com/abidlabs) in [PR 2502](https://github.com/gradio-app/gradio/pull/2502)\\n* Allows the render() function to return self by [@Raul9595](https://github.com/Raul9595) in [PR 2514](https://github.com/gradio-app/gradio/pull/2514)\\n* Fixes issue where plotly animations, interactivity, titles, legends, were not working properly. [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 2486](https://github.com/gradio-app/gradio/pull/2486)\\n* Gradio now supports batched functions by [@abidlabs](https://github.com/abidlabs) in [PR 2218](https://github.com/gradio-app/gradio/pull/2218)\\n* Add `upload` event for `Video`, `Audio`, `Image`, and `File` components [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 2448](https://github.com/gradio-app/gradio/pull/2456)\\n* Changes websocket path for Spaces as it is no longer necessary to have a different URL for websocket connections on Spaces by [@abidlabs](https://github.com/abidlabs) in [PR 2528](https://github.com/gradio-app/gradio/pull/2528)\\n* Clearer error message when events are', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='defined outside of a Blocks scope, and a warning if you\\ntry to use `Series` or `Parallel` with `Blocks` by [@abidlabs](https://github.com/abidlabs) in [PR 2543](https://github.com/gradio-app/gradio/pull/2543)\\n* Adds support for audio samples that are in `float64`, `float16`, or `uint16` formats by [@abidlabs](https://github.com/abidlabs) in [PR 2545](https://github.com/gradio-app/gradio/pull/2545)\\n\\n## Contributors Shoutout:\\nNo changes to highlight.\\n\\n\\n# Version 3.6\\n\\n## New Features:\\n\\n### Cancelling Running Events\\nRunning events can be cancelled when other events are triggered! To test this feature, pass the `cancels` parameter to the event listener.\\nFor this feature to work, the queue must be enabled.\\n\\n![cancel_on_change_rl](https://user-images.githubusercontent.com/41651716/195952623-61a606bd-e82b-4e1a-802e-223154cb8727.gif)\\n\\nCode:\\n```python\\nimport time\\nimport gradio as gr\\n\\ndef fake_diffusion(steps):\\n    for i in range(steps):\\n        time.sleep(1)\\n        yield str(i)\\n\\ndef long_prediction(*args, **kwargs):\\n    time.sleep(10)\\n    return 42\\n\\n\\nwith gr.Blocks() as demo:\\n    with gr.Row():\\n        with gr.Column():\\n            n = gr.Slider(1, 10, value=9, step=1,', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='label=\"Number Steps\")\\n            run = gr.Button()\\n            output = gr.Textbox(label=\"Iterative Output\")\\n            stop = gr.Button(value=\"Stop Iterating\")\\n        with gr.Column():\\n            prediction = gr.Number(label=\"Expensive Calculation\")\\n            run_pred = gr.Button(value=\"Run Expensive Calculation\")\\n        with gr.Column():\\n            cancel_on_change = gr.Textbox(label=\"Cancel Iteration and Expensive Calculation on Change\")\\n\\n    click_event = run.click(fake_diffusion, n, output)\\n    stop.click(fn=None, inputs=None, outputs=None, cancels=[click_event])\\n    pred_event = run_pred.click(fn=long_prediction, inputs=None, outputs=prediction)\\n\\n    cancel_on_change.change(None, None, None, cancels=[click_event, pred_event])\\n\\n\\ndemo.queue(concurrency_count=1, max_size=20).launch()\\n```\\n\\nFor interfaces, a stop button will be added automatically if the function uses a `yield` statement.\\n\\n```python\\nimport gradio as gr\\nimport time\\n\\ndef iteration(steps):\\n    for i in range(steps):\\n       time.sleep(0.5)\\n       yield i\\n\\ngr.Interface(iteration,\\n             inputs=gr.Slider(minimum=1, maximum=10, step=1, value=5),\\n            ', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='            outputs=gr.Number()).queue().launch()\\n```\\n\\n![stop_interface_rl](https://user-images.githubusercontent.com/41651716/195952883-e7ca4235-aae3-4852-8f28-96d01d0c5822.gif)\\n\\n\\n## Bug Fixes:\\n* Add loading status tracker UI to HTML and Markdown components. [@pngwn](https://github.com/pngwn) in [PR 2474](https://github.com/gradio-app/gradio/pull/2474)\\n* Fixed videos being mirrored in the front-end if source is not webcam by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2475](https://github.com/gradio-app/gradio/pull/2475)\\n* Add clear button for timeseries component [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 2487](https://github.com/gradio-app/gradio/pull/2487)\\n* Removes special characters from temporary filenames so that the files can be served by components [@abidlabs](https://github.com/abidlabs) in [PR 2480](https://github.com/gradio-app/gradio/pull/2480)\\n* Fixed infinite reload loop when mounting gradio as a sub application by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2477](https://github.com/gradio-app/gradio/pull/2477)\\n\\n## Documentation', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='Changes:\\n* Adds a demo to show how a sound alert can be played upon completion of a prediction by [@abidlabs](https://github.com/abidlabs) in [PR 2478](https://github.com/gradio-app/gradio/pull/2478)\\n\\n## Testing and Infrastructure Changes:\\nNo changes to highlight.\\n\\n## Breaking Changes:\\nNo changes to highlight.\\n\\n## Full Changelog:\\n* Enable running events to be cancelled from other events by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2433](https://github.com/gradio-app/gradio/pull/2433)\\n* Small fix for version check before reuploading demos by [@aliabd](https://github.com/aliabd) in [PR 2469](https://github.com/gradio-app/gradio/pull/2469)\\n* Add loading status tracker UI to HTML and Markdown components. [@pngwn](https://github.com/pngwn) in [PR 2400](https://github.com/gradio-app/gradio/pull/2474)\\n* Add clear button for timeseries component [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 2487](https://github.com/gradio-app/gradio/pull/2487)\\n\\n## Contributors Shoutout:\\nNo changes to highlight.\\n\\n\\n# Version 3.5\\n\\n## Bug Fixes:\\n\\n* Ensure that Gradio does not take control of the HTML page title when', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='embedding a gradio app as a web component, this behaviour flipped by adding `control_page_title=\"true\"` to the webcomponent. [@pngwn](https://github.com/pngwn) in [PR 2400](https://github.com/gradio-app/gradio/pull/2400)\\n* Decreased latency in iterative-output demos by making the iteration asynchronous [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2409](https://github.com/gradio-app/gradio/pull/2409)\\n* Fixed queue getting stuck under very high load by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2374](https://github.com/gradio-app/gradio/pull/2374)\\n* Ensure that components always behave as if `interactive=True` were set when the following conditions are true:\\n  - no default value is provided,\\n  - they are not set as the input or output of an event,\\n  - `interactive` kwarg is not set.\\n\\n  [@pngwn](https://github.com/pngwn) in [PR 2459](https://github.com/gradio-app/gradio/pull/2459)\\n\\n## New Features:\\n\\n* When an `Image` component is set to `source=\"upload\"`, it is now possible to drag and drop and image to replace a previously uploaded image by [@pngwn](https://github.com/pngwn) in [PR', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='1711](https://github.com/gradio-app/gradio/issues/1711)\\n* The `gr.Dataset` component now accepts `HTML` and `Markdown` components by [@abidlabs](https://github.com/abidlabs) in [PR 2437](https://github.com/gradio-app/gradio/pull/2437)\\n\\n\\n## Documentation Changes:\\n* Improved documentation for the `gr.Dataset` component by [@abidlabs](https://github.com/abidlabs) in [PR 2437](https://github.com/gradio-app/gradio/pull/2437)\\n\\n## Testing and Infrastructure Changes:\\nNo changes to highlight.\\n\\n## Breaking Changes:\\n* The `Carousel` component is officially deprecated. Since gradio 3.0, code containing the `Carousel` component would throw warnings. As of the next release, the `Carousel` component will raise an exception.\\n\\n## Full Changelog:\\n* Speeds up Gallery component by using temporary files instead of base64 representation in the front-end by [@proxyphi](https://github.com/proxyphi), [@pngwn](https://github.com/pngwn), and [@abidlabs](https://github.com/abidlabs) in [PR 2265](https://github.com/gradio-app/gradio/pull/2265)\\n* Fixed some embedded demos in the guides by not loading the gradio web component in some guides by', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='[@freddyaboulton](https://github.com/freddyaboulton) in [PR 2403](https://github.com/gradio-app/gradio/pull/2403)\\n* When an `Image` component is set to `source=\"upload\"`, it is now possible to drag and drop and image to replace a previously uploaded image by [@pngwn](https://github.com/pngwn) in [PR 2400](https://github.com/gradio-app/gradio/pull/2410)\\n* Improve documentation of the `Blocks.load()` event by [@abidlabs](https://github.com/abidlabs) in [PR 2413](https://github.com/gradio-app/gradio/pull/2413)\\n* Decreased latency in iterative-output demos by making the iteration asynchronous [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2409](https://github.com/gradio-app/gradio/pull/2409)\\n* Updated share link message to reference new Spaces Hardware [@abidlabs](https://github.com/abidlabs) in [PR 2423](https://github.com/gradio-app/gradio/pull/2423)\\n* Automatically restart spaces if they\\'re down by [@aliabd](https://github.com/aliabd) in [PR 2405](https://github.com/gradio-app/gradio/pull/2405)\\n* Carousel component is now deprecated by [@abidlabs](https://github.com/abidlabs) in [PR', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='2434](https://github.com/gradio-app/gradio/pull/2434)\\n* Build Gradio from source in ui tests by by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2440](https://github.com/gradio-app/gradio/pull/2440)\\n* Change \"return ValueError\" to \"raise ValueError\" by [@vzakharov](https://github.com/vzakharov) in [PR 2445](https://github.com/gradio-app/gradio/pull/2445)\\n* Add guide on creating a map demo using the `gr.Plot()` component [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 2402](https://github.com/gradio-app/gradio/pull/2402)\\n* Add blur event for `Textbox` and `Number` components [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 2448](https://github.com/gradio-app/gradio/pull/2448)\\n* Stops a gradio launch from hogging a port even after it\\'s been killed [@aliabid94](https://github.com/aliabid94) in [PR 2453](https://github.com/gradio-app/gradio/pull/2453)\\n* Fix embedded interfaces on touch screen devices by [@aliabd](https://github.com/aliabd) in [PR 2457](https://github.com/gradio-app/gradio/pull/2457)\\n* Upload all demos to spaces by [@aliabd](https://github.com/aliabd) in', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content=\"[PR 2281](https://github.com/gradio-app/gradio/pull/2281)\\n\\n## Contributors Shoutout:\\nNo changes to highlight.\\n\\n\\n# Version 3.4.1\\n\\n## New Features:\\n\\n### 1. See Past and Upcoming Changes in the Release History 👀\\n\\nYou can now see gradio's release history directly on the website, and also keep track of upcoming changes. Just go [here](https://gradio.app/changelog/).\\n\\n![release-history](https://user-images.githubusercontent.com/9021060/193145458-3de699f7-7620-45de-aa73-a1c1b9b96257.gif)\\n\\n## Bug Fixes:\\n\\n1. Fix typo in guide image path by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2357](https://github.com/gradio-app/gradio/pull/2357)\\n2. Raise error if Blocks has duplicate component with same IDs by [@abidlabs](https://github.com/abidlabs) in [PR 2359](https://github.com/gradio-app/gradio/pull/2359)\\n3. Catch the permission exception on the audio component by [@Ian-GL](https://github.com/Ian-GL) in [PR 2330](https://github.com/gradio-app/gradio/pull/2330)\\n4. Fix image_classifier_interface_load demo by [@freddyaboulton](https://github.com/freddyaboulton) in [PR\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='2365](https://github.com/gradio-app/gradio/pull/2365)\\n5. Fix combining adjacent components without gaps by introducing `gr.Row(variant=\"compact\")` by [@aliabid94](https://github.com/aliabid94) in [PR 2291](https://github.com/gradio-app/gradio/pull/2291) This comes with deprecation of the following arguments for `Component.style`: `round`, `margin`, `border`.\\n6. Fix audio streaming, which was previously choppy in [PR 2351](https://github.com/gradio-app/gradio/pull/2351). Big thanks to [@yannickfunk](https://github.com/yannickfunk) for the proposed solution.\\n7. Fix bug where new typeable slider doesn\\'t respect the minimum and maximum values [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 2380](https://github.com/gradio-app/gradio/pull/2380)\\n\\n\\n## Documentation Changes:\\n\\n1. New Guide: Connecting to a Database 🗄️\\n\\n    A new guide by [@freddyaboulton](https://github.com/freddyaboulton) that explains how you can use Gradio to connect your app to a database. Read more [here](https://gradio.app/connecting_to_a_database/).\\n\\n2. New Guide: Running Background Tasks \\U0001f977\\n\\n    A new guide by', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='[@freddyaboulton](https://github.com/freddyaboulton) that explains how you can run background tasks from your gradio app. Read more [here](https://gradio.app/running_background_tasks/).\\n\\n3. Small fixes to docs for `Image` component by [@abidlabs](https://github.com/abidlabs) in [PR 2372](https://github.com/gradio-app/gradio/pull/2372)\\n\\n\\n## Testing and Infrastructure Changes:\\nNo changes to highlight.\\n\\n## Breaking Changes:\\nNo changes to highlight.\\n\\n## Full Changelog:\\n\\n* Create a guide on how to connect an app to a database hosted on the cloud by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2341](https://github.com/gradio-app/gradio/pull/2341)\\n* Removes `analytics` dependency by [@abidlabs](https://github.com/abidlabs) in [PR 2347](https://github.com/gradio-app/gradio/pull/2347)\\n* Add guide on launching background tasks from your app by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2350](https://github.com/gradio-app/gradio/pull/2350)\\n* Fix typo in guide image path by [@freddyaboulton](https://github.com/freddyaboulton) in [PR', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='2357](https://github.com/gradio-app/gradio/pull/2357)\\n* Raise error if Blocks has duplicate component with same IDs by [@abidlabs](https://github.com/abidlabs) in [PR 2359](https://github.com/gradio-app/gradio/pull/2359)\\n* Hotfix: fix version back to 3.4 by [@abidlabs](https://github.com/abidlabs) in [PR 2361](https://github.com/gradio-app/gradio/pull/2361)\\n* Change version.txt to 3.4 instead of 3.4.0 by [@aliabd](https://github.com/aliabd) in [PR 2363](https://github.com/gradio-app/gradio/pull/2363)\\n* Catch the permission exception on the audio component by [@Ian-GL](https://github.com/Ian-GL) in [PR 2330](https://github.com/gradio-app/gradio/pull/2330)\\n* Fix image_classifier_interface_load demo by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2365](https://github.com/gradio-app/gradio/pull/2365)\\n* Small fixes to docs for `Image` component by [@abidlabs](https://github.com/abidlabs) in [PR 2372](https://github.com/gradio-app/gradio/pull/2372)\\n* Automated Release Notes by [@freddyaboulton](https://github.com/freddyaboulton) in [PR', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content=\"2306](https://github.com/gradio-app/gradio/pull/2306)\\n* Fixed small typos in the docs [@julien-c](https://github.com/julien-c) in [PR 2373](https://github.com/gradio-app/gradio/pull/2373)\\n* Adds ability to disable pre/post-processing for examples [@abidlabs](https://github.com/abidlabs) in [PR 2383](https://github.com/gradio-app/gradio/pull/2383)\\n* Copy changelog file in website docker by [@aliabd](https://github.com/aliabd) in [PR 2384](https://github.com/gradio-app/gradio/pull/2384)\\n* Lets users provide a `gr.update()` dictionary even if post-processing is diabled [@abidlabs](https://github.com/abidlabs) in [PR 2385](https://github.com/gradio-app/gradio/pull/2385)\\n* Fix bug where errors would cause apps run in reload mode to hang forever by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2394](https://github.com/gradio-app/gradio/pull/2394)\\n* Fix bug where new typeable slider doesn't respect the minimum and maximum values [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 2380](https://github.com/gradio-app/gradio/pull/2380)\\n\\n\\n## Contributors Shoutout:\\nNo changes to\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='highlight.\\n\\n# Version 3.4\\n\\n## New Features:\\n\\n### 1. Gallery Captions 🖼️\\n\\nYou can now pass captions to images in the Gallery component. To do so you need to pass a {List} of (image, {str} caption) tuples. This is optional and the component also accepts just a list of the images.\\n\\nHere\\'s an example:\\n\\n```python\\nimport gradio as gr\\n\\nimages_with_captions = [\\n    (\"https://images.unsplash.com/photo-1551969014-7d2c4cddf0b6\", \"Cheetah by David Groves\"),\\n    (\"https://images.unsplash.com/photo-1546182990-dffeafbe841d\", \"Lion by Francesco\"),\\n    (\"https://images.unsplash.com/photo-1561731216-c3a4d99437d5\", \"Tiger by Mike Marrah\")\\n    ]\\n\\nwith gr.Blocks() as demo:\\n    gr.Gallery(value=images_with_captions)\\n\\ndemo.launch()\\n```\\n\\n<img src=\"https://user-images.githubusercontent.com/9021060/192399521-7360b1a9-7ce0-443e-8e94-863a230a7dbe.gif\" alt=\"gallery_captions\" width=\"1000\"/>\\n\\n### 2. Type Values into the Slider 🔢\\n\\nYou can now type values directly on the Slider component! Here\\'s what it looks like:\\n\\n![type-slider](https://user-images.githubusercontent.com/9021060/192399877-76b662a1-fede-4417-a932-fc15f0da7360.gif)\\n\\n### 3. Better', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content=\"Sketching and Inpainting 🎨\\n\\nWe've made a lot of changes to our Image component so that it can support better sketching and inpainting.\\n\\nNow supports:\\n* A standalone black-and-white sketch\\n```python\\nimport gradio as gr\\ndemo = gr.Interface(lambda x: x, gr.Sketchpad(), gr.Image())\\ndemo.launch()\\n```\\n![bw](https://user-images.githubusercontent.com/9021060/192410264-b08632b5-7b2a-4f86-afb0-5760e7b474cf.gif)\\n\\n\\n* A standalone color sketch\\n```python\\nimport gradio as gr\\ndemo = gr.Interface(lambda x: x, gr.Paint(), gr.Image())\\ndemo.launch()\\n```\\n![color-sketch](https://user-images.githubusercontent.com/9021060/192410500-3c8c3e64-a5fd-4df2-a991-f0a5cef93728.gif)\\n\\n\\n* An uploadable image with black-and-white or color sketching\\n\\n```python\\nimport gradio as gr\\ndemo = gr.Interface(lambda x: x, gr.Image(source='upload', tool='color-sketch'), gr.Image()) # for black and white, tool = 'sketch'\\ndemo.launch()\\n```\\n![sketch-new](https://user-images.githubusercontent.com/9021060/192402422-e53cb7b6-024e-448c-87eb-d6a35a63c476.gif)\\n\\n\\n* Webcam with black-and-white or color sketching\\n\\n```python\\nimport gradio as gr\\ndemo =\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content=\"gr.Interface(lambda x: x, gr.Image(source='webcam', tool='color-sketch'), gr.Image()) # for black and white, tool = 'sketch'\\ndemo.launch()\\n```\\n![webcam-sketch](https://user-images.githubusercontent.com/9021060/192410820-0ffaf324-776e-4e1f-9de6-0fdbbf4940fa.gif)\\n\\n\\nAs well as other fixes\\n\\n\\n## Bug Fixes:\\n1. Fix bug where max concurrency count is not respected in queue by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2286](https://github.com/gradio-app/gradio/pull/2286)\\n2. fix : queue could be blocked by [@SkyTNT](https://github.com/SkyTNT) in [PR 2288](https://github.com/gradio-app/gradio/pull/2288)\\n3. Supports `gr.update()` in example caching by [@abidlabs](https://github.com/abidlabs) in [PR 2309](https://github.com/gradio-app/gradio/pull/2309)\\n4. Clipboard fix for iframes by [@abidlabs](https://github.com/abidlabs) in [PR 2321](https://github.com/gradio-app/gradio/pull/2321)\\n5. Fix: Dataframe column headers are reset when you add a new column by [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 2318](https://github.com/gradio-app/gradio/pull/2318)\\n6. Added support for URLs\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='for Video, Audio, and Image by [@abidlabs](https://github.com/abidlabs) in [PR 2256](https://github.com/gradio-app/gradio/pull/2256)\\n7. Add documentation about how to create and use the Gradio FastAPI app by [@abidlabs](https://github.com/abidlabs) in [PR 2263](https://github.com/gradio-app/gradio/pull/2263)\\n\\n## Documentation Changes:\\n1. Adding a Playground Tab to the Website by [@aliabd](https://github.com/aliabd) in [PR 1860](https://github.com/gradio-app/gradio/pull/1860)\\n3. Gradio for Tabular Data Science Workflows Guide by [@merveenoyan](https://github.com/merveenoyan) in [PR 2199](https://github.com/gradio-app/gradio/pull/2199)\\n4. Promotes `postprocess` and `preprocess` to documented parameters by [@abidlabs](https://github.com/abidlabs) in [PR 2293](https://github.com/gradio-app/gradio/pull/2293)\\n5. Update 2)key_features.md by [@voidxd](https://github.com/voidxd) in [PR 2326](https://github.com/gradio-app/gradio/pull/2326)\\n6. Add docs to blocks context postprocessing function by [@Ian-GL](https://github.com/Ian-GL) in [PR 2332](https://github.com/gradio-app/gradio/pull/2332)\\n\\n##', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content=\"Testing and Infrastructure Changes\\n1. Website fixes and refactoring by [@aliabd](https://github.com/aliabd) in [PR 2280](https://github.com/gradio-app/gradio/pull/2280)\\n2. Don't deploy to spaces on release by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2313](https://github.com/gradio-app/gradio/pull/2313)\\n\\n## Full Changelog:\\n* Website fixes and refactoring by [@aliabd](https://github.com/aliabd) in [PR 2280](https://github.com/gradio-app/gradio/pull/2280)\\n* Fix bug where max concurrency count is not respected in queue by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2286](https://github.com/gradio-app/gradio/pull/2286)\\n* Promotes `postprocess` and `preprocess` to documented parameters by [@abidlabs](https://github.com/abidlabs) in [PR 2293](https://github.com/gradio-app/gradio/pull/2293)\\n* Raise warning when trying to cache examples but not all inputs have examples by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2279](https://github.com/gradio-app/gradio/pull/2279)\\n* fix : queue could be blocked by [@SkyTNT](https://github.com/SkyTNT) in [PR\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content=\"2288](https://github.com/gradio-app/gradio/pull/2288)\\n* Don't deploy to spaces on release by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2313](https://github.com/gradio-app/gradio/pull/2313)\\n* Supports `gr.update()` in example caching by [@abidlabs](https://github.com/abidlabs) in [PR 2309](https://github.com/gradio-app/gradio/pull/2309)\\n* Respect Upstream Queue when loading interfaces/blocks from Spaces by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2294](https://github.com/gradio-app/gradio/pull/2294)\\n* Clipboard fix for iframes by [@abidlabs](https://github.com/abidlabs) in [PR 2321](https://github.com/gradio-app/gradio/pull/2321)\\n* Sketching + Inpainting Capabilities to Gradio by [@abidlabs](https://github.com/abidlabs) in [PR 2144](https://github.com/gradio-app/gradio/pull/2144)\\n* Update 2)key_features.md by [@voidxd](https://github.com/voidxd) in [PR 2326](https://github.com/gradio-app/gradio/pull/2326)\\n* release 3.4b3 by [@abidlabs](https://github.com/abidlabs) in [PR 2328](https://github.com/gradio-app/gradio/pull/2328)\\n* Fix: Dataframe\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='column headers are reset when you add a new column by [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 2318](https://github.com/gradio-app/gradio/pull/2318)\\n* Start queue when gradio is a sub application by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2319](https://github.com/gradio-app/gradio/pull/2319)\\n* Fix Web Tracker Script by [@aliabd](https://github.com/aliabd) in [PR 2308](https://github.com/gradio-app/gradio/pull/2308)\\n* Add docs to blocks context postprocessing function by [@Ian-GL](https://github.com/Ian-GL) in [PR 2332](https://github.com/gradio-app/gradio/pull/2332)\\n* Fix typo in iterator variable name in run_predict function by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2340](https://github.com/gradio-app/gradio/pull/2340)\\n* Add captions to galleries by [@aliabid94](https://github.com/aliabid94) in [PR 2284](https://github.com/gradio-app/gradio/pull/2284)\\n* Typeable value on gradio.Slider by [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 2329](https://github.com/gradio-app/gradio/pull/2329)\\n\\n## Contributors Shoutout:\\n*', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='[@SkyTNT](https://github.com/SkyTNT) made their first contribution in [PR 2288](https://github.com/gradio-app/gradio/pull/2288)\\n* [@voidxd](https://github.com/voidxd) made their first contribution in [PR 2326](https://github.com/gradio-app/gradio/pull/2326)\\n\\n\\n# Version 3.3\\n\\n## New Features:\\n\\n### 1. Iterative Outputs ⏳\\n\\nYou can now create an iterative output simply by having your function return a generator!\\n\\nHere\\'s (part of) an example that was used to generate the interface below it. [See full code](https://colab.research.google.com/drive/1m9bWS6B82CT7bw-m4L6AJR8za7fEK7Ov?usp=sharing).\\n\\n```python\\ndef predict(steps, seed):\\n    generator = torch.manual_seed(seed)\\n    for i in range(1,steps):\\n        yield pipeline(generator=generator, num_inference_steps=i)[\"sample\"][0]\\n```\\n\\n\\n![example](https://user-images.githubusercontent.com/9021060/189086273-f5e7087d-71fa-4158-90a9-08e84da0421c.mp4)\\n\\n### 2. Accordion Layout 🆕\\n\\nThis version of Gradio introduces a new layout component to Blocks: the Accordion. Wrap your elements in a neat, expandable layout that allows users to toggle them as needed.\\n\\nUsage: ([Read the', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='docs](https://gradio.app/docs/#accordion))\\n\\n```python\\nwith gr.Accordion(\"open up\"):\\n# components here\\n```\\n\\n![accordion](https://user-images.githubusercontent.com/9021060/189088465-f0ffd7f0-fc6a-42dc-9249-11c5e1e0529b.gif)\\n\\n### 3. Skops Integration 📈\\n\\nOur new integration with [skops](https://huggingface.co/blog/skops) allows you to load tabular classification and regression models directly from the [hub](https://huggingface.co/models).\\n\\nHere\\'s a classification example showing how quick it is to set up an interface for a [model](https://huggingface.co/scikit-learn/tabular-playground).\\n\\n```python\\nimport gradio as gr\\ngr.Interface.load(\"models/scikit-learn/tabular-playground\").launch()\\n```\\n\\n![187936493-5c90c01d-a6dd-400f-aa42-833a096156a1](https://user-images.githubusercontent.com/9021060/189090519-328fbcb4-120b-43c8-aa54-d6fccfa6b7e8.png)\\n\\n\\n## Bug Fixes:\\nNo changes to highlight.\\n## Documentation Changes:\\nNo changes to highlight.\\n## Testing and Infrastructure Changes:\\nNo changes to highlight.\\n## Breaking Changes:\\nNo changes to highlight.\\n## Full Changelog:\\n\\n* safari fixes by', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content=\"[@pngwn](https://github.com/pngwn) in [PR 2138](https://github.com/gradio-app/gradio/pull/2138)\\n* Fix roundedness and form borders by [@aliabid94](https://github.com/aliabid94) in [PR 2147](https://github.com/gradio-app/gradio/pull/2147)\\n* Better processing of example data prior to creating dataset component by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2147](https://github.com/gradio-app/gradio/pull/2147)\\n* Show error on Connection drops by [@aliabid94](https://github.com/aliabid94) in [PR 2147](https://github.com/gradio-app/gradio/pull/2147)\\n* 3.2 release! by [@abidlabs](https://github.com/abidlabs) in [PR 2139](https://github.com/gradio-app/gradio/pull/2139)\\n* Fixed Named API Requests by [@abidlabs](https://github.com/abidlabs) in [PR 2151](https://github.com/gradio-app/gradio/pull/2151)\\n* Quick Fix: Cannot upload Model3D image after clearing it by [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 2168](https://github.com/gradio-app/gradio/pull/2168)\\n* Fixed misleading log when server_name is '0.0.0.0' by [@lamhoangtung](https://github.com/lamhoangtung) in [PR\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='2176](https://github.com/gradio-app/gradio/pull/2176)\\n* Keep embedded PngInfo metadata by [@cobryan05](https://github.com/cobryan05) in [PR 2170](https://github.com/gradio-app/gradio/pull/2170)\\n* Skops integration: Load tabular classification and regression models from the hub by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2126](https://github.com/gradio-app/gradio/pull/2126)\\n* Respect original filename when cached example files are downloaded by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2145](https://github.com/gradio-app/gradio/pull/2145)\\n* Add manual trigger to deploy to pypi by [@abidlabs](https://github.com/abidlabs) in [PR 2192](https://github.com/gradio-app/gradio/pull/2192)\\n* Fix bugs with gr.update by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2157](https://github.com/gradio-app/gradio/pull/2157)\\n* Make queue per app by [@aliabid94](https://github.com/aliabid94) in [PR 2193](https://github.com/gradio-app/gradio/pull/2193)\\n* Preserve Labels In Interpretation Components by [@freddyaboulton](https://github.com/freddyaboulton)', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content=\"in [PR 2166](https://github.com/gradio-app/gradio/pull/2166)\\n* Quick Fix: Multiple file download not working by [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 2169](https://github.com/gradio-app/gradio/pull/2169)\\n* use correct MIME type for js-script file by [@daspartho](https://github.com/daspartho) in [PR 2200](https://github.com/gradio-app/gradio/pull/2200)\\n* Add accordion component by [@aliabid94](https://github.com/aliabid94) in [PR 2208](https://github.com/gradio-app/gradio/pull/2208)\\n\\n\\n## Contributors Shoutout:\\n\\n* [@lamhoangtung](https://github.com/lamhoangtung) made their first contribution in [PR 2176](https://github.com/gradio-app/gradio/pull/2176)\\n* [@cobryan05](https://github.com/cobryan05) made their first contribution in [PR 2170](https://github.com/gradio-app/gradio/pull/2170)\\n* [@daspartho](https://github.com/daspartho) made their first contribution in [PR 2200](https://github.com/gradio-app/gradio/pull/2200)\\n\\n# Version 3.2\\n\\n## New Features:\\n\\n### 1. Improvements to Queuing 🥇\\n\\nWe've implemented a brand new queuing system based on **web sockets** instead of HTTP long\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='polling. Among other things, this allows us to manage queue sizes better on Hugging Face Spaces. There are also additional queue-related parameters you can add:\\n\\n* Now supports concurrent workers (parallelization)\\n```python\\ndemo = gr.Interface(...)\\ndemo.queue(concurrency_count=3)\\ndemo.launch()\\n```\\n* Configure a maximum queue size\\n```python\\ndemo = gr.Interface(...)\\ndemo.queue(max_size=100)\\ndemo.launch()\\n```\\n\\n* If a user closes their tab / browser, they leave the queue, which means the demo will run faster for everyone else\\n\\n### 2. Fixes to Examples\\n\\n* Dataframe examples will render properly, and look much clearer in the UI: (thanks to PR #2125)\\n\\n![Screen Shot 2022-08-30 at 8 29 58 PM](https://user-images.githubusercontent.com/9021060/187586561-d915bafb-f968-4966-b9a2-ef41119692b2.png)\\n\\n* Image and Video thumbnails are cropped to look neater and more uniform: (thanks to PR #2109)\\n\\n\\n![Screen Shot 2022-08-30 at 8 32 15 PM](https://user-images.githubusercontent.com/9021060/187586890-56e1e4f0-1b84-42d9-a82f-911772c41030.png)\\n\\n* Other fixes in PR #2131 and #2064  make it easier to design and use Examples\\n\\n### 3. Component Fixes 🧱\\n* Specify the', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='width and height of an image in its style tag (thanks to PR #2133)\\n```python\\ncomponents.Image().style(height=260, width=300)\\n```\\n* Automatic conversion of videos so they are playable in the browser (thanks to PR #2003). Gradio will check if a video\\'s format is playable  in the browser and, if it isn\\'t, will automatically convert it to a format that is (mp4).\\n* Pass in a json filepath to the Label component (thanks to PR #2083)\\n* Randomize the default value of a Slider (thanks to PR #1935)\\n\\n![slider-random](https://user-images.githubusercontent.com/9021060/187596230-3db9697f-9f4d-42f5-9387-d77573513448.gif)\\n\\n\\n* Improvements to State in PR #2100\\n\\n### 4. Ability to Randomize Input Sliders and Reload Data whenever the Page Loads\\n* In some cases, you want to be able to show a different set of input data to every user as they load the page app. For example, you might want to randomize the value of a \"seed\" `Slider` input. Or you might want to show a `Textbox` with the current date. We now supporting passing _functions_ as the default value in input components. When you pass in a function, it gets **re-evaluated** every time someone loads the demo, allowing you to reload / change data for', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='different users.\\n\\nHere\\'s an example loading the current date time into an input Textbox:\\n\\n```python\\nimport gradio as gr\\nimport datetime\\n\\nwith gr.Blocks() as demo:\\n    gr.Textbox(datetime.datetime.now)\\n\\ndemo.launch()\\n```\\n\\nNote that we don\\'t evaluate the function -- `datetime.datetime.now()` -- we pass in the function itself to get this behavior -- `datetime.datetime.now`\\n\\nBecause randomizing the initial value of `Slider` is a common use case, we\\'ve added a `randomize` keyword argument you can use to randomize its initial value:\\n\\n```python\\nimport gradio as gr\\ndemo = gr.Interface(lambda x:x, gr.Slider(0, 10, randomize=True), \"number\")\\ndemo.launch()\\n```\\n\\n### 5. New Guide 🖊️\\n* [Gradio and W&B Integration](https://gradio.app/Gradio_and_Wandb_Integration/)\\n\\n\\n## Full Changelog:\\n\\n* Reset components to original state by setting value to None by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2044](https://github.com/gradio-app/gradio/pull/2044)\\n* Cleaning up the way data is processed for components by [@abidlabs](https://github.com/abidlabs) in [PR 1967](https://github.com/gradio-app/gradio/pull/1967)\\n* version 3.1.8b by', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='[@abidlabs](https://github.com/abidlabs) in [PR 2063](https://github.com/gradio-app/gradio/pull/2063)\\n* Wandb guide  by [@AK391](https://github.com/AK391) in [PR 1898](https://github.com/gradio-app/gradio/pull/1898)\\n* Add a flagging callback to save json files to a hugging face dataset by [@chrisemezue](https://github.com/chrisemezue) in [PR 1821](https://github.com/gradio-app/gradio/pull/1821)\\n* Add data science demos to landing page by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2067](https://github.com/gradio-app/gradio/pull/2067)\\n* Hide time series + xgboost demos by default by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2079](https://github.com/gradio-app/gradio/pull/2079)\\n* Encourage people to keep trying when queue full by [@apolinario](https://github.com/apolinario) in [PR 2076](https://github.com/gradio-app/gradio/pull/2076)\\n* Updated our analytics on creation of Blocks/Interface by [@abidlabs](https://github.com/abidlabs) in [PR 2082](https://github.com/gradio-app/gradio/pull/2082)\\n* `Label` component now accepts file paths to `.json` files  by', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='[@abidlabs](https://github.com/abidlabs) in [PR 2083](https://github.com/gradio-app/gradio/pull/2083)\\n* Fix issues related to demos in Spaces by [@abidlabs](https://github.com/abidlabs) in [PR 2086](https://github.com/gradio-app/gradio/pull/2086)\\n* Fix TimeSeries examples not properly displayed in UI by [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 2064](https://github.com/gradio-app/gradio/pull/2064)\\n* Fix infinite requests when doing tab item select by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 2070](https://github.com/gradio-app/gradio/pull/2070)\\n* Accept deprecated `file` route as well by [@abidlabs](https://github.com/abidlabs) in [PR 2099](https://github.com/gradio-app/gradio/pull/2099)\\n* Allow frontend method execution on Block.load event by [@codedealer](https://github.com/codedealer) in [PR 2108](https://github.com/gradio-app/gradio/pull/2108)\\n* Improvements to `State` by [@abidlabs](https://github.com/abidlabs) in [PR 2100](https://github.com/gradio-app/gradio/pull/2100)\\n* Catch IndexError, KeyError in video_is_playable by', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='[@freddyaboulton](https://github.com/freddyaboulton) in [PR 2113](https://github.com/gradio-app/gradio/pull/2113)\\n* Fix: Download button does not respect the filepath returned by the function by [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 2073](https://github.com/gradio-app/gradio/pull/2073)\\n* Refactoring Layout: Adding column widths, forms, and more. by [@aliabid94](https://github.com/aliabid94) in [PR 2097](https://github.com/gradio-app/gradio/pull/2097)\\n* Update CONTRIBUTING.md by [@abidlabs](https://github.com/abidlabs) in [PR 2118](https://github.com/gradio-app/gradio/pull/2118)\\n* 2092 df ex by [@pngwn](https://github.com/pngwn) in [PR 2125](https://github.com/gradio-app/gradio/pull/2125)\\n* feat(samples table/gallery): Crop thumbs to square by [@ronvoluted](https://github.com/ronvoluted) in [PR 2109](https://github.com/gradio-app/gradio/pull/2109)\\n* Some enhancements to `gr.Examples` by [@abidlabs](https://github.com/abidlabs) in [PR 2131](https://github.com/gradio-app/gradio/pull/2131)\\n* Image size fix by [@aliabid94](https://github.com/aliabid94) in [PR', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='2133](https://github.com/gradio-app/gradio/pull/2133)\\n\\n## Contributors Shoutout:\\n* [@chrisemezue](https://github.com/chrisemezue) made their first contribution in [PR 1821](https://github.com/gradio-app/gradio/pull/1821)\\n* [@apolinario](https://github.com/apolinario) made their first contribution in [PR 2076](https://github.com/gradio-app/gradio/pull/2076)\\n* [@codedealer](https://github.com/codedealer) made their first contribution in [PR 2108](https://github.com/gradio-app/gradio/pull/2108)\\n\\n# Version 3.1\\n\\n## New Features:\\n\\n### 1.  Embedding Demos on Any Website 💻\\n\\nWith PR #1444, Gradio is now distributed as a web component. This means demos can be natively embedded on websites. You\\'ll just need to add two lines: one to load the gradio javascript, and one to link to the demos backend.\\n\\nHere\\'s a simple example that embeds the demo from a Hugging Face space:\\n\\n```html\\n<script type=\"module\" src=\"https://gradio.s3-us-west-2.amazonaws.com/3.0.18/gradio.js\"></script>\\n<gradio-app space=\"abidlabs/pytorch-image-classifier\"></gradio-app>\\n```\\n\\nBut you can also embed demos that are running anywhere, you just need to link the', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='demo to `src` instead of `space`. In fact, all the demos on the gradio website are embedded this way:\\n\\n<img width=\"1268\" alt=\"Screen Shot 2022-07-14 at 2 41 44 PM\" src=\"https://user-images.githubusercontent.com/9021060/178997124-b2f05af2-c18f-4716-bf1b-cb971d012636.png\">\\n\\n\\nRead more in the [Embedding Gradio Demos](https://gradio.app/embedding_gradio_demos) guide.\\n\\n### 2. Reload Mode 👨\\u200d💻\\n\\nReload mode helps developers create gradio demos faster by automatically reloading the demo whenever the code changes. It can support development on Python IDEs (VS Code, PyCharm, etc), the terminal, as well as Jupyter notebooks.\\n\\nIf your demo code is in a script named `app.py`, instead of running `python app.py` you can now run `gradio app.py` and that will launch the demo in reload mode:\\n\\n```bash\\nLaunching in reload mode on: http://127.0.0.1:7860 (Press CTRL+C to quit)\\nWatching...\\nWARNING: The --reload flag should not be used in production on Windows.\\n```\\n\\nIf you\\'re working from a Jupyter or Colab Notebook, use these magic commands instead: `%load_ext gradio` when you import gradio, and `%%blocks` in the top of the cell with the demo code. Here\\'s an example that shows how much', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='faster the development becomes:\\n\\n![Blocks](https://user-images.githubusercontent.com/9021060/178986488-ed378cc8-5141-4330-ba41-672b676863d0.gif)\\n\\n### 3. Inpainting Support on `gr.Image()` 🎨\\n\\nWe updated the Image component to add support for inpainting demos. It works by adding `tool=\"sketch\"` as a parameter, that passes both an image and a sketchable mask to your prediction function.\\n\\nHere\\'s an example from the [LAMA space](https://huggingface.co/spaces/akhaliq/lama):\\n\\n![FXApVlFVsAALSD-](https://user-images.githubusercontent.com/9021060/178989479-549867c8-7fb0-436a-a97d-1e91c9f5e611.jpeg)\\n\\n### 4. Markdown and HTML support in Dataframes 🔢\\n\\nWe upgraded the Dataframe component in PR #1684 to support rendering Markdown and HTML inside the cells.\\n\\nThis means you can build Dataframes that look like the following:\\n\\n![image (8)](https://user-images.githubusercontent.com/9021060/178991233-41cb07a5-e7a3-433e-89b8-319bc78eb9c2.png)\\n\\n\\n### 5. `gr.Examples()` for Blocks 🧱\\n\\nWe\\'ve added the `gr.Examples` component helper to allow you to add examples to any Blocks demo. This class is a wrapper over the `gr.Dataset` component.\\n\\n<img', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='width=\"1271\" alt=\"Screen Shot 2022-07-14 at 2 23 50 PM\" src=\"https://user-images.githubusercontent.com/9021060/178992715-c8bc7550-bc3d-4ddc-9fcb-548c159cd153.png\">\\n\\n\\ngr.Examples takes two required parameters:\\n\\n- `examples` which takes in a nested list\\n-  `inputs` which takes in a component or list of components\\n\\nYou can read more in the [Examples docs](https://gradio.app/docs/#examples) or the [Adding Examples to your Demos guide](https://gradio.app/adding_examples_to_your_app/).\\n\\n### 6. Fixes to Audio Streaming\\n\\nWith [PR 1828](https://github.com/gradio-app/gradio/pull/1828) we now hide the status loading animation, as well as remove the echo in streaming. Check out the [stream_audio](https://github.com/gradio-app/gradio/blob/main/demo/stream_audio/run.py) demo for more or read through our [Real Time Speech Recognition](https://gradio.app/real_time_speech_recognition/) guide.\\n\\n<img width=\"785\" alt=\"Screen Shot 2022-07-19 at 6 02 35 PM\" src=\"https://user-images.githubusercontent.com/9021060/179808136-9e84502c-f9ee-4f30-b5e9-1086f678fe91.png\">\\n\\n\\n## Full Changelog:\\n\\n* File component: list multiple files and', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='allow for download #1446 by [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 1681](https://github.com/gradio-app/gradio/pull/1681)\\n* Add ColorPicker to docs by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 1768](https://github.com/gradio-app/gradio/pull/1768)\\n* Mock out requests in TestRequest unit tests by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 1794](https://github.com/gradio-app/gradio/pull/1794)\\n* Add requirements.txt and test_files to source dist by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 1817](https://github.com/gradio-app/gradio/pull/1817)\\n* refactor: f-string for tunneling.py by [@nhankiet](https://github.com/nhankiet) in [PR 1819](https://github.com/gradio-app/gradio/pull/1819)\\n* Miscellaneous formatting improvements to website by [@aliabd](https://github.com/aliabd) in [PR 1754](https://github.com/gradio-app/gradio/pull/1754)\\n* `integrate()` method moved to `Blocks` by [@abidlabs](https://github.com/abidlabs) in [PR 1776](https://github.com/gradio-app/gradio/pull/1776)\\n* Add python-3.7 tests by', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='[@freddyaboulton](https://github.com/freddyaboulton) in [PR 1818](https://github.com/gradio-app/gradio/pull/1818)\\n* Copy test dir in website dockers by [@aliabd](https://github.com/aliabd) in [PR 1827](https://github.com/gradio-app/gradio/pull/1827)\\n* Add info to docs on how to set default values for components by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 1788](https://github.com/gradio-app/gradio/pull/1788)\\n* Embedding Components on Docs by [@aliabd](https://github.com/aliabd) in [PR 1726](https://github.com/gradio-app/gradio/pull/1726)\\n* Remove usage of deprecated gr.inputs and gr.outputs from website by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 1796](https://github.com/gradio-app/gradio/pull/1796)\\n* Some cleanups to the docs page by [@abidlabs](https://github.com/abidlabs) in [PR 1822](https://github.com/gradio-app/gradio/pull/1822)\\n\\n## Contributors Shoutout:\\n* [@nhankiet](https://github.com/nhankiet) made their first contribution in [PR 1819](https://github.com/gradio-app/gradio/pull/1819)\\n\\n# Version 3.0\\n\\n### 🔥 Gradio 3.0 is the biggest update to the', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='library, ever.\\n\\n## New Features:\\n\\n### 1.  Blocks 🧱\\n\\nBlocks is a new, low-level API that allows you to have full control over the data flows and layout of your application. It allows you to build very complex, multi-step applications. For example, you might want to:\\n\\n* Group together related demos as multiple tabs in one web app\\n* Change the layout of your demo instead of just having all of the inputs on the left and outputs on the right\\n* Have multi-step interfaces, in which the output of one model becomes the input to the next model, or have more flexible data flows in general\\n* Change a component\\'s properties (for example, the choices in a Dropdown) or its visibility based on user input\\n\\nHere\\'s a simple example that creates the demo below it:\\n\\n```python\\nimport gradio as gr\\n\\ndef update(name):\\n    return f\"Welcome to Gradio, {name}!\"\\n\\ndemo = gr.Blocks()\\n\\nwith demo:\\n    gr.Markdown(\\n    \"\"\"\\n    # Hello World!\\n    Start typing below to see the output.\\n    \"\"\")\\n    inp = gr.Textbox(placeholder=\"What is your name?\")\\n    out = gr.Textbox()\\n\\n    inp.change(fn=update,\\n               inputs=inp,\\n              ', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content=\"              outputs=out)\\n\\ndemo.launch()\\n```\\n\\n![hello-blocks](https://user-images.githubusercontent.com/9021060/168684108-78cbd24b-e6bd-4a04-a8d9-20d535203434.gif)\\n\\n\\nRead our [Introduction to Blocks](http://gradio.app/introduction_to_blocks/) guide for more, and join the 🎈 [Gradio Blocks Party](https://huggingface.co/spaces/Gradio-Blocks/README)!\\n\\n\\n### 2. Our Revamped Design 🎨\\n\\nWe've upgraded our design across the entire library: from components, and layouts all the way to dark mode.\\n\\n![kitchen_sink](https://user-images.githubusercontent.com/9021060/168686333-7a6e3096-3e23-4309-abf2-5cd7736e0463.gif)\\n\\n\\n### 3. A New Website 💻\\n\\nWe've upgraded [gradio.app](https://gradio.app) to make it cleaner, faster and easier to use. Our docs now come with components and demos embedded directly on the page. So you can quickly get up to speed with what you're looking for.\\n\\n![website](https://user-images.githubusercontent.com/9021060/168687191-10d6a3bd-101f-423a-8193-48f47a5e077d.gif)\\n\\n\\n### 4. New Components: Model3D, Dataset, and More..\\n\\nWe've introduced a lot of new components in `3.0`, including `Model3D`, `Dataset`, `Markdown`,\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='`Button` and `Gallery`. You can find all the components and play around with them [here](https://gradio.app/docs/#components).\\n\\n\\n![Model3d](https://user-images.githubusercontent.com/9021060/168689062-6ad77151-8cc5-467d-916c-f7c78e52ec0c.gif)\\n\\n## Full Changelog:\\n\\n* Gradio dash fe by [@pngwn](https://github.com/pngwn) in [PR 807](https://github.com/gradio-app/gradio/pull/807)\\n* Blocks components by [@FarukOzderim](https://github.com/FarukOzderim) in [PR 765](https://github.com/gradio-app/gradio/pull/765)\\n* Blocks components V2 by [@FarukOzderim](https://github.com/FarukOzderim) in [PR 843](https://github.com/gradio-app/gradio/pull/843)\\n* Blocks-Backend-Events by [@FarukOzderim](https://github.com/FarukOzderim) in [PR 844](https://github.com/gradio-app/gradio/pull/844)\\n* Interfaces from Blocks by [@aliabid94](https://github.com/aliabid94) in [PR 849](https://github.com/gradio-app/gradio/pull/849)\\n* Blocks dev by [@aliabid94](https://github.com/aliabid94) in [PR 853](https://github.com/gradio-app/gradio/pull/853)\\n* Started updating demos to use the new `gradio.components` syntax', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='by [@abidlabs](https://github.com/abidlabs) in [PR 848](https://github.com/gradio-app/gradio/pull/848)\\n* add test infra + add browser tests to CI by [@pngwn](https://github.com/pngwn) in [PR 852](https://github.com/gradio-app/gradio/pull/852)\\n* 854 textbox by [@pngwn](https://github.com/pngwn) in [PR 859](https://github.com/gradio-app/gradio/pull/859)\\n* Getting old Python unit tests to pass on `blocks-dev` by [@abidlabs](https://github.com/abidlabs) in [PR 861](https://github.com/gradio-app/gradio/pull/861)\\n* initialise chatbot with empty array of messages by [@pngwn](https://github.com/pngwn) in [PR 867](https://github.com/gradio-app/gradio/pull/867)\\n* add test for output to input by [@pngwn](https://github.com/pngwn) in [PR 866](https://github.com/gradio-app/gradio/pull/866)\\n* More Interface -> Blocks features by [@aliabid94](https://github.com/aliabid94) in [PR 864](https://github.com/gradio-app/gradio/pull/864)\\n* Fixing external.py in blocks-dev to reflect the new HF Spaces paths by [@abidlabs](https://github.com/abidlabs) in [PR 879](https://github.com/gradio-app/gradio/pull/879)\\n*', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='backend_default_value_refactoring by [@FarukOzderim](https://github.com/FarukOzderim) in [PR 871](https://github.com/gradio-app/gradio/pull/871)\\n* fix default_value  by [@pngwn](https://github.com/pngwn) in [PR 869](https://github.com/gradio-app/gradio/pull/869)\\n* fix buttons by [@aliabid94](https://github.com/aliabid94) in [PR 883](https://github.com/gradio-app/gradio/pull/883)\\n* Checking and updating more demos to use 3.0 syntax by [@abidlabs](https://github.com/abidlabs) in [PR 892](https://github.com/gradio-app/gradio/pull/892)\\n* Blocks Tests by [@FarukOzderim](https://github.com/FarukOzderim) in [PR 902](https://github.com/gradio-app/gradio/pull/902)\\n* Interface fix by [@pngwn](https://github.com/pngwn) in [PR 901](https://github.com/gradio-app/gradio/pull/901)\\n* Quick fix: Issue 893 by [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 907](https://github.com/gradio-app/gradio/pull/907)\\n* 3d Image Component by [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 775](https://github.com/gradio-app/gradio/pull/775)\\n* fix endpoint url in prod by', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='[@pngwn](https://github.com/pngwn) in [PR 911](https://github.com/gradio-app/gradio/pull/911)\\n* rename Model3d to Image3D by [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 912](https://github.com/gradio-app/gradio/pull/912)\\n* update pypi to 2.9.1 by [@abidlabs](https://github.com/abidlabs) in [PR 916](https://github.com/gradio-app/gradio/pull/916)\\n* blocks-with-fix by [@FarukOzderim](https://github.com/FarukOzderim) in [PR 917](https://github.com/gradio-app/gradio/pull/917)\\n* Restore Interpretation, Live, Auth, Queueing by [@aliabid94](https://github.com/aliabid94) in [PR 915](https://github.com/gradio-app/gradio/pull/915)\\n* Allow `Blocks` instances to be used like a `Block` in other `Blocks` by [@abidlabs](https://github.com/abidlabs) in [PR 919](https://github.com/gradio-app/gradio/pull/919)\\n* Redesign 1 by [@pngwn](https://github.com/pngwn) in [PR 918](https://github.com/gradio-app/gradio/pull/918)\\n* blocks-components-tests by [@FarukOzderim](https://github.com/FarukOzderim) in [PR 904](https://github.com/gradio-app/gradio/pull/904)\\n* fix unit + browser tests by', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='[@pngwn](https://github.com/pngwn) in [PR 926](https://github.com/gradio-app/gradio/pull/926)\\n* blocks-move-test-data by [@FarukOzderim](https://github.com/FarukOzderim) in [PR 927](https://github.com/gradio-app/gradio/pull/927)\\n* remove debounce from form inputs by [@pngwn](https://github.com/pngwn) in [PR 932](https://github.com/gradio-app/gradio/pull/932)\\n* reimplement webcam video by [@pngwn](https://github.com/pngwn) in [PR 928](https://github.com/gradio-app/gradio/pull/928)\\n* blocks-move-test-data by [@FarukOzderim](https://github.com/FarukOzderim) in [PR 941](https://github.com/gradio-app/gradio/pull/941)\\n* allow audio components to take a string value by [@pngwn](https://github.com/pngwn) in [PR 930](https://github.com/gradio-app/gradio/pull/930)\\n* static mode for textbox by [@pngwn](https://github.com/pngwn) in [PR 929](https://github.com/gradio-app/gradio/pull/929)\\n* fix file upload text by [@pngwn](https://github.com/pngwn) in [PR 931](https://github.com/gradio-app/gradio/pull/931)\\n* tabbed-interface-rewritten by [@FarukOzderim](https://github.com/FarukOzderim) in', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='[PR 958](https://github.com/gradio-app/gradio/pull/958)\\n* Gan demo fix by [@abidlabs](https://github.com/abidlabs) in [PR 965](https://github.com/gradio-app/gradio/pull/965)\\n* Blocks analytics by [@abidlabs](https://github.com/abidlabs) in [PR 947](https://github.com/gradio-app/gradio/pull/947)\\n* Blocks page load by [@FarukOzderim](https://github.com/FarukOzderim) in [PR 963](https://github.com/gradio-app/gradio/pull/963)\\n* add frontend for page load events by [@pngwn](https://github.com/pngwn) in [PR 967](https://github.com/gradio-app/gradio/pull/967)\\n* fix i18n and some tweaks by [@pngwn](https://github.com/pngwn) in [PR 966](https://github.com/gradio-app/gradio/pull/966)\\n* add jinja2 to reqs by [@FarukOzderim](https://github.com/FarukOzderim) in [PR 969](https://github.com/gradio-app/gradio/pull/969)\\n* Cleaning up `Launchable()` by [@abidlabs](https://github.com/abidlabs) in [PR 968](https://github.com/gradio-app/gradio/pull/968)\\n* Fix #944 by [@FarukOzderim](https://github.com/FarukOzderim) in [PR 971](https://github.com/gradio-app/gradio/pull/971)\\n* New Blocks Demo: neural', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='instrument cloning by [@abidlabs](https://github.com/abidlabs) in [PR 975](https://github.com/gradio-app/gradio/pull/975)\\n* Add huggingface_hub client library by [@FarukOzderim](https://github.com/FarukOzderim) in [PR 973](https://github.com/gradio-app/gradio/pull/973)\\n* State and variables by [@aliabid94](https://github.com/aliabid94) in [PR 977](https://github.com/gradio-app/gradio/pull/977)\\n* update-components by [@FarukOzderim](https://github.com/FarukOzderim) in [PR 986](https://github.com/gradio-app/gradio/pull/986)\\n* ensure dataframe updates as expected by [@pngwn](https://github.com/pngwn) in [PR 981](https://github.com/gradio-app/gradio/pull/981)\\n* test-guideline by [@FarukOzderim](https://github.com/FarukOzderim) in [PR 990](https://github.com/gradio-app/gradio/pull/990)\\n* Issue #785: add footer by [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 972](https://github.com/gradio-app/gradio/pull/972)\\n* indentation fix by [@abidlabs](https://github.com/abidlabs) in [PR 993](https://github.com/gradio-app/gradio/pull/993)\\n* missing quote by', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='[@aliabd](https://github.com/aliabd) in [PR 996](https://github.com/gradio-app/gradio/pull/996)\\n* added interactive parameter to components by [@abidlabs](https://github.com/abidlabs) in [PR 992](https://github.com/gradio-app/gradio/pull/992)\\n* custom-components by [@FarukOzderim](https://github.com/FarukOzderim) in [PR 985](https://github.com/gradio-app/gradio/pull/985)\\n* Refactor component shortcuts by [@FarukOzderim](https://github.com/FarukOzderim) in [PR 995](https://github.com/gradio-app/gradio/pull/995)\\n* Plot Component by [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 805](https://github.com/gradio-app/gradio/pull/805)\\n* updated PyPi version to 2.9.2 by [@abidlabs](https://github.com/abidlabs) in [PR 1002](https://github.com/gradio-app/gradio/pull/1002)\\n* Release 2.9.3 by [@abidlabs](https://github.com/abidlabs) in [PR 1003](https://github.com/gradio-app/gradio/pull/1003)\\n* Image3D Examples Fix by [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 1001](https://github.com/gradio-app/gradio/pull/1001)\\n* release 2.9.4 by', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='[@abidlabs](https://github.com/abidlabs) in [PR 1006](https://github.com/gradio-app/gradio/pull/1006)\\n* templates import hotfix by [@FarukOzderim](https://github.com/FarukOzderim) in [PR 1008](https://github.com/gradio-app/gradio/pull/1008)\\n* Progress indicator bar by [@aliabid94](https://github.com/aliabid94) in [PR 997](https://github.com/gradio-app/gradio/pull/997)\\n* Fixed image input for absolute path by [@JefferyChiang](https://github.com/JefferyChiang) in [PR 1004](https://github.com/gradio-app/gradio/pull/1004)\\n* Model3D + Plot Components by [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 1010](https://github.com/gradio-app/gradio/pull/1010)\\n* Gradio Guides: Creating CryptoPunks with GANs by [@NimaBoscarino](https://github.com/NimaBoscarino) in [PR 1000](https://github.com/gradio-app/gradio/pull/1000)\\n* [BIG PR] Gradio blocks & redesigned components by [@abidlabs](https://github.com/abidlabs) in [PR 880](https://github.com/gradio-app/gradio/pull/880)\\n* fixed failing test on main by [@abidlabs](https://github.com/abidlabs) in [PR', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='1023](https://github.com/gradio-app/gradio/pull/1023)\\n* Use smaller ASR model in external test by [@abidlabs](https://github.com/abidlabs) in [PR 1024](https://github.com/gradio-app/gradio/pull/1024)\\n* updated PyPi version to 2.9.0b by [@abidlabs](https://github.com/abidlabs) in [PR 1026](https://github.com/gradio-app/gradio/pull/1026)\\n* Fixing import issues so that the package successfully installs on colab notebooks by [@abidlabs](https://github.com/abidlabs) in [PR 1027](https://github.com/gradio-app/gradio/pull/1027)\\n* Update website tracker slackbot  by [@aliabd](https://github.com/aliabd) in [PR 1037](https://github.com/gradio-app/gradio/pull/1037)\\n* textbox-autoheight by [@FarukOzderim](https://github.com/FarukOzderim) in [PR 1009](https://github.com/gradio-app/gradio/pull/1009)\\n* Model3D Examples fixes by [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 1035](https://github.com/gradio-app/gradio/pull/1035)\\n* GAN Gradio Guide: Adjustments to iframe heights by [@NimaBoscarino](https://github.com/NimaBoscarino) in [PR', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='1042](https://github.com/gradio-app/gradio/pull/1042)\\n* added better default labels to form components by [@abidlabs](https://github.com/abidlabs) in [PR 1040](https://github.com/gradio-app/gradio/pull/1040)\\n* Slackbot web tracker fix by [@aliabd](https://github.com/aliabd) in [PR 1043](https://github.com/gradio-app/gradio/pull/1043)\\n* Plot fixes by [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 1044](https://github.com/gradio-app/gradio/pull/1044)\\n* Small fixes to the demos by [@abidlabs](https://github.com/abidlabs) in [PR 1030](https://github.com/gradio-app/gradio/pull/1030)\\n* fixing demo issue with website by [@aliabd](https://github.com/aliabd) in [PR 1047](https://github.com/gradio-app/gradio/pull/1047)\\n* [hotfix] HighlightedText by [@aliabid94](https://github.com/aliabid94) in [PR 1046](https://github.com/gradio-app/gradio/pull/1046)\\n* Update text by [@ronvoluted](https://github.com/ronvoluted) in [PR 1050](https://github.com/gradio-app/gradio/pull/1050)\\n* Update CONTRIBUTING.md by [@FarukOzderim](https://github.com/FarukOzderim) in [PR', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='1052](https://github.com/gradio-app/gradio/pull/1052)\\n* fix(ui): Increase contrast for footer by [@ronvoluted](https://github.com/ronvoluted) in [PR 1048](https://github.com/gradio-app/gradio/pull/1048)\\n* UI design update by [@gary149](https://github.com/gary149) in [PR 1041](https://github.com/gradio-app/gradio/pull/1041)\\n* updated PyPi version to 2.9.0b8 by [@abidlabs](https://github.com/abidlabs) in [PR 1059](https://github.com/gradio-app/gradio/pull/1059)\\n* Running, testing, and fixing demos by [@abidlabs](https://github.com/abidlabs) in [PR 1060](https://github.com/gradio-app/gradio/pull/1060)\\n* Form layout by [@pngwn](https://github.com/pngwn) in [PR 1054](https://github.com/gradio-app/gradio/pull/1054)\\n* inputless-interfaces by [@FarukOzderim](https://github.com/FarukOzderim) in [PR 1038](https://github.com/gradio-app/gradio/pull/1038)\\n* Update PULL_REQUEST_TEMPLATE.md by [@FarukOzderim](https://github.com/FarukOzderim) in [PR 1068](https://github.com/gradio-app/gradio/pull/1068)\\n* Upgrading node memory to 4gb in website Docker by [@aliabd](https://github.com/aliabd)', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='in [PR 1069](https://github.com/gradio-app/gradio/pull/1069)\\n* Website reload error by [@aliabd](https://github.com/aliabd) in [PR 1079](https://github.com/gradio-app/gradio/pull/1079)\\n* fixed favicon issue by [@abidlabs](https://github.com/abidlabs) in [PR 1064](https://github.com/gradio-app/gradio/pull/1064)\\n* remove-queue-from-events by [@FarukOzderim](https://github.com/FarukOzderim) in [PR 1056](https://github.com/gradio-app/gradio/pull/1056)\\n* Enable vertex colors for OBJs files by [@radames](https://github.com/radames) in [PR 1074](https://github.com/gradio-app/gradio/pull/1074)\\n* Dark text by [@ronvoluted](https://github.com/ronvoluted) in [PR 1049](https://github.com/gradio-app/gradio/pull/1049)\\n* Scroll to output by [@pngwn](https://github.com/pngwn) in [PR 1077](https://github.com/gradio-app/gradio/pull/1077)\\n* Explicitly list pnpm version 6 in contributing guide by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 1085](https://github.com/gradio-app/gradio/pull/1085)\\n* hotfix for encrypt issue by [@abidlabs](https://github.com/abidlabs) in [PR', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='1096](https://github.com/gradio-app/gradio/pull/1096)\\n* Release 2.9b9 by [@abidlabs](https://github.com/abidlabs) in [PR 1098](https://github.com/gradio-app/gradio/pull/1098)\\n* tweak node circleci settings by [@pngwn](https://github.com/pngwn) in [PR 1091](https://github.com/gradio-app/gradio/pull/1091)\\n* Website Reload Error by [@aliabd](https://github.com/aliabd) in [PR 1099](https://github.com/gradio-app/gradio/pull/1099)\\n* Website Reload: README in demos docker by [@aliabd](https://github.com/aliabd) in [PR 1100](https://github.com/gradio-app/gradio/pull/1100)\\n* Flagging fixes by [@abidlabs](https://github.com/abidlabs) in [PR 1081](https://github.com/gradio-app/gradio/pull/1081)\\n* Backend for optional labels by [@abidlabs](https://github.com/abidlabs) in [PR 1080](https://github.com/gradio-app/gradio/pull/1080)\\n* Optional labels fe by [@pngwn](https://github.com/pngwn) in [PR 1105](https://github.com/gradio-app/gradio/pull/1105)\\n* clean-deprecated-parameters by [@FarukOzderim](https://github.com/FarukOzderim) in [PR', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='1090](https://github.com/gradio-app/gradio/pull/1090)\\n* Blocks rendering fix by [@abidlabs](https://github.com/abidlabs) in [PR 1102](https://github.com/gradio-app/gradio/pull/1102)\\n* Redos #1106 by [@abidlabs](https://github.com/abidlabs) in [PR 1112](https://github.com/gradio-app/gradio/pull/1112)\\n* Interface types: handle input-only, output-only, and unified interfaces by [@abidlabs](https://github.com/abidlabs) in [PR 1108](https://github.com/gradio-app/gradio/pull/1108)\\n* Hotfix + New pypi release 2.9b11 by [@abidlabs](https://github.com/abidlabs) in [PR 1118](https://github.com/gradio-app/gradio/pull/1118)\\n* issue-checkbox by [@FarukOzderim](https://github.com/FarukOzderim) in [PR 1122](https://github.com/gradio-app/gradio/pull/1122)\\n* issue-checkbox-hotfix by [@FarukOzderim](https://github.com/FarukOzderim) in [PR 1127](https://github.com/gradio-app/gradio/pull/1127)\\n* Fix demos in website by [@aliabd](https://github.com/aliabd) in [PR 1130](https://github.com/gradio-app/gradio/pull/1130)\\n* Guide for Gradio ONNX model zoo on Huggingface by', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='[@AK391](https://github.com/AK391) in [PR 1073](https://github.com/gradio-app/gradio/pull/1073)\\n* ONNX guide fixes by [@aliabd](https://github.com/aliabd) in [PR 1131](https://github.com/gradio-app/gradio/pull/1131)\\n* Stacked form inputs css by [@gary149](https://github.com/gary149) in [PR 1134](https://github.com/gradio-app/gradio/pull/1134)\\n* made default value in textbox empty string by [@abidlabs](https://github.com/abidlabs) in [PR 1135](https://github.com/gradio-app/gradio/pull/1135)\\n* Examples UI by [@gary149](https://github.com/gary149) in [PR 1121](https://github.com/gradio-app/gradio/pull/1121)\\n* Chatbot custom color support by [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 1092](https://github.com/gradio-app/gradio/pull/1092)\\n* highlighted text colors by [@pngwn](https://github.com/pngwn) in [PR 1119](https://github.com/gradio-app/gradio/pull/1119)\\n* pin to pnpm 6 for now by [@pngwn](https://github.com/pngwn) in [PR 1147](https://github.com/gradio-app/gradio/pull/1147)\\n* Restore queue in Blocks by [@aliabid94](https://github.com/aliabid94) in [PR', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='1137](https://github.com/gradio-app/gradio/pull/1137)\\n* add select event for tabitems by [@pngwn](https://github.com/pngwn) in [PR 1154](https://github.com/gradio-app/gradio/pull/1154)\\n* max_lines + autoheight for textbox by [@pngwn](https://github.com/pngwn) in [PR 1153](https://github.com/gradio-app/gradio/pull/1153)\\n* use color palette for chatbot by [@pngwn](https://github.com/pngwn) in [PR 1152](https://github.com/gradio-app/gradio/pull/1152)\\n* Timeseries improvements by [@pngwn](https://github.com/pngwn) in [PR 1149](https://github.com/gradio-app/gradio/pull/1149)\\n* move styling for interface panels to frontend by [@pngwn](https://github.com/pngwn) in [PR 1146](https://github.com/gradio-app/gradio/pull/1146)\\n* html tweaks by [@pngwn](https://github.com/pngwn) in [PR 1145](https://github.com/gradio-app/gradio/pull/1145)\\n* Issue #768: Support passing none to resize and crop image by [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 1144](https://github.com/gradio-app/gradio/pull/1144)\\n* image gallery component + img css by [@aliabid94](https://github.com/aliabid94) in [PR', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='1140](https://github.com/gradio-app/gradio/pull/1140)\\n* networking tweak by [@abidlabs](https://github.com/abidlabs) in [PR 1143](https://github.com/gradio-app/gradio/pull/1143)\\n* Allow enabling queue per event listener by [@aliabid94](https://github.com/aliabid94) in [PR 1155](https://github.com/gradio-app/gradio/pull/1155)\\n* config hotfix and v. 2.9b23 by [@abidlabs](https://github.com/abidlabs) in [PR 1158](https://github.com/gradio-app/gradio/pull/1158)\\n* Custom JS calls by [@aliabid94](https://github.com/aliabid94) in [PR 1082](https://github.com/gradio-app/gradio/pull/1082)\\n* Small fixes: queue default fix, ffmpeg installation message by [@abidlabs](https://github.com/abidlabs) in [PR 1159](https://github.com/gradio-app/gradio/pull/1159)\\n* formatting by [@abidlabs](https://github.com/abidlabs) in [PR 1161](https://github.com/gradio-app/gradio/pull/1161)\\n* enable flex grow for gr-box by [@radames](https://github.com/radames) in [PR 1165](https://github.com/gradio-app/gradio/pull/1165)\\n* 1148 loading by [@pngwn](https://github.com/pngwn) in [PR', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='1164](https://github.com/gradio-app/gradio/pull/1164)\\n* Put enable_queue kwarg back in launch() by [@aliabid94](https://github.com/aliabid94) in [PR 1167](https://github.com/gradio-app/gradio/pull/1167)\\n* A few small fixes by [@abidlabs](https://github.com/abidlabs) in [PR 1171](https://github.com/gradio-app/gradio/pull/1171)\\n* Hotfix for dropdown component by [@abidlabs](https://github.com/abidlabs) in [PR 1172](https://github.com/gradio-app/gradio/pull/1172)\\n* use secondary buttons in interface by [@pngwn](https://github.com/pngwn) in [PR 1173](https://github.com/gradio-app/gradio/pull/1173)\\n* 1183 component height by [@pngwn](https://github.com/pngwn) in [PR 1185](https://github.com/gradio-app/gradio/pull/1185)\\n* 962 dataframe by [@pngwn](https://github.com/pngwn) in [PR 1186](https://github.com/gradio-app/gradio/pull/1186)\\n* update-contributing by [@FarukOzderim](https://github.com/FarukOzderim) in [PR 1188](https://github.com/gradio-app/gradio/pull/1188)\\n* Table tweaks by [@pngwn](https://github.com/pngwn) in [PR 1195](https://github.com/gradio-app/gradio/pull/1195)\\n*', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='wrap tab content in column by [@pngwn](https://github.com/pngwn) in [PR 1200](https://github.com/gradio-app/gradio/pull/1200)\\n* WIP: Add dark mode support by [@gary149](https://github.com/gary149) in [PR 1187](https://github.com/gradio-app/gradio/pull/1187)\\n* Restored /api/predict/ endpoint for Interfaces by [@abidlabs](https://github.com/abidlabs) in [PR 1199](https://github.com/gradio-app/gradio/pull/1199)\\n* hltext-label by [@pngwn](https://github.com/pngwn) in [PR 1204](https://github.com/gradio-app/gradio/pull/1204)\\n* add copy functionality to json by [@pngwn](https://github.com/pngwn) in [PR 1205](https://github.com/gradio-app/gradio/pull/1205)\\n* Update component config by [@aliabid94](https://github.com/aliabid94) in [PR 1089](https://github.com/gradio-app/gradio/pull/1089)\\n* fix placeholder prompt by [@pngwn](https://github.com/pngwn) in [PR 1215](https://github.com/gradio-app/gradio/pull/1215)\\n* ensure webcam video value is propogated correctly by [@pngwn](https://github.com/pngwn) in [PR 1218](https://github.com/gradio-app/gradio/pull/1218)\\n* Automatic word-break in', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='highlighted text, combine_adjacent support by [@aliabid94](https://github.com/aliabid94) in [PR 1209](https://github.com/gradio-app/gradio/pull/1209)\\n* async-function-support by [@FarukOzderim](https://github.com/FarukOzderim) in [PR 1190](https://github.com/gradio-app/gradio/pull/1190)\\n* Sharing fix for assets by [@aliabid94](https://github.com/aliabid94) in [PR 1208](https://github.com/gradio-app/gradio/pull/1208)\\n* Hotfixes for course demos by [@abidlabs](https://github.com/abidlabs) in [PR 1222](https://github.com/gradio-app/gradio/pull/1222)\\n* Allow Custom CSS by [@aliabid94](https://github.com/aliabid94) in [PR 1170](https://github.com/gradio-app/gradio/pull/1170)\\n* share-hotfix by [@FarukOzderim](https://github.com/FarukOzderim) in [PR 1226](https://github.com/gradio-app/gradio/pull/1226)\\n* tweaks by [@pngwn](https://github.com/pngwn) in [PR 1229](https://github.com/gradio-app/gradio/pull/1229)\\n* white space for class concatenation by [@radames](https://github.com/radames) in [PR 1228](https://github.com/gradio-app/gradio/pull/1228)\\n* Tweaks by', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='[@pngwn](https://github.com/pngwn) in [PR 1230](https://github.com/gradio-app/gradio/pull/1230)\\n* css tweaks by [@pngwn](https://github.com/pngwn) in [PR 1235](https://github.com/gradio-app/gradio/pull/1235)\\n* ensure defaults height match for media inputs by [@pngwn](https://github.com/pngwn) in [PR 1236](https://github.com/gradio-app/gradio/pull/1236)\\n* Default Label label value by [@radames](https://github.com/radames) in [PR 1239](https://github.com/gradio-app/gradio/pull/1239)\\n* update-shortcut-syntax by [@FarukOzderim](https://github.com/FarukOzderim) in [PR 1234](https://github.com/gradio-app/gradio/pull/1234)\\n* Update version.txt by [@FarukOzderim](https://github.com/FarukOzderim) in [PR 1244](https://github.com/gradio-app/gradio/pull/1244)\\n* Layout bugs by [@pngwn](https://github.com/pngwn) in [PR 1246](https://github.com/gradio-app/gradio/pull/1246)\\n* Update demo by [@FarukOzderim](https://github.com/FarukOzderim) in [PR 1253](https://github.com/gradio-app/gradio/pull/1253)\\n* Button default name by [@FarukOzderim](https://github.com/FarukOzderim) in [PR', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='1243](https://github.com/gradio-app/gradio/pull/1243)\\n* Labels spacing by [@gary149](https://github.com/gary149) in [PR 1254](https://github.com/gradio-app/gradio/pull/1254)\\n* add global loader for gradio app by [@pngwn](https://github.com/pngwn) in [PR 1251](https://github.com/gradio-app/gradio/pull/1251)\\n* ui apis for dalle-mini by [@pngwn](https://github.com/pngwn) in [PR 1258](https://github.com/gradio-app/gradio/pull/1258)\\n* Add precision to Number, backend only by [@freddyaboulton](https://github.com/freddyaboulton) in [PR 1125](https://github.com/gradio-app/gradio/pull/1125)\\n* Website Design Changes by [@abidlabs](https://github.com/abidlabs) in [PR 1015](https://github.com/gradio-app/gradio/pull/1015)\\n* Small fixes for multiple demos compatible with 3.0 by [@radames](https://github.com/radames) in [PR 1257](https://github.com/gradio-app/gradio/pull/1257)\\n* Issue #1160: Model 3D component not destroyed correctly by [@dawoodkhan82](https://github.com/dawoodkhan82) in [PR 1219](https://github.com/gradio-app/gradio/pull/1219)\\n* Fixes to components by', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='[@abidlabs](https://github.com/abidlabs) in [PR 1260](https://github.com/gradio-app/gradio/pull/1260)\\n* layout docs by [@abidlabs](https://github.com/abidlabs) in [PR 1263](https://github.com/gradio-app/gradio/pull/1263)\\n* Static forms by [@pngwn](https://github.com/pngwn) in [PR 1264](https://github.com/gradio-app/gradio/pull/1264)\\n* Cdn assets by [@pngwn](https://github.com/pngwn) in [PR 1265](https://github.com/gradio-app/gradio/pull/1265)\\n* update logo by [@gary149](https://github.com/gary149) in [PR 1266](https://github.com/gradio-app/gradio/pull/1266)\\n* fix slider by [@aliabid94](https://github.com/aliabid94) in [PR 1268](https://github.com/gradio-app/gradio/pull/1268)\\n* maybe fix auth in iframes by [@pngwn](https://github.com/pngwn) in [PR 1261](https://github.com/gradio-app/gradio/pull/1261)\\n* Improves \"Getting Started\" guide by [@abidlabs](https://github.com/abidlabs) in [PR 1269](https://github.com/gradio-app/gradio/pull/1269)\\n* Add embedded demos to website by [@aliabid94](https://github.com/aliabid94) in [PR', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='1270](https://github.com/gradio-app/gradio/pull/1270)\\n* Label hotfixes by [@abidlabs](https://github.com/abidlabs) in [PR 1281](https://github.com/gradio-app/gradio/pull/1281)\\n* General tweaks by [@pngwn](https://github.com/pngwn) in [PR 1276](https://github.com/gradio-app/gradio/pull/1276)\\n* only affect links within the document by [@pngwn](https://github.com/pngwn) in [PR 1282](https://github.com/gradio-app/gradio/pull/1282)\\n* release 3.0b9 by [@abidlabs](https://github.com/abidlabs) in [PR 1283](https://github.com/gradio-app/gradio/pull/1283)\\n* Dm by [@pngwn](https://github.com/pngwn) in [PR 1284](https://github.com/gradio-app/gradio/pull/1284)\\n* Website fixes by [@aliabd](https://github.com/aliabd) in [PR 1286](https://github.com/gradio-app/gradio/pull/1286)\\n* Create Streamables by [@aliabid94](https://github.com/aliabid94) in [PR 1279](https://github.com/gradio-app/gradio/pull/1279)\\n* ensure table works on mobile by [@pngwn](https://github.com/pngwn) in [PR 1277](https://github.com/gradio-app/gradio/pull/1277)\\n* changes by [@aliabid94](https://github.com/aliabid94) in', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='[PR 1287](https://github.com/gradio-app/gradio/pull/1287)\\n* demo alignment on landing page by [@aliabd](https://github.com/aliabd) in [PR 1288](https://github.com/gradio-app/gradio/pull/1288)\\n* New meta img by [@aliabd](https://github.com/aliabd) in [PR 1289](https://github.com/gradio-app/gradio/pull/1289)\\n* updated PyPi version to 3.0 by [@abidlabs](https://github.com/abidlabs) in [PR 1290](https://github.com/gradio-app/gradio/pull/1290)\\n* Fix site by [@aliabid94](https://github.com/aliabid94) in [PR 1291](https://github.com/gradio-app/gradio/pull/1291)\\n* Mobile responsive guides by [@aliabd](https://github.com/aliabd) in [PR 1293](https://github.com/gradio-app/gradio/pull/1293)\\n* Update readme by [@abidlabs](https://github.com/abidlabs) in [PR 1292](https://github.com/gradio-app/gradio/pull/1292)\\n* gif by [@abidlabs](https://github.com/abidlabs) in [PR 1296](https://github.com/gradio-app/gradio/pull/1296)\\n\\n## Contributors Shoutout:\\n\\n* [@JefferyChiang](https://github.com/JefferyChiang) made their first contribution in [PR', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content='1004](https://github.com/gradio-app/gradio/pull/1004)\\n* [@NimaBoscarino](https://github.com/NimaBoscarino) made their first contribution in [PR 1000](https://github.com/gradio-app/gradio/pull/1000)\\n* [@ronvoluted](https://github.com/ronvoluted) made their first contribution in [PR 1050](https://github.com/gradio-app/gradio/pull/1050)\\n* [@radames](https://github.com/radames) made their first contribution in [PR 1074](https://github.com/gradio-app/gradio/pull/1074)\\n* [@freddyaboulton](https://github.com/freddyaboulton) made their first contribution in [PR 1085](https://github.com/gradio-app/gradio/pull/1085)', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md'}, lookup_index=0),\n",
              " Document(page_content=\"# Contributing to Gradio\\n\\nPrequisites:\\n\\n* [Python 3.7+](https://www.python.org/downloads/)\\n* [pnpm version 7.x](https://pnpm.io/7.x/installation) (optional for backend-only changes, but needed for any frontend changes)\\n\\nMore than 80 awesome developers have contributed to the `gradio` library, and we'd be thrilled if you would like be the next `gradio` contributor! Start by cloning this repo and installing Gradio locally:\\n\\n### Install Gradio locally from the `main` branch\\n\\n* Clone this repo\\n* Navigate to the repo folder and run\\n\\n```bash\\nbash scripts/install_gradio.sh\\n```\\n\\n* Build the front end\\n\\n```\\nbash scripts/build_frontend.sh\\n```\\n\\n\\n### Install testing requirements\\n\\nIn order to be able to run the Python unit tests, do the following:\\n\\n* Navigate to the repo folder and install test requirements (note that it is highly recommended to use a virtual environment running **Python 3.9** since the versions are pinned)\\n\\n```\\nbash scripts/install_test_requirements.sh\\n```\\n* If you have a different Python version and conflicting packages during the installation, please first run:\\n\\n```\\nbash scripts/create_test_requirements.sh\\n```\\n\\n### Extra tidbits\\n\\n* You\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CONTRIBUTING.md'}, lookup_index=0),\n",
              " Document(page_content=\"can run gradio scripts in reload mode which will watch for changes in the `gradio` folder and reload the app if changes are made.\\n```\\ngradio app.py\\n```\\n\\n* You can also start a local frontend development server (on port 3000 by default) that responds to any changes in the frontend.\\n\\n```\\nbash scripts/run_frontend.sh\\n```\\n* To run all of the tests, do:\\n\\n```\\nbash scripts/run_all_tests.sh\\n```\\n\\n\\n### Structure of the Repository\\n\\nIt's helpful to know the overall structure of the repository so that you can focus on the part of the source code you'd like to contribute to\\n\\n* `/gradio`: contains the Python source code for the library\\n    * `/gradio/interface.py`: contains the Python source code for the core `Interface` class\\n    * `/gradio/blocks.py`: contains the Python source code for the core `Blocks` class\\n    * `/gradio/components.py`: contains the Python source code for the `components`, you can add your custom components here.\\n* `/ui`: contains the HTML/JS/CSS source code for the library ([start here for frontend changes](/ui/README.md))\\n* `/test`: contains Python unit tests for the library\\n* `/demo`: contains demos that are used in the documentation, you can find `Gradio` examples over\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CONTRIBUTING.md'}, lookup_index=0),\n",
              " Document(page_content='here.\\n* `/website`: contains the code for the Gradio website (www.gradio.app). See the README in the `/website` folder for more details\\n\\n### Continuous Integration and Testing\\n\\nAll PRs must pass the continuous integration tests before merging. To test locally, you can run `python -m unittest` from the repo directory.\\n\\n## Submitting PRs\\n\\nAll PRs should be against `main`. Direct commits to main are blocked, and PRs require an approving review to merge into main. By convention, the Gradio maintainers will review PRs when:\\n\\n* An initial review has been requested, and\\n* A description of the change (with a link to the GitHub PR) has been added to CHANGELOG.md, and\\n* A maintainer (@abidlabs, @aliabid94, @aliabd, @AK391, @dawoodkhan82, @pngwn, @freddyaboulton) is tagged in the PR comments and asked to complete a review\\n\\nWe ask that you make sure initial CI checks are passing before requesting a review. One of the Gradio maintainers will merge the PR when all the checks are passing.\\n\\nDo not forget the format the backend before pushing.\\n```\\nbash scripts/format_backend.sh\\n```\\n```\\nbash scripts/format_frontend.sh\\n```\\nYou can run the circleci checks locally as well. \\n```\\nbash', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CONTRIBUTING.md'}, lookup_index=0),\n",
              " Document(page_content='scripts/run_circleci.sh\\n```\\n\\n*Could these guidelines be clearer? Feel free to open a PR to help us faciltiate open-source contributions!*\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CONTRIBUTING.md'}, lookup_index=0),\n",
              " Document(page_content='# Security Policy\\n\\n## Reporting a Vulnerability\\n\\nIf you discover a security vulnerability, we would be very grateful if you could email us at team@gradio.app. This is the preferred approach instead of opening a public issue. We take all vulnerability reports seriously, and will work to patch the vulnerability immediately. Whenever possible, we will credit the person or people who report the security vulnerabilities after it has been patched.\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/SECURITY.md'}, lookup_index=0),\n",
              " Document(page_content=\"This text generation demo works like autocomplete. There's only one textbox and it's used for both the input and the output. The demo loads the model as an interface, and uses that interface as an API. It then uses blocks to create the UI. All of this is done in less than 10 lines of code.\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/demo/autocomplete/DESCRIPTION.md'}, lookup_index=0),\n",
              " Document(page_content=\"This demo identifies if two speakers are the same person using Gradio's Audio and HTML components.\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/demo/same-person-or-different/DESCRIPTION.md'}, lookup_index=0),\n",
              " Document(page_content='This text generation demo takes in input text and returns generated text. It uses the Transformers library to set up the model and has two examples.', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/demo/text_generation/DESCRIPTION.md'}, lookup_index=0),\n",
              " Document(page_content=\"This sentiment analaysis demo takes in input text and returns its classification for either positive, negative or neutral using Gradio's Label output. It also uses the default interpretation method so users can click the Interpret button after a submission and see which words had the biggest effect on the output.\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/demo/sentiment_analysis/DESCRIPTION.md'}, lookup_index=0),\n",
              " Document(page_content='A simple demo showcasing the upload button used with its `upload` event trigger.', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/demo/upload_button/DESCRIPTION.md'}, lookup_index=0),\n",
              " Document(page_content=\"Simple image classification in Pytorch with Gradio's Image input and Label output.\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/demo/image_classification/DESCRIPTION.md'}, lookup_index=0),\n",
              " Document(page_content='A demo for predicting the depth of an image and generating a 3D model of it.', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/demo/depth_estimation/DESCRIPTION.md'}, lookup_index=0),\n",
              " Document(page_content='Display an interactive map of AirBnB locations with Plotly. Data is hosted on HuggingFace Datasets. ', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/demo/map_airbnb/DESCRIPTION.md'}, lookup_index=0),\n",
              " Document(page_content='Image segmentation using DETR. Takes in both an inputu image and the desired confidence, and returns a segmented image.', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/demo/image_segmentation/DESCRIPTION.md'}, lookup_index=0),\n",
              " Document(page_content='This translation demo takes in the text, source and target languages, and returns the translation. It uses the Transformers library to set up the model and has a title, description, and example.', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/demo/translation/DESCRIPTION.md'}, lookup_index=0),\n",
              " Document(page_content='Calculate taxes using Textbox, Radio, and Dataframe components', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/demo/tax_calculator/DESCRIPTION.md'}, lookup_index=0),\n",
              " Document(page_content='A simple dashboard showing pypi stats for python libraries. Updates on load, and has no buttons!', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/demo/timeseries-forecasting-with-prophet/DESCRIPTION.md'}, lookup_index=0),\n",
              " Document(page_content='Generate a plot based on 5 inputs.', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/demo/outbreak_forecast/DESCRIPTION.md'}, lookup_index=0),\n",
              " Document(page_content='Note: This is a simplified version of the code needed to create the Stable Diffusion demo. See full code here: https://hf.co/spaces/stabilityai/stable-diffusion/tree/main', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/demo/stable-diffusion/DESCRIPTION.md'}, lookup_index=0),\n",
              " Document(page_content='This demo built with Blocks generates 9 plots based on the input.', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/demo/clustering/DESCRIPTION.md'}, lookup_index=0),\n",
              " Document(page_content='This  demo converts text to speech in 14 languages.', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/demo/neon-tts-plugin-coqui/DESCRIPTION.md'}, lookup_index=0),\n",
              " Document(page_content='A simple dashboard ranking spaces by number of likes.', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/demo/leaderboard/DESCRIPTION.md'}, lookup_index=0),\n",
              " Document(page_content='Recreate the viral AnimeGAN image transformation demo.', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/demo/animeganv2/DESCRIPTION.md'}, lookup_index=0),\n",
              " Document(page_content=\"This demo shows how you can build a live interactive dashboard with gradio.\\nThe current time is refreshed every second and the plot every half second by using the 'every' keyword in the event handler.\\nChanging the value of the slider will control the period of the sine curve (the distance between peaks). \", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/demo/live_dashboard/DESCRIPTION.md'}, lookup_index=0),\n",
              " Document(page_content='This demo takes in 12 inputs from the user in dropdowns and sliders and predicts income. It also has a separate button for explaining the prediction.', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/demo/xgboost-income-prediction-with-explainability/DESCRIPTION.md'}, lookup_index=0),\n",
              " Document(page_content=\"This simple demo takes advantage of Gradio's HighlightedText, JSON and HTML outputs to create a clear NER segmentation.\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/demo/text_analysis/DESCRIPTION.md'}, lookup_index=0),\n",
              " Document(page_content='Automatic speech recognition English. Record from your microphone and the app will transcribe the audio.', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/demo/automatic-speech-recognition/DESCRIPTION.md'}, lookup_index=0),\n",
              " Document(page_content=\"This demo identifies musical instruments from an audio file. It uses Gradio's Audio and Label components.\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/demo/musical_instrument_identification/DESCRIPTION.md'}, lookup_index=0),\n",
              " Document(page_content=\"The simplest possible Gradio demo. It wraps a 'Hello {name}!' function in an Interface that accepts and returns text.\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/demo/hello_world/DESCRIPTION.md'}, lookup_index=0),\n",
              " Document(page_content='This demo uses a fake model to showcase iterative output. The Image output will update every time a generator is returned until the final image.', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/demo/fake_diffusion/DESCRIPTION.md'}, lookup_index=0),\n",
              " Document(page_content=\"This demo shows how you can build an interactive dashboard with gradio. Click on a python library on the left hand side and then on the right hand side click on the metric you'd like to see plot over time. Data is pulled from HuggingFace Hub datasets.\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/demo/dashboard/DESCRIPTION.md'}, lookup_index=0),\n",
              " Document(page_content='# Backend Testing Guidelines\\n\\n- All the tests should test Backend functionalities. Frontend functionalities and e2e tests are done in Frontend.\\n- Make use of pytest fixtures whenever it is possible. With fixtures, objects with high initialize durations are reused within tests, ex. a client session.\\n- All test_data resides within _gradio/test_data_ and all test_files resides within test/test_files.\\n- When doing network operations do not forget to make use of async to make tests faster.\\n- Have clear class and function naming within the tests.\\n- Short descriptions within test functions are great.\\n- Library function docstrings is expected to contain an example, please add missing docstrings to the library while you are writing tests the related function.\\n- Library docstring examples and descriptions are expected to align with tests, please fix divergent tests and library docstrings.\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/test/README.md'}, lookup_index=0),\n",
              " Document(page_content=\"# gradio-ui\\n\\nThis folder contains all of the Gradio UI and component source code.\\n\\n- [set up](#setup)\\n- [running the application](#running-the-application)\\n- [local development](#local-development)\\n- [building for production](#building-for-production)\\n- [quality checks](#quality-checks)\\n- [ci checks](#ci-checks)\\n\\n> Note: The below assumes you are in the `ui` directory unless alternative instructions are given.\\n\\n## setup\\n\\nThis folder is managed as 'monorepo' a multi-package repository which make dependency management very simple. In order to do this we use `pnpm` as our package manager.\\n\\nMake sure [`pnpm`](https://pnpm.io/) is installed by [following the installation instructions for your system](https://pnpm.io/installation).\\n\\nYou will also need `node` which you probably already have\\n\\n## running the application\\n\\nInstall all dependencies from the `ui` folder:\\n\\n```bash\\npnpm i\\n```\\n\\nThis will install the dependencies for all packages within the `ui` folder and link any local packages\\n\\n## local development\\n\\nTo develop locally, open two terminal tabs from the root of the repository.\\n\\nRun the python test server, from the root directory:\\n\\n```bash\\ncd\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/ui/README.md'}, lookup_index=0),\n",
              " Document(page_content=\"demo/kitchen_sink\\npython run.py\\n```\\n\\nThis will start a development server on port `7860` that the web app is expecting.\\n\\nRun the web app:\\n\\n```bash\\ncd ui #move back into ui if you haven't already\\npnpm dev\\n```\\n\\n## building for production\\n\\nFrom the `ui` folder run the build.\\n\\n```bash\\npnpm build\\n```\\n\\nThis will create the necessary files in `ui/app/public` and also in `gradio/templates/frontend`.\\n\\n## quality checks\\n\\nThe repos currently has two quality checks that can be run locally and are run in CI.\\n\\n### formatting\\n\\nFormatting is handled by [`prettier`](https://prettier.io/) to ensure consistent formatting and prevent style-focused conversations. Formatting failures will fails CI and should be reoslve before merging.\\n\\nTo check formatting:\\n\\n```bash\\npnpm format:check\\n```\\n\\nIf you have formatting failures then you can run the following command to fix them:\\n\\n```bash\\npnpm format:write\\n```\\n\\n### type checking\\n\\nWe use [TypeScript](https://www.typescriptlang.org/) to provide static types to javascript code. These checks are also run in CI.\\n\\nto typecheck the code:\\n\\n```bash\\npnpm ts:check\\n```\\n\\n## ci checks\\n\\nCurrently the following checks are run in CI:\\n\\n- Format\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/ui/README.md'}, lookup_index=0),\n",
              " Document(page_content='check (`pnpm format:check`)\\n- Type check (`pnpm ts:check`)\\n- Build as a smoke test (`pnpm build`)\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/ui/README.md'}, lookup_index=0),\n",
              " Document(page_content=\"# How to add support for more languages\\n\\nWe would love to support more languages for Gradio 🌎\\n\\nTo add your language, do the following steps:\\n\\n1. Create a new json file in this directory\\n2. Name the file after the language code (Here's a list: http://4umi.com/web/html/languagecodes.php)\\n3. Please provide clear and complete translations. Take a look at the [`en.json`](https://github.com/gradio-app/gradio/blob/master/ui/packages/app/public/lang/en.json) file for the corresponding English text.\\n\\nThat's it!\\n\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/ui/packages/app/src/lang/README.md'}, lookup_index=0),\n",
              " Document(page_content='# `@gradio/uploadbutton`\\n\\n```html\\n<script>\\n\\timport { UploadButton } from \"@gradio/uploadbutton\";\\n</script>\\n\\n<button type=\"primary|secondary\" href=\"string\" on:click=\"{e.detail === href}\">\\n\\tcontent\\n</button>\\n```\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/ui/packages/upload-button/README.md'}, lookup_index=0),\n",
              " Document(page_content='# `@gradio/button`\\n\\n```html\\n<script>\\n\\timport { Button } from \"@gradio/button\";\\n</script>\\n\\n<button type=\"primary|secondary\" href=\"string\" on:click=\"{e.detail === href}\">\\n\\tcontent\\n</button>\\n```\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/ui/packages/tootils/README.md'}, lookup_index=0),\n",
              " Document(page_content='# `@gradio/button`\\n\\n```html\\n<script>\\n\\timport { Button } from \"@gradio/button\";\\n</script>\\n\\n<button type=\"primary|secondary\" href=\"string\" on:click=\"{e.detail === href}\">\\n\\tcontent\\n</button>\\n```\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/ui/packages/gallery/README.md'}, lookup_index=0),\n",
              " Document(page_content='# `@gradio/button`\\n\\n```html\\n<script>\\n\\timport { Button } from \"@gradio/button\";\\n</script>\\n\\n<button type=\"primary|secondary\" href=\"string\" on:click=\"{e.detail === href}\">\\n\\tcontent\\n</button>\\n```\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/ui/packages/image/README.md'}, lookup_index=0),\n",
              " Document(page_content='# `@gradio/button`\\n\\n```html\\n<script>\\n\\timport { Button } from \"@gradio/button\";\\n</script>\\n\\n<button type=\"primary|secondary\" href=\"string\" on:click=\"{e.detail === href}\">\\n\\tcontent\\n</button>\\n```\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/ui/packages/chatbot/README.md'}, lookup_index=0),\n",
              " Document(page_content='# `@gradio/button`\\n\\n```html\\n<script>\\n\\timport { Button } from \"@gradio/button\";\\n</script>\\n\\n<button type=\"primary|secondary\" href=\"string\" on:click=\"{e.detail === href}\">\\n\\tcontent\\n</button>\\n```\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/ui/packages/label/README.md'}, lookup_index=0),\n",
              " Document(page_content='# `@gradio/button`\\n\\n```html\\n<script>\\n\\timport { Button } from \"@gradio/button\";\\n</script>\\n\\n<button type=\"primary|secondary\" href=\"string\" on:click=\"{e.detail === href}\">\\n\\tcontent\\n</button>\\n```\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/ui/packages/json/README.md'}, lookup_index=0),\n",
              " Document(page_content='# `@gradio/button`\\n\\n```html\\n<script>\\n\\timport { Button } from \"@gradio/button\";\\n</script>\\n\\n<button type=\"primary|secondary\" href=\"string\" on:click=\"{e.detail === href}\">\\n\\tcontent\\n</button>\\n```\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/ui/packages/video/README.md'}, lookup_index=0),\n",
              " Document(page_content='# `@gradio/button`\\n\\n```html\\n<script>\\n\\timport { Button } from \"@gradio/button\";\\n</script>\\n\\n<button type=\"primary|secondary\" href=\"string\" on:click=\"{e.detail === href}\">\\n\\tcontent\\n</button>\\n```\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/ui/packages/tooltip/README.md'}, lookup_index=0),\n",
              " Document(page_content='# `@gradio/table`\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/ui/packages/table/README.md'}, lookup_index=0),\n",
              " Document(page_content='# `@gradio/button`\\n\\n```html\\n<script>\\n\\timport { Button } from \"@gradio/button\";\\n</script>\\n\\n<button type=\"primary|secondary\" href=\"string\" on:click=\"{e.detail === href}\">\\n\\tcontent\\n</button>\\n```\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/ui/packages/form/README.md'}, lookup_index=0),\n",
              " Document(page_content='# `@gradio/button`\\n\\n```html\\n<script>\\n\\timport { Button } from \"@gradio/button\";\\n</script>\\n\\n<button type=\"primary|secondary\" href=\"string\" on:click=\"{e.detail === href}\">\\n\\tcontent\\n</button>\\n```\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/ui/packages/button/README.md'}, lookup_index=0),\n",
              " Document(page_content='# `@gradio/button`\\n\\n```html\\n<script>\\n\\timport { Button } from \"@gradio/button\";\\n</script>\\n\\n<button type=\"primary|secondary\" href=\"string\" on:click=\"{e.detail === href}\">\\n\\tcontent\\n</button>\\n```\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/ui/packages/file/README.md'}, lookup_index=0),\n",
              " Document(page_content='# `@gradio/table`\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/ui/packages/utils/README.md'}, lookup_index=0),\n",
              " Document(page_content='# `@gradio/button`\\n\\n```html\\n<script>\\n\\timport { Button } from \"@gradio/button\";\\n</script>\\n\\n<button type=\"primary|secondary\" href=\"string\" on:click=\"{e.detail === href}\">\\n\\tcontent\\n</button>\\n```\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/ui/packages/atoms/README.md'}, lookup_index=0),\n",
              " Document(page_content='# `@gradio/button`\\n\\n```html\\n<script>\\n\\timport { Button } from \"@gradio/button\";\\n</script>\\n\\n<button type=\"primary|secondary\" href=\"string\" on:click=\"{e.detail === href}\">\\n\\tcontent\\n</button>\\n```\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/ui/packages/accordion/README.md'}, lookup_index=0),\n",
              " Document(page_content='# `@gradio/button`\\n\\n```html\\n<script>\\n\\timport { Button } from \"@gradio/button\";\\n</script>\\n\\n<button type=\"primary|secondary\" href=\"string\" on:click=\"{e.detail === href}\">\\n\\tcontent\\n</button>\\n```\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/ui/packages/html/README.md'}, lookup_index=0),\n",
              " Document(page_content='# `@gradio/button`\\n\\n```html\\n<script>\\n\\timport { Button } from \"@gradio/button\";\\n</script>\\n\\n<button type=\"primary|secondary\" href=\"string\" on:click=\"{e.detail === href}\">\\n\\tcontent\\n</button>\\n```\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/ui/packages/highlighted-text/README.md'}, lookup_index=0),\n",
              " Document(page_content=\"# create-svelte\\n\\nEverything you need to build a Svelte project, powered by [`create-svelte`](https://github.com/sveltejs/kit/tree/master/packages/create-svelte).\\n\\n## Creating a project\\n\\nIf you're seeing this, you've probably already done this step. Congrats!\\n\\n```bash\\n# create a new project in the current directory\\nnpm init svelte@next\\n\\n# create a new project in my-app\\nnpm init svelte@next my-app\\n```\\n\\n> Note: the `@next` is temporary\\n\\n## Developing\\n\\nOnce you've created a project and installed dependencies with `npm install` (or `pnpm install` or `yarn`), start a development server:\\n\\n```bash\\nnpm run dev\\n\\n# or start the server and open the app in a new browser tab\\nnpm run dev -- --open\\n```\\n\\n## Building\\n\\nTo create a production version of your app:\\n\\n```bash\\nnpm run build\\n```\\n\\nYou can preview the production build with `npm run preview`.\\n\\n> To deploy your app, you may need to install an [adapter](https://kit.svelte.dev/docs/adapters) for your target environment.\\n\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/ui/packages/workbench/README.md'}, lookup_index=0),\n",
              " Document(page_content='# `@gradio/theme`\\n\\ncss for gradio\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/ui/packages/theme/README.md'}, lookup_index=0),\n",
              " Document(page_content='# `@gradio/chart`\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/ui/packages/chart/README.md'}, lookup_index=0),\n",
              " Document(page_content='# `@gradio/audio`\\n\\n```svelte\\n<script>\\n\\timport { Audio } from \"@gradio/audio\";\\n</script>\\n\\n<Audio\\n\\tvalue=\"string\"\\n\\ttheme=\"string\"\\n\\tname=\"string\"\\n\\tsource=\"microphone | upload\"\\n\\ton:change={e.detail === value}\\n/>\\n```\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/ui/packages/audio/README.md'}, lookup_index=0),\n",
              " Document(page_content=\"# Contributing a Guide\\n\\nWant to help teach Gradio? Consider contributing a Guide! 🤗 \\n\\nBroadly speaking, there are two types of guides:\\n\\n* **Use cases**: guides that cover step-by-step how to build a particular type of machine learning demo or app using Gradio. Here's an example: [_Creating a Chatbot_](https://github.com/gradio-app/gradio/blob/master/guides/creating_a_chatbot.md)\\n* **Feature explanation**: guides that describe in detail a particular feature of Gradio.  Here's an example: [_Using Flagging_](https://github.com/gradio-app/gradio/blob/master/guides/using_flagging.md)\\n\\nWe encourage you to submit either type of Guide! (Looking for ideas? We may also have open [issues](https://github.com/gradio-app/gradio/issues?q=is%3Aopen+is%3Aissue+label%3Aguides) where users have asked for guides on particular topics)\\n\\n## Guide Structure\\n\\nAs you can see with the previous examples, Guides are standard markdown documents. They usually:\\n* start with an Introduction section describing the topic\\n* include subheadings to make articles easy to navigate\\n* include real code snippets that make it easy to follow along and implement the Guide\\n* include\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/CONTRIBUTING.md'}, lookup_index=0),\n",
              " Document(page_content=\"embedded Gradio demos to make them more interactive and provide immediate demonstrations of the topic being discussed. These Gradio demos are hosted on [Hugging Face Spaces](https://huggingface.co/spaces) and are embedded using the standard \\\\<iframe\\\\> tag.\\n\\n\\n## How to Contribute a Guide\\n\\n1. Clone or fork this `gradio` repo\\n2. Add a new markdown document with a descriptive title to the `/guides` folder\\n3. Write your Guide in standard markdown! Embed Gradio demos wherever helpful\\n4. Add a list of `related_spaces` at the top of the markdown document (see the previously linked Guides for how to do this)\\n5. Add 3 `tags` at the top of the markdown document to help users find your guide (again, see the previously linked Guides for how to do this)\\n6. Open a PR to have your guide reviewed\\n\\nThat's it! We're looking forward to reading your Guide 🥳\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/CONTRIBUTING.md'}, lookup_index=0),\n",
              " Document(page_content=\"# Sharing Your App\\n\\nHow to share your Gradio app: \\n\\n1. [Sharing demos with the share parameter](#sharing-demos)\\n2. [Hosting on HF Spaces](#hosting-on-hf-spaces)\\n3. [Embedding hosted spaces](#embedding-hosted-spaces)\\n4. [Embedding with web components](#embedding-with-web-components)\\n5. [Using the API page](#api-page)\\n6. [Adding authentication to the page](#authentication)\\n7. [Accessing Network Requests](#accessing-the-network-request-directly)\\n8. [Mounting within FastAPI](#mounting-within-another-fastapi-app)\\n\\n## Sharing Demos\\n\\nGradio demos can be easily shared publicly by setting `share=True` in the `launch()` method. Like this:\\n\\n```python\\ndemo.launch(share=True)\\n```\\n\\nThis generates a public, shareable link that you can send to anybody! When you send this link, the user on the other side can try out the model in their browser. Because the processing happens on your device (as long as your device stays on!), you don't have to worry about any packaging any dependencies. A share link usually looks something like this:  **XXXXX.gradio.app**. Although the link is served through a Gradio URL, we are only a proxy for your local server, and do not store any\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/01_getting-started/03_sharing-your-app.md'}, lookup_index=0),\n",
              " Document(page_content='data sent through your app.\\n\\nKeep in mind, however, that these links are publicly accessible, meaning that anyone can use your model for prediction! Therefore, make sure not to expose any sensitive information through the functions you write, or allow any critical changes to occur on your device. If you set `share=False` (the default, except in colab notebooks), only a local link is created, which can be shared by  [port-forwarding](https://www.ssh.com/ssh/tunneling/example)  with specific users. \\n\\n<img style=\"width: 40%\" src=\"/assets/guides/sharing.svg\">\\n\\nShare links expire after 72 hours.\\n\\n## Hosting on HF Spaces\\n\\nIf you\\'d like to have a permanent link to your Gradio demo on the internet, use Hugging Face Spaces. [Hugging Face Spaces](http://huggingface.co/spaces/) provides the infrastructure to permanently host your machine learning model for free! \\n\\nYou can either drag and drop a folder containing your Gradio model and all related files, or you can point Spaces to your Git repository and Spaces will pull the Gradio app from there. See [this guide how to host on Hugging Face Spaces](https://huggingface.co/blog/gradio-spaces) for more information. \\n\\n<video autoplay muted', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/01_getting-started/03_sharing-your-app.md'}, lookup_index=0),\n",
              " Document(page_content='loop>\\n  <source src=\"/assets/guides/hf_demo.mp4\" type=\"video/mp4\" />\\n</video>\\n\\n## Embedding Hosted Spaces\\n\\nOnce you have hosted your app on Hugging Face Spaces, you may want to embed the demo on a different website, such as your blog or your portfolio. Embedding an interactive demo allows people to try out the machine learning model that you have built, without needing to download or install anything — right in their browser! The best part is that you can embed interative demos even in static websites, such as GitHub pages.\\n\\nThere are two ways to embed your Gradio demos, hosted on Hugging Face Spaces. You can find quick links to both options directly on the Space page, in the \"Embed this Space\" dropdown option:\\n\\n![Embed this Space dropdown option](/assets/guides/embed_this_space.png)\\n\\n### Embedding with Web Components\\n\\nUsing web components is faster then iframes, and will automatically adjust to other content on your site. To embed with Web Components:\\n\\n1. Import the gradio JS library into into your site by adding the script below in your site (replace {GRADIO_VERSION} in the URL with the library version of Gradio you are using). \\n\\n    ```html\\n&lt;script', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/01_getting-started/03_sharing-your-app.md'}, lookup_index=0),\n",
              " Document(page_content='type=\"module\"\\nsrc=\"https://gradio.s3-us-west-2.amazonaws.com/{GRADIO_VERSION}/gradio.js\">\\n&lt;/script>\\n    ```\\n\\n2. Add \\n    ```html\\n&lt;gradio-app src=\"https://$your_space_host.hf.space\">&lt;/gradio-app>\\n    ```\\nelement where you want to place the app. Set the `src=` attribute to your Space\\'s embed URL, which you can find in the Embed this Space button. For example:\\n\\n    ```html\\n&lt;gradio-app src=\"https://abidlabs-pytorch-image-classifier.hf.space\">&lt;/gradio-app>\\n    ```\\n\\n<script>\\nfetch(\"https://pypi.org/pypi/gradio/json\"\\n).then(r => r.json()\\n).then(obj => {\\n    let v = obj.info.version;\\n    content = document.querySelector(\\'.prose\\');\\n    content.innerHTML = content.innerHTML.replaceAll(\"{GRADIO_VERSION}\", v);\\n});\\n</script>\\n\\n_Note: While Gradio\\'s CSS will never impact the embedding page, the embedding page can affect the style of the embedded Gradio app. Make sure that any CSS in the parent page isn\\'t so general that it could also apply to the embedded Gradio app and cause the styling to break. Element selectors such as `header { ... }` and `footer { ... }` will be the most likely to cause issues._\\n\\n### Embedding with IFrames\\n\\nTo embed with IFrames', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/01_getting-started/03_sharing-your-app.md'}, lookup_index=0),\n",
              " Document(page_content='instead, simply add this element:\\n\\n```html\\n&lt;iframe src=\"https://$your_space_host.hf.space\">&lt;/iframe>\\n```\\n\\nFor example: \\n\\n```html\\n&lt;iframe src=\"https://abidlabs-pytorch-image-classifier.hf.space\">&lt;/iframe>\\n```\\n\\n## API Page\\n\\n$demo_hello_world\\n\\nSee the \"view api\" link in footer of the app above? This is a page that documents the REST API that users can use to query the `Interface` function. `Blocks` apps can also generate an API page, though the API has to be explicitly named for each event listener, such as\\n\\n```python\\nbtn.click(add, [num1, num2], output, api_name=\"addition\")\\n```\\n\\nThis will document the endpoint `/api/addition/` to the automatically generated API page. \\n\\n## Authentication\\n\\nYou may wish to put an authentication page in front of your app to limit who can open your app. With the `auth=` keyword argument in the `launch()` method, you can provide a tuple with a username and password, or a  list of acceptable username/password tuples;  Here\\'s an example that provides password-based authentication for a single user named \"admin\":\\n\\n```python\\ndemo.launch(auth=(\"admin\", \"pass1234\"))\\n```\\n\\nFor more complex authentication handling, you', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/01_getting-started/03_sharing-your-app.md'}, lookup_index=0),\n",
              " Document(page_content='can even pass a function that takes a username and password as arguments, and returns True to allow authentication, False otherwise. This can be used for, among other things, making requests to 3rd-party authentication services.\\n\\nHere\\'s an example of a function that accepts any login where the username and password are the same:\\n\\n```python\\ndef same_auth(username, password):\\n    return username == password\\ndemo.launch(auth=same_auth)\\n```\\n\\nFor authentication to work properly, third party cookies must be enabled in your browser.\\nThis is not the case by default for Safari, Chrome Incognito Mode.\\n\\n## Accessing the Network Request Directly\\n\\nWhen a user makes a prediction to your app, you may need the underlying network request, in order to get the request headers (e.g. for advanced authentication), log the client\\'s IP address, or for other reasons. Gradio supports this in a similar manner to FastAPI: simply add a function parameter whose type hint is `gr.Request` and Gradio will pass in the network request as that parameter. Here is an example:\\n\\n```python\\nimport gradio as gr\\n\\ndef echo(name, request: gr.Request):\\n    if request:\\n        print(\"Request headers dictionary:\", request.headers)\\n       ', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/01_getting-started/03_sharing-your-app.md'}, lookup_index=0),\n",
              " Document(page_content='       print(\"IP address:\", request.client.host)\\n    return name\\n\\nio = gr.Interface(echo, \"textbox\", \"textbox\").launch()\\n```\\n\\nNote: if your function is called directly instead of through the UI (this happens, for \\nexample, when examples are cached), then `request` will be `None`. You should handle\\nthis case explicitly to ensure that your app does not throw any errors. That is why\\nwe have the explicit check `if request`.\\n\\n## Mounting Within Another FastAPI App\\n\\nIn some cases, you might have an existing FastAPI app, and you\\'d like to add a path for a Gradio demo.\\nYou can easily do this with `gradio.mount_gradio_app()`.\\n\\nHere\\'s a complete example:\\n\\n$code_custom_path\\n\\nNote that this approach also allows you run your Gradio apps on custom paths (`http://localhost:8000/gradio` in the example above).\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/01_getting-started/03_sharing-your-app.md'}, lookup_index=0),\n",
              " Document(page_content=\"# Key Features\\n\\nLet's go through some of the most popular features of Gradio! Here are Gradio's key features: \\n\\n1. [Adding example inputs](#example-inputs)\\n2. [Passing custom error messages](#errors)\\n3. [Adding descriptive content](#descriptive-content)\\n4. [Setting up flagging](#flagging)\\n5. [Preprocessing and postprocessing](#preprocessing-and-postprocessing)\\n6. [Styling demos](#styling)\\n7. [Queuing users](#queuing)\\n8. [Iterative outputs](#iterative-outputs)\\n9. [Progress bars](#progress-bars)\\n10. [Batch functions](#batch-functions)\\n\\n## Example Inputs\\n\\nYou can provide example data that a user can easily load into `Interface`. This can be helpful to demonstrate the types of inputs the model expects, as well as to provide a way to explore your dataset in conjunction with your model. To load example data, you can provide a **nested list** to the `examples=`  keyword argument of the Interface constructor. Each sublist within the outer list represents a data sample, and each element within the sublist represents an input for each input component. The format of example data for each component is specified in the\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/01_getting-started/02_key-features.md'}, lookup_index=0),\n",
              " Document(page_content='[Docs](https://gradio.app/docs#components).\\n\\n$code_calculator\\n$demo_calculator\\n\\nYou can load a large dataset into the examples to browse and interact with the dataset through Gradio. The examples will be automatically paginated (you can configure this through the `examples_per_page` argument of `Interface`). \\n\\nContinue learning about examples in the [More On Examples](https://gradio.app/more-on-examples) guide.\\n\\n## Errors\\n\\nYou wish to pass custom error messages to the user. To do so, raise a `gr.Error(\"custom message\")` to display an error message. If you try to divide by zero in the calculator demo above, a popup modal will display the custom error message. Learn more about Error in the [docs](https://gradio.app/docs#errors).\\n\\n## Descriptive Content\\n\\nIn the previous example, you may have noticed the `title=` and `description=` keyword arguments in the `Interface` constructor that helps users understand your app.\\n\\nThere are three arguments in the `Interface` constructor to specify where this content should go:\\n\\n* `title`: which accepts text and can display it at the very top of interface, and also becomes the page title.\\n* `description`: which accepts text,', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/01_getting-started/02_key-features.md'}, lookup_index=0),\n",
              " Document(page_content='markdown or HTML and places it right under the title.\\n* `article`: which also accepts text, markdown or HTML and places it below the interface.\\n\\n![annotated](/assets/guides/annotated.png)\\n\\nIf you\\'re using the `Blocks` API instead, you can insert text, markdown, or HTML anywhere using the `gr.Markdown(...)` or `gr.HTML(...)` components, with descriptive content inside the `Component` constructor.\\n\\nAnother useful keyword argument is `label=`, which is present in every `Component`. This modifies the label text at the top of each `Component`.\\n\\n```python\\ngr.Number(label=\\'Age\\')\\n```\\n\\n## Flagging\\n\\nBy default, an `Interface` will have \"Flag\" button. When a user testing your `Interface` sees input with interesting output, such as erroneous or unexpected model behaviour, they can flag the input for you to review. Within the directory provided by the  `flagging_dir=`  argument to the `Interface` constructor, a CSV file will log the flagged inputs. If the interface involves file data, such as for Image and Audio components, folders will be created to store those flagged data as well.\\n\\nFor example, with the calculator interface shown above, we would have the flagged data stored in the', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/01_getting-started/02_key-features.md'}, lookup_index=0),\n",
              " Document(page_content=\"flagged directory shown below:\\n\\n```directory\\n+-- calculator.py\\n+-- flagged/\\n|   +-- logs.csv\\n```\\n\\n*flagged/logs.csv*\\n```csv\\nnum1,operation,num2,Output\\n5,add,7,12\\n6,subtract,1.5,4.5\\n```\\n\\nWith the sepia interface shown earlier, we would have the flagged data stored in the flagged directory shown below:\\n\\n```directory\\n+-- sepia.py\\n+-- flagged/\\n|   +-- logs.csv\\n|   +-- im/\\n|   |   +-- 0.png\\n|   |   +-- 1.png\\n|   +-- Output/\\n|   |   +-- 0.png\\n|   |   +-- 1.png\\n```\\n\\n*flagged/logs.csv*\\n```csv\\nim,Output\\nim/0.png,Output/0.png\\nim/1.png,Output/1.png\\n```\\n\\nIf you wish for the user to provide a reason for flagging, you can pass a list of strings to the `flagging_options` argument of Interface. Users will have to select one of the strings when flagging, which will be saved as an additional column to the CSV.\\n\\n## Preprocessing and Postprocessing\\n\\n![annotated](/assets/img/dataflow.svg)\\n\\nAs you've seen, Gradio includes components that can handle a variety of different data types, such as images, audio, and video. Most components can be used both as inputs or outputs.\\n\\nWhen a component is used as an input, Gradio automatically handles the *preprocessing* needed to convert the data from a type\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/01_getting-started/02_key-features.md'}, lookup_index=0),\n",
              " Document(page_content='sent by the user\\'s browser (such as a base64 representation of a webcam snapshot) to a form that can be accepted by your function (such as a `numpy` array). \\n\\nSimilarly, when a component is used as an output, Gradio automatically handles the *postprocessing* needed to convert the data from what is returned by your function (such as a list of image paths) to a form that can be displayed in the user\\'s browser (such as a `Gallery` of images in base64 format).\\n\\nYou can control the *preprocessing* using the parameters when constructing the image component. For example, here if you instantiate the `Image` component with the following parameters, it will convert the image to the `PIL` type and reshape it to be `(100, 100)` no matter the original size that it was submitted as:\\n\\n```py\\nimg = gradio.Image(shape=(100, 100), type=\"pil\")\\n```\\n\\nIn contrast, here we keep the original size of the image, but invert the colors before converting it to a numpy array:\\n\\n```py\\nimg = gradio.Image(invert_colors=True, type=\"numpy\")\\n```\\n\\nPostprocessing is a lot easier! Gradio automatically recognizes the format of the returned data (e.g. is the `Image` a `numpy` array or a `str` filepath?) and postprocesses it into a', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/01_getting-started/02_key-features.md'}, lookup_index=0),\n",
              " Document(page_content='format that can be displayed by the browser.\\n\\nTake a look at the [Docs](https://gradio.app/docs) to see all the preprocessing-related parameters for each Component.\\n\\n\\n## Styling\\n\\nMany components can be styled through the `style()` method. For example:\\n\\n```python\\nimg = gr.Image(\"lion.jpg\").style(height=\\'24\\', rounded=False)\\n```\\n\\nTake a look at the [Docs](https://gradio.app/docs) to see all the styling options for each Component.\\n\\nFor additional styling ability, you can pass any CSS to your app using the `css=` kwarg.\\nThe base class for the Gradio app is `gradio-container`, so here\\'s an example that changes the background color of the Gradio app:\\n\\n```python\\nwith gr.Interface(css=\".gradio-container {background-color: red}\") as demo:\\n    ...\\n```\\n\\n## Queuing\\n\\nIf your app expects heavy traffic, use the `queue()` method to control processing rate. This will queue up calls so only a certain number of requests are processed at a single time. Queueing uses websockets, which also prevent network timeouts, so you should use queueing if the inference time of your function is long (> 1min). \\n\\nWith `Interface`:\\n```python\\ndemo =', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/01_getting-started/02_key-features.md'}, lookup_index=0),\n",
              " Document(page_content='gr.Interface(...).queue()\\ndemo.launch()\\n```\\n\\nWith `Blocks`:\\n```python\\nwith gr.Blocks() as demo:\\n    #...\\ndemo.queue()\\ndemo.launch()\\n```\\n\\nYou can control the number of requests processsed at a single time as such:\\n\\n```python\\ndemo.queue(concurrency_count=3)\\n```\\n\\nSee the [Docs on queueing](/docs/#queue) on configuring other queuing parameters.\\n\\nTo specify only certain functions for queueing in Blocks:\\n```python\\nwith gr.Blocks() as demo2:\\n    num1 = gr.Number()\\n    num2 = gr.Number()\\n    output = gr.Number()\\n    gr.Button(\"Add\").click(\\n        lambda a, b: a + b, [num1, num2], output)\\n    gr.Button(\"Multiply\").click(\\n        lambda a, b: a * b, [num1, num2], output, queue=True)\\ndemo2.launch()\\n```\\n\\n## Iterative Outputs\\n\\nIn some cases, you may want to show a sequence of outputs rather than a single output. For example, you might have an image generation model and you want to show the image that is generated at each step, leading up to the final image.\\n\\nIn such cases, you can supply a **generator** function into Gradio instead of a regular function. Creating generators in Python is very simple: instead of a single `return` value, a function should `yield` a series of values instead. Usually the', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/01_getting-started/02_key-features.md'}, lookup_index=0),\n",
              " Document(page_content=\"`yield` statement is put in some kind of loop. Here's an example of an generator that simply counts up to a given number:\\n\\n```python\\ndef my_generator(x):\\n    for i in range(x):\\n        yield i\\n```\\n\\nYou supply a generator into Gradio the same way as you would a regular function. For example, here's a a (fake) image generation model that generates noise for several steps before outputting an image:\\n\\n$code_fake_diffusion\\n$demo_fake_diffusion\\n\\nNote that we've added a `time.sleep(1)` in the iterator to create an artificial pause between steps so that you are able to observe the steps of the iterator (in a real image generation model, this probably wouldn't be necessary).\\n\\nSupplying a generator into Gradio **requires** you to enable queuing in the underlying Interface or Blocks (see the queuing section above).\\n\\n## Progress Bars\\n\\nGradio supports the ability to create a custom Progress Bars so that you have customizability and control over the progress update that you show to the user. In order to enable this, simply add an argument to your method that has a default value of a `gradio.Progress` instance. Then you can update the progress levels by calling this instance directly with a float between 0 and 1, or\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/01_getting-started/02_key-features.md'}, lookup_index=0),\n",
              " Document(page_content=\"using the `tqdm()` method of the `Progress` instance to track progress over an iterable, as shown below. Queueing must be enabled for progress updates.\\n\\n$code_progress_simple\\n$demo_progress_simple\\n\\nIf you use the `tqdm` library, you can even report progress updates automatically from any `tqdm.tqdm` that already exists within your function by setting the default argument as  `gr.Progress(track_tqdm=True)`!\\n\\n## Batch Functions\\n\\nGradio supports the ability to pass *batch* functions. Batch functions are just\\nfunctions which take in a list of inputs and return a list of predictions.\\n\\nFor example, here is a batched function that takes in two lists of inputs (a list of \\nwords and a list of ints), and returns a list of trimmed words as output:\\n\\n```py\\nimport time\\n\\ndef trim_words(words, lens):\\n    trimmed_words = []\\n    time.sleep(5)\\n    for w, l in zip(words, lens):\\n        trimmed_words.append(w[:int(l)])        \\n    return [trimmed_words]\\n```\\n\\nThe advantage of using batched functions is that if you enable queuing, the Gradio\\nserver can automatically *batch* incoming requests and process them in parallel, \\npotentially speeding up your demo. Here's what the Gradio code looks like (notice\\nthe\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/01_getting-started/02_key-features.md'}, lookup_index=0),\n",
              " Document(page_content='`batch=True` and `max_batch_size=16` -- both of these parameters can be passed\\ninto event triggers or into the `Interface` class) \\n\\nWith `Interface`:\\n```python\\ndemo = gr.Interface(trim_words, [\"textbox\", \"number\"], [\"output\"], \\n                    batch=True, max_batch_size=16)\\ndemo.queue()\\ndemo.launch()\\n```\\n\\n\\nWith `Blocks`:\\n```py\\nimport gradio as gr\\n\\nwith gr.Blocks() as demo:\\n    with gr.Row():\\n        word = gr.Textbox(label=\"word\")\\n        leng = gr.Number(label=\"leng\")\\n        output = gr.Textbox(label=\"Output\")\\n    with gr.Row():\\n        run = gr.Button()\\n\\n    event = run.click(trim_words, [word, leng], output, batch=True, max_batch_size=16)\\n\\ndemo.queue()\\ndemo.launch()\\n```\\n\\nIn the example above, 16 requests could be processed in parallel (for a total inference\\ntime of 5 seconds), instead of each request being processed separately (for a total\\ninference time of 80 seconds).\\n\\nSupplying a generator into Gradio **requires** you to enable queuing in the underlying Interface or Blocks (see the queuing section above).\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/01_getting-started/02_key-features.md'}, lookup_index=0),\n",
              " Document(page_content='# Quickstart\\n\\n**Prerequisite**: Gradio requires Python 3.7 or higher, that\\'s all!\\n\\n## What Does Gradio Do?\\n\\nOne of the *best ways to share* your machine learning model, API, or data science workflow with others is to create an **interactive app** that allows your users or colleagues to try out the demo in their browsers.\\n\\nGradio allows you to **build demos and share them, all in Python.** And usually in just a few lines of code! So let\\'s get started.\\n\\n## Hello, World\\n\\nTo get Gradio running with a simple \"Hello, World\" example, follow these three steps:\\n\\n1\\\\. Install Gradio using pip:\\n\\n```bash\\npip install gradio\\n```\\n\\n2\\\\. Run the code below as a Python script or in a Jupyter Notebook (or [Google Colab](https://colab.research.google.com/drive/18ODkJvyxHutTN0P5APWyGFO_xwNcgHDZ?usp=sharing)):\\n\\n$code_hello_world\\n\\n3\\\\. The demo below will appear automatically within the Jupyter Notebook, or pop in a browser on [http://localhost:7860](http://localhost:7860) if running from a script:\\n\\n$demo_hello_world\\n\\n## The `Interface` Class\\n\\nYou\\'ll notice that in order to make the demo, we created a `gradio.Interface`. This `Interface` class can wrap any Python function with a user', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/01_getting-started/01_quickstart.md'}, lookup_index=0),\n",
              " Document(page_content='interface. In the example above, we saw a simple text-based function, but the function could be anything from music generator to a tax calculator to the prediction function of a pretrained machine learning model.\\n\\nThe core `Interface` class is initialized with three required parameters:\\n\\n- `fn`: the function to wrap a UI around\\n- `inputs`: which component(s) to use for the input (e.g. `\"text\"`, `\"image\"` or `\"audio\"`)\\n- `outputs`: which component(s) to use for the output (e.g. `\"text\"`, `\"image\"` or `\"label\"`)\\n\\nLet\\'s take a closer look at these components used to provide input and output.\\n\\n## Components Attributes\\n\\nWe saw some simple `Textbox` components in the previous examples, but what if you want to change how the UI components look or behave?\\n\\nLet\\'s say you want to customize the input text field — for example, you wanted it to be larger and have a text placeholder. If we use the actual class for `Textbox` instead of using the string shortcut, you have access to much more customizability through component attributes.\\n\\n$code_hello_world_2\\n$demo_hello_world_2\\n\\n## Multiple Input and Output Components\\n\\nSuppose you had a more complex function, with multiple inputs and outputs. In the', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/01_getting-started/01_quickstart.md'}, lookup_index=0),\n",
              " Document(page_content='example below, we define a function that takes a string, boolean, and number, and returns a string and number. Take a look how you pass a list of input and output components.\\n\\n$code_hello_world_3\\n$demo_hello_world_3\\n\\nYou simply wrap the components in a list. Each component in the `inputs` list corresponds to one of the parameters of the function, in order. Each component in the `outputs` list corresponds to one of the values returned by the function, again in order.\\n\\n## An Image Example\\n\\nGradio supports many types of components, such as `Image`, `DataFrame`, `Video`, or `Label`. Let\\'s try an image-to-image function to get a feel for these!\\n\\n$code_sepia_filter\\n$demo_sepia_filter\\n\\nWhen using the `Image` component as input, your function will receive a NumPy array with the shape `(width, height, 3)`, where the last dimension represents the RGB values. We\\'ll return an image as well in the form of a NumPy array.\\n\\nYou can also set the datatype used by the component with the `type=` keyword argument. For example, if you wanted your function to take a file path to an image instead of a NumPy array, the input `Image` component could be written as:\\n\\n```python\\ngr.Image(type=\"filepath\",', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/01_getting-started/01_quickstart.md'}, lookup_index=0),\n",
              " Document(page_content=\"shape=...)\\n```\\n\\nAlso note that our input `Image` component comes with an edit button 🖉, which allows for cropping and zooming into images. Manipulating images in this way can help reveal biases or hidden flaws in a machine learning model!\\n\\nYou can read more about the many components and how to use them in the [Gradio docs](https://gradio.app/docs).\\n\\n## Blocks: More Flexibility and Control\\n\\nGradio offers two classes to build apps:\\n\\n1\\\\. **Interface**, that provides a high-level abstraction for creating demos that we've been discussing so far.\\n\\n2\\\\. **Blocks**, a low-level API for designing web apps with more flexible layouts and data flows. Blocks allows you to do things like feature multiple data flows and demos, control where components appear on the page, handle complex data flows (e.g. outputs can serve as inputs to other functions), and update properties/visibility of components based on user interaction — still all in Python. If this customizability is what you need, try `Blocks` instead!\\n\\n## Hello, Blocks\\n\\nLet's take a look at a simple example. Note how the API here differs from `Interface`.\\n\\n$code_hello_blocks\\n$demo_hello_blocks\\n\\nThings to note:\\n\\n- `Blocks` are made with a\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/01_getting-started/01_quickstart.md'}, lookup_index=0),\n",
              " Document(page_content=\"`with` clause, and any component created inside this clause is automatically added to the app.\\n- Components appear vertically in the app in the order they are created. (Later we will cover customizing layouts!)\\n- A `Button` was created, and then a `click` event-listener was added to this button. The API for this should look familiar! Like an `Interface`, the `click` method takes a Python function, input components, and output components.\\n\\n## More Complexity\\n\\nHere's an app to give you a taste of what's possible with `Blocks`:\\n\\n$code_blocks_flipper\\n$demo_blocks_flipper\\n\\nA lot more going on here! We'll cover how to create complex `Blocks` apps like this in the [building with blocks](https://gradio.app/building_with_blocks) section for you.\\n\\nCongrats, you're now familiar with the basics of Gradio! 🥳 Go to our [next guide](https://gradio.app/key_features) to learn more about the key features of Gradio.\\n\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/01_getting-started/01_quickstart.md'}, lookup_index=0),\n",
              " Document(page_content=\"# Blocks and Event Listeners\\n\\nWe took a quick look at Blocks in the [Quickstart](https://gradio.app/quickstart/#blocks-more-flexibility-and-control). Let's dive deeper. This guide will cover the how Blocks are structured, event listeners and their types, running events continuously, updating configurations, and using dictionaries vs lists. \\n\\n## Blocks Structure\\n\\nTake a look at the demo below.\\n\\n$code_hello_blocks\\n$demo_hello_blocks\\n\\n- First, note the `with gr.Blocks() as demo:` clause. The Blocks app code will be contained within this clause.\\n- Next come the Components. These are the same Components used in `Interface`. However, instead of being passed to some constructor, Components are automatically added to the Blocks as they are created within the `with` clause.\\n- Finally, the `click()` event listener. Event listeners define the data flow within the app. In the example above, the listener ties the two Textboxes together. The Textbox `name` acts as the input and Textbox `output` acts as the output to the `greet` method. This dataflow is triggered when the Button `greet_btn` is clicked. Like an Interface, an event listener can take multiple inputs or outputs.\\n\\n## Event\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/03_building-with-blocks/01_blocks-and-event-listeners.md'}, lookup_index=0),\n",
              " Document(page_content='Listeners and Interactivity\\n\\nIn the example above, you\\'ll notice that you are able to edit Textbox `name`, but not Textbox `output`. This is because any Component that acts as an input to an event listener is made interactive. However, since Textbox `output` acts only as an output, it is not interactive. You can directly configure the interactivity of a Component with the `interactive=` keyword argument. \\n\\n```python\\noutput = gr.Textbox(label=\"Output\", interactive=True)\\n```\\n\\n## Types of Event Listeners\\n\\nTake a look at the demo below:\\n\\n$code_blocks_hello\\n$demo_blocks_hello\\n\\nInstead of being triggered by a click, the `welcome` function is triggered by typing in the Textbox `inp`. This is due to the `change()` event listener. Different Components support different event listeners. For example, the `Video` Component supports a `play()` event listener, triggered when a user presses play. See the [Docs](http://gradio.app/docs#components) for the event listeners for each Component.\\n\\n## Running Events Continuously\\n\\nYou can run events on a fixed schedule using the `every` parameter of the event listener. This will run the event\\n`every` number of seconds while the client', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/03_building-with-blocks/01_blocks-and-event-listeners.md'}, lookup_index=0),\n",
              " Document(page_content='connection is open. If the connection is closed, the event will stop running after the following iteration.\\nNote that this does not take into account the runtime of the event itself. So a function\\nwith a 1 second runtime running with `every=5`, would actually run every 6 seconds.\\n\\nHere is an example of a sine curve that updates every second!\\n\\n$code_sine_curve\\n$demo_sine_curve\\n\\n## Multiple Data Flows\\n\\nA Blocks app is not limited to a single data flow the way Interfaces are. Take a look at the demo below:\\n\\n$code_reversible_flow\\n$demo_reversible_flow\\n\\nNote that `num1` can act as input to `num2`, and also vice-versa! As your apps get more complex, you will have many data flows connecting various Components. \\n\\nHere\\'s an example of a \"multi-step\" demo, where the output of one model (a speech-to-text model) gets fed into the next model (a sentiment classifier).\\n\\n$code_blocks_speech_text_sentiment\\n$demo_blocks_speech_text_sentiment\\n\\n## Function Input List vs Dict\\n\\nThe event listeners you\\'ve seen so far have a single input component. If you\\'d like to have multiple input components pass data to the function, you have two options on how the function can accept input component values:\\n\\n1.', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/03_building-with-blocks/01_blocks-and-event-listeners.md'}, lookup_index=0),\n",
              " Document(page_content=\"as a list of arguments, or\\n2. as a single dictionary of values, keyed by the component\\n\\nLet's see an example of each:\\n$code_calculator_list_and_dict\\n\\nBoth `add()` and `sub()` take `a` and `b` as inputs. However, the syntax is different between these listeners. \\n\\n1. To the `add_btn` listener, we pass the inputs as a list. The function `add()` takes each of these inputs as arguments. The value of `a` maps to the argument `num1`, and the value of `b` maps to the argument `num2`.\\n2. To the `sub_btn` listener, we pass the inputs as a set (note the curly brackets!). The function `sub()` takes a single dictionary argument `data`, where the keys are the input components, and the values are the values of those components.\\n\\nIt is a matter of preference which syntax you prefer! For functions with many input components, option 2 may be easier to manage.\\n\\n$demo_calculator_list_and_dict\\n\\n## Function Return List vs Dict\\n\\nSimilarly, you may return values for multiple output components either as:\\n\\n1. a list of values, or\\n2. a dictionary keyed by the component\\n\\nLet's first see an example of (1), where we set the values of two output components by returning two values:\\n\\n```python\\nwith gr.Blocks() as demo:\\n   \", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/03_building-with-blocks/01_blocks-and-event-listeners.md'}, lookup_index=0),\n",
              " Document(page_content='   food_box = gr.Number(value=10, label=\"Food Count\")\\n    status_box = gr.Textbox()\\n    def eat(food):\\n        if food > 0:\\n            return food - 1, \"full\"\\n        else:\\n            return 0, \"hungry\"\\n    gr.Button(\"EAT\").click(\\n        fn=eat, \\n        inputs=food_box,\\n        outputs=[food_box, status_box]\\n    )\\n```\\n\\nAbove, each return statement returns two values corresponding to `food_box` and `status_box`, respectively.\\n\\nInstead of returning a list of values corresponding to each output component in order, you can also return a dictionary, with the key corresponding to the output component and the value as the new value. This also allows you to skip updating some output components. \\n\\n```python\\nwith gr.Blocks() as demo:\\n    food_box = gr.Number(value=10, label=\"Food Count\")\\n    status_box = gr.Textbox()\\n    def eat(food):\\n        if food > 0:\\n            return {food_box: food - 1, status_box: \"full\"}\\n        else:\\n            return {status_box: \"hungry\"}\\n    gr.Button(\"EAT\").click(\\n        fn=eat, \\n        inputs=food_box,\\n        outputs=[food_box, status_box]\\n    )\\n```\\n\\nNotice how when there is no food, we only update the `status_box` element. We skipped updating the `food_box` component.\\n\\nDictionary returns are helpful when an event listener affects many components on return, or', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/03_building-with-blocks/01_blocks-and-event-listeners.md'}, lookup_index=0),\n",
              " Document(page_content='conditionally affects outputs and not others.\\n\\nKeep in mind that with dictionary returns, we still need to specify the possible outputs in the event listener.\\n\\n## Updating Component Configurations\\n\\nThe return value of an event listener function is usually the updated value of the corresponding output Component. Sometimes we want to update the configuration of the Component as well, such as the visibility. In this case, we return a `gr.update()` object instead of just the update Component value.\\n\\n$code_blocks_essay_update\\n$demo_blocks_essay_update\\n\\nSee how we can configure the Textbox itself through the `gr.update()` method. The `value=` argument can still be used to update the value along with Component configuration.\\n\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/03_building-with-blocks/01_blocks-and-event-listeners.md'}, lookup_index=0),\n",
              " Document(page_content='# Using Gradio Blocks Like Functions\\nTags: TRANSLATION, HUB, SPACES\\n\\n\\n**Prerequisite**: This Guide builds on the Blocks Introduction. Make sure to [read that guide first](https://gradio.app/quickstart/#blocks-more-flexibility-and-control).\\n\\n## Introduction\\n\\nDid you know that apart from being a full-stack machine learning demo, a Gradio Blocks app is also a regular-old python function!?\\n\\nThis means that if you have a gradio Blocks (or Interface) app called `demo`, you can use `demo` like you would any python function.\\n\\nSo doing something like `output = demo(\"Hello\", \"friend\")` will run the first event defined in `demo` on the inputs \"Hello\" and \"friend\" and store it\\nin the variable `output`.\\n\\nIf I put you to sleep 🥱, please bear with me! By using apps like functions, you can seamlessly compose Gradio apps.\\nThe following section will show how.\\n\\n## Treating spaces like functions\\n\\nLet\\'s say we have the following demo that translates english text to german text. \\n\\n$code_english_translator\\n\\nI already went ahead and hosted it in Hugging Face spaces at [gradio/english_translator](https://huggingface.co/spaces/gradio/english_translator).\\n\\nYou can see the demo below as', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/03_building-with-blocks/05_using-blocks-like-functions.md'}, lookup_index=0),\n",
              " Document(page_content=\"well:\\n\\n$demo_english_translator\\n\\nNow, let's say you have an app that generates english text, but you wanted to additionally generate german text.\\n\\nYou could either:\\n\\n1. Copy the source code of my english-to-german translation and paste it in your app.\\n\\n2. Load my english-to-german translation in your app and treat it like a normal python function.\\n\\nOption 1 technically always works, but it often introduces unwanted complexity.\\n\\nOption 2 lets you borrow the functionality you want without tightly coupling our apps.\\n\\nAll you have to do is call the `Blocks.load` class method in your source file.\\nAfter that, you can use my translation app like a regular python function!\\n\\nThe following code snippet and demo shows how to use `Blocks.load`.\\n\\nNote that the variable `english_translator` is my english to german app, but its used in `generate_text` like a regular function.\\n\\n$code_generate_english_german\\n\\n$demo_generate_english_german\\n\\n## How to control which function in the app to use\\n\\nIf the app you are loading defines more than one function, you can specify which function to use\\nwith the `fn_index` and `api_name` parameters.\\n\\nIn the code for our english to german demo, you'll see the\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/03_building-with-blocks/05_using-blocks-like-functions.md'}, lookup_index=0),\n",
              " Document(page_content='following line:\\n\\n```python\\ntranslate_btn.click(translate, inputs=english, outputs=german, api_name=\"translate-to-german\")\\n```\\n\\nThe `api_name` gives this function a unique name in our app. You can use this name to tell gradio which\\nfunction in the upstream space you want to use:\\n\\n```python\\nenglish_generator(text, api_name=\"translate-to-german\")[0][\"generated_text\"]\\n```\\n\\nYou can also use the `fn_index` parameter.\\nImagine my app also defined an english to spanish translation function.\\nIn order to use it in our text generation app, we would use the following code:\\n\\n```python\\nenglish_generator(text, fn_index=1)[0][\"generated_text\"]\\n```\\n\\nFunctions in gradio spaces are zero-indexed, so since the spanish translator would be the second function in my space,\\nyou would use index 1. \\n\\n## Parting Remarks\\n\\nWe showed how treating a Blocks app like a regular python helps you compose functionality across different apps.\\nAny Blocks app can be treated like a function, but a powerful pattern is to `load` an app hosted on \\n[Hugging Face Spaces](https://huggingface.co/spaces) prior to treating it like a function in your own app.\\nYou can also load models hosted on the', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/03_building-with-blocks/05_using-blocks-like-functions.md'}, lookup_index=0),\n",
              " Document(page_content='[Hugging Face Model Hub](https://huggingface.co/models) - see the [Using Hugging Face Integrations](/using_hugging_face_integrations) guide for an example.\\n\\n### Happy building! ⚒️\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/03_building-with-blocks/05_using-blocks-like-functions.md'}, lookup_index=0),\n",
              " Document(page_content='# Custom JS and CSS\\n\\nThis guide covers how to style Blocks with more flexibility, as well as adding Javascript code to event listeners. \\n\\n## Custom CSS\\n\\nFor additional styling ability, you can pass any CSS to your app using the `css=` kwarg.\\n\\nThe base class for the Gradio app is `gradio-container`, so here\\'s an example that changes the background color of the Gradio app:\\n```python\\nwith gr.Blocks(css=\".gradio-container {background-color: red}\") as demo:\\n    ...\\n```\\n\\nIf you\\'d like to reference external files in your css, preface the file path (which can be a relative or absolute path) with `\"file=\"`, for example:\\n\\n```python\\nwith gr.Blocks(css=\".gradio-container {background-image: url(\\'file=clouds.jpg\\')}\") as demo:\\n    ...\\n```\\n\\nYou can also pass the filepath to a CSS file to the `css` argument.\\n\\n## The `elem_id` Argument\\n\\nYou can `elem_id` to add an HTML element `id` to any component. This will allow you to select elements more easily with CSS.\\n\\n```python\\nwith gr.Blocks(css=\"#warning {color: red}\") as demo:\\n    box1 = gr.Textbox(value=\"Good Job\")\\n    box2 = gr.Textbox(value=\"Failure\", elem_id=\"warning\")\\n```\\n\\nThe CSS ruleset will only target the second Textbox here.\\n\\n## Custom', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/03_building-with-blocks/04_custom-CSS-and-JS.md'}, lookup_index=0),\n",
              " Document(page_content='JS\\n\\nEvent listeners have a `_js` argument that can take a Javascript function as a string and treat it just like a Python event listener function. You can pass both a Javascript function and a Python function (in which case the Javascript function is run first) or only Javascript (and set the Python `fn` to `None`). Take a look at the code below:\\n\\n$code_blocks_js_methods\\n$demo_blocks_js_methods', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/03_building-with-blocks/04_custom-CSS-and-JS.md'}, lookup_index=0),\n",
              " Document(page_content='# Controlling Layout\\n\\nBy default, Components in Blocks are arranged vertically. Let\\'s take a look at how we can rearrange Components. Under the hood, this layout structure uses the [flexbox model of web development](https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Flexible_Box_Layout/Basic_Concepts_of_Flexbox).\\n\\n## Rows\\n\\nElements within a `with gr.Row` clause will all be displayed horizontally. For example, to display two Buttons side by side:\\n\\n```python\\nwith gr.Blocks() as demo:\\n    with gr.Row():\\n        btn1 = gr.Button(\"Button 1\")\\n        btn2 = gr.Button(\"Button 2\")\\n```\\n\\nTo make every element in a Row have the same height, use the `equal_height` argument.\\n\\n```python\\nwith gr.Blocks() as demo:\\n    with gr.Row(equal_height=True):\\n        textbox = gr.Textbox()\\n        btn2 = gr.Button(\"Button 2\")\\n```\\n\\nLearn more about Rows in the [docs](https://gradio.app/docs/#row). \\n\\n## Columns and Nesting\\n\\nComponents within a Column will be placed vertically atop each other. Since the vertical layout is the default layout for Blocks apps anyway, to be useful, Columns are usually  nested within Rows. For example:\\n\\n$code_rows_and_columns\\n$demo_rows_and_columns\\n\\nSee how the first column', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/03_building-with-blocks/02_controlling-layout.md'}, lookup_index=0),\n",
              " Document(page_content=\"has two Textboxes arranged vertically. The second column has an Image and Button arranged vertically. Notice how the relative widths of the two columns is set by the `scale` parameter. The column with twice the `scale` value takes up twice the width. \\n\\nColumns have a `min_width` parameter as well (320 pixels by default). This prevents adjacent columns from becoming too narrow on mobile screens.\\n\\nLearn more about Columns in the [docs](https://gradio.app/docs/#column). \\n\\n## Tabs and Accordions\\n\\nYou can also create Tabs using the `with gradio.Tab('tab_name'):` clause. Any component created inside of a `with gradio.Tab('tab_name'):` context appears in that tab. Consecutive Tab clauses are grouped together so that a single tab can be selected at one time, and only the components within that Tab's context are shown.\\n\\nFor example:\\n\\n$code_blocks_flipper\\n$demo_blocks_flipper\\n\\nAlso note the `gradio.Accordion('label')` in this example. The Accordion is a layout that can be toggled open or closed. Like `Tabs`, it is a layout element that can selectively hide or show content. Any components that are defined inside of a `with gradio.Accordion('label'):` will be hidden or shown when the\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/03_building-with-blocks/02_controlling-layout.md'}, lookup_index=0),\n",
              " Document(page_content=\"accordion's toggle icon is clicked.\\n\\nLearn more about [Tabs](https://gradio.app/docs/#tab) and [Accordions](https://gradio.app/docs/#accordion) in the docs.\\n\\n## Visibility\\n\\nBoth Components and Layout elements have a `visible` argument that can set initially and also updated using `gr.update()`. Setting `gr.update(visible=...)` on a Column can be used to show or hide a set of Components.\\n\\n$code_blocks_form\\n$demo_blocks_form\\n\\n## Defining and Rendering Components Separately\\n\\nIn some cases, you might want to define components before you actually render them in your UI. For instance, you might want to show an examples section using `gr.Examples` above the corresponding `gr.Textbox` input. Since `gr.Examples` requires as a parameter the input component object, you will need to first define the input component, but then render it later, after you have defined the `gr.Examples` object.\\n\\nThe solution to this is to define the `gr.Textbox` outside of the `gr.Blocks()` scope and use the component's `.render()` method wherever you'd like it placed in the UI.\\n\\nHere's a full code example:\\n\\n```python\\ninput_textbox = gr.Textbox()\\n\\nwith gr.Blocks() as demo:\\n   \", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/03_building-with-blocks/02_controlling-layout.md'}, lookup_index=0),\n",
              " Document(page_content='   gr.Examples([\"hello\", \"bonjour\", \"merhaba\"], input_textbox)\\n    input_textbox.render()\\n```\\n\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/03_building-with-blocks/02_controlling-layout.md'}, lookup_index=0),\n",
              " Document(page_content=\"# State in Blocks\\n\\nWe covered [State in Interfaces](https://gradio.app/interface-state), this guide takes a look at state in Blocks, which works mostly the same. \\n\\n## Global State\\n\\nGlobal state in Blocks works the same as in Interface. Any variable created outside a function call is a reference shared between all users.\\n\\n## Session State\\n\\nGradio supports session **state**, where data persists across multiple submits within a page session, in Blocks apps as well. To reiterate, session data is *not* shared between different users of your model. To store data in a session state, you need to do three things:\\n\\n1. Create a `gr.State()` object. If there is a default value to this stateful object, pass that into the constructor.\\n2. In the event listener, put the `State` object as an input and output.\\n3. In the event listener function, add the variable to the input parameters and the return value.\\n\\nLet's take a look at a game of hangman. \\n\\n$code_hangman\\n$demo_hangman\\n\\nLet's see how we do each of the 3 steps listed above in this game:\\n\\n1. We store the used letters in `used_letters_var`. In the constructor of `State`, we set the initial value of this to `[]`, an empty list. \\n2. In `btn.click()`, we have a\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/03_building-with-blocks/03_state-in-blocks.md'}, lookup_index=0),\n",
              " Document(page_content='reference to `used_letters_var` in both the inputs and outputs.\\n3. In `guess_letter`, we pass the value of this `State` to `used_letters`, and then return an updated value of this `State` in the return statement.\\n\\nWith more complex apps, you will likely have many State variables storing session state in a single Blocks app.\\n\\nLearn more about `State` in the [docs](https://gradio.app/docs#state).\\n\\n\\n\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/03_building-with-blocks/03_state-in-blocks.md'}, lookup_index=0),\n",
              " Document(page_content='# Creating a Real-Time Dashboard from BigQuery Data\\n\\nTags: TABULAR, DASHBOARD, PLOTS \\n\\n\\n[Google BigQuery](https://cloud.google.com/bigquery) is a cloud-based service for processing very large data sets. It is a serverless and highly scalable data warehousing solution that enables users to analyze data [using SQL-like queries](https://www.oreilly.com/library/view/google-bigquery-the/9781492044451/ch01.html).\\n\\nIn this tutorial, we will show you how to query a BigQuery dataset in Python and display the data in a dashboard that updates in real time using `gradio`. The dashboard will look like this:\\n\\n<img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/gradio-guides/bigquery-dashboard.gif\">\\n\\nWe\\'ll cover the following steps in this Guide:\\n\\n1. Setting up your BigQuery credentials\\n2. Using the BigQuery client\\n3. Building the real-time dashboard (in just *7 lines of Python*)\\n\\nWe\\'ll be working with the [New York Times\\' COVID dataset](https://www.nytimes.com/interactive/2021/us/covid-cases.html) that is available as a public dataset on BigQuery. The dataset, named `covid19_nyt.us_counties` contains the latest', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/05_tabular-data-science-and-plots/creating-a-dashboard-from-bigquery-data.md'}, lookup_index=0),\n",
              " Document(page_content='information about the number of confirmed cases and deaths from COVID across US counties. \\n\\n**Prerequisites**: This Guide uses [Gradio Blocks](../quickstart/#blocks-more-flexibility-and-control), so make your are familiar with the Blocks class. \\n\\n## Setting up your BigQuery Credentials\\n\\nTo use Gradio with BigQuery, you will need to obtain your BigQuery credentials and use them with the [BigQuery Python client](https://pypi.org/project/google-cloud-bigquery/). If you already have BigQuery credentials (as a `.json` file), you can skip this section. If not, you can do this for free in just a couple of minutes.\\n\\n1. First, log in to your Google Cloud account and go to the Google Cloud Console (https://console.cloud.google.com/)\\n\\n2. In the Cloud Console, click on the hamburger menu in the top-left corner and select \"APIs & Services\" from the menu. If you do not have an existing project, you will need to create one.\\n\\n3. Then, click the \"+ Enabled APIs & services\" button, which allows you to enable specific services for your project. Search for \"BigQuery API\", click on it, and click the \"Enable\" button. If you see the \"Manage\" button, then the BigQuery is already enabled, and you\\'re all set.', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/05_tabular-data-science-and-plots/creating-a-dashboard-from-bigquery-data.md'}, lookup_index=0),\n",
              " Document(page_content='\\n\\n4. In the APIs & Services menu, click on the \"Credentials\" tab and then click on the \"Create credentials\" button.\\n\\n5. In the \"Create credentials\" dialog, select \"Service account key\" as the type of credentials to create, and give it a name. Also grant the service account permissions by giving it a role such as \"BigQuery User\", which will allow you to run queries.\\n\\n6. After selecting the service account, select the \"JSON\" key type and then click on the \"Create\" button. This will download the JSON key file containing your credentials to your computer. It will look something like this:\\n\\n```json\\n{\\n \"type\": \"service_account\",\\n \"project_id\": \"your project\",\\n \"private_key_id\": \"your private key id\",\\n \"private_key\": \"private key\",\\n \"client_email\": \"email\",\\n \"client_id\": \"client id\",\\n \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\\n \"token_uri\": \"https://accounts.google.com/o/oauth2/token\",\\n \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\\n \"client_x509_cert_url\":  \"https://www.googleapis.com/robot/v1/metadata/x509/email_id\"\\n}\\n```\\n\\n## Using the BigQuery Client\\n\\nOnce you have the credentials, you will need to use', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/05_tabular-data-science-and-plots/creating-a-dashboard-from-bigquery-data.md'}, lookup_index=0),\n",
              " Document(page_content='the BigQuery Python client to authenticate using your credentials. To do this, you will need to install the BigQuery Python client by running the following command in the terminal:\\n\\n```bash\\npip install google-cloud-bigquery[pandas]\\n```\\n\\nYou\\'ll notice that we\\'ve installed the pandas add-on, which will be helpful for processing the BigQuery dataset as a pandas dataframe. Once the client is installed, you can authenticate using your credentials by running the following code:\\n\\n```py\\nfrom google.cloud import bigquery\\n\\nclient = bigquery.Client.from_service_account_json(\"path/to/key.json\")\\n```\\n\\nWith your credentials authenticated, you can now use the BigQuery Python client to interact with your BigQuery datasets. \\n\\nHere is an example of a function which queries the `covid19_nyt.us_counties` dataset in BigQuery to show the top 20 counties with the most confirmed cases as of the current day:\\n\\n```py\\nimport numpy as np\\n\\nQUERY = (\\n    \\'SELECT * FROM `bigquery-public-data.covid19_nyt.us_counties` \\' \\n    \\'ORDER BY date DESC,confirmed_cases DESC \\'\\n    \\'LIMIT 20\\')\\n\\ndef run_query():\\n    query_job = client.query(QUERY)  \\n    query_result = query_job.result()  \\n    df =', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/05_tabular-data-science-and-plots/creating-a-dashboard-from-bigquery-data.md'}, lookup_index=0),\n",
              " Document(page_content='query_result.to_dataframe()\\n    # Select a subset of columns \\n    df = df[[\"confirmed_cases\", \"deaths\", \"county\", \"state_name\"]]\\n    # Convert numeric columns to standard numpy types\\n    df = df.astype({\"deaths\": np.int64, \"confirmed_cases\": np.int64})\\n    return df\\n```\\n\\n## Building the Real-Time Dashboard\\n\\nOnce you have a function to query the data, you can use the `gr.DataFrame` component from the Gradio library to display the results in a tabular format. This is a useful way to inspect the data and make sure that it has been queried correctly.\\n\\nHere is an example of how to use the `gr.DataFrame` component to display the results. By passing in the `run_query` function to `gr.DataFrame`, we instruct Gradio to run the function as soon as the page loads and show the results. In addition, you also pass in the keyword `every` to tell the dashboard to refresh every hour (60*60 seconds).\\n\\n```py\\nimport gradio as gr\\n\\nwith gr.Blocks() as demo:\\n    gr.DataFrame(run_query, every=60*60)\\n\\ndemo.queue().launch()  # Run the demo using queuing\\n```\\n\\nPerhaps you\\'d like to add a visualization to our dashboard. You can use the `gr.ScatterPlot()` component to visualize the data in a scatter plot. This allows you to see', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/05_tabular-data-science-and-plots/creating-a-dashboard-from-bigquery-data.md'}, lookup_index=0),\n",
              " Document(page_content='the relationship between different variables such as case count and case deaths in the dataset and can be useful for exploring the data and gaining insights. Again, we can do this in real-time\\nby passing in the `every` parameter. \\n\\nHere is a complete example showing how to use the `gr.ScatterPlot` to visualize in addition to displaying data with the `gr.DataFrame`\\n\\n```py\\nimport gradio as gr\\n\\nwith gr.Blocks() as demo:\\n    gr.Markdown(\"# 💉 Covid Dashboard (Updated Hourly)\")\\n    with gr.Row():\\n        gr.DataFrame(run_query, every=60*60)\\n        gr.ScatterPlot(run_query, every=60*60, x=\"confirmed_cases\", \\n                        y=\"deaths\", tooltip=\"county\", width=500, height=500)\\n\\ndemo.queue().launch()  # Run the demo with queuing enabled\\n```', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/05_tabular-data-science-and-plots/creating-a-dashboard-from-bigquery-data.md'}, lookup_index=0),\n",
              " Document(page_content=\"##\\xa0Using Gradio for Tabular Data Science Workflows\\n\\nRelated spaces: https://huggingface.co/spaces/scikit-learn/gradio-skops-integration, https://huggingface.co/spaces/scikit-learn/tabular-playground, https://huggingface.co/spaces/merve/gradio-analysis-dashboard\\n\\n\\n## Introduction\\n\\nTabular data science is the most widely used domain of machine learning, with problems ranging from customer segmentation to churn prediction. Throughout various stages of the tabular data science workflow, communicating your work to stakeholders or clients can be cumbersome; which prevents data scientists from focusing on what matters, such as data analysis and model building. Data scientists can end up spending hours building a dashboard that takes in dataframe and returning plots, or returning a prediction or plot of clusters in a dataset. In this guide, we'll go through how to use `gradio` to improve your data science workflows. We will also talk about how to use `gradio` and [skops](https://skops.readthedocs.io/en/stable/) to build interfaces with only one line of code!\\n\\n###\\xa0Prerequisites\\n\\nMake sure you have the `gradio` Python package already\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/05_tabular-data-science-and-plots/using-gradio-for-tabular-workflows.md'}, lookup_index=0),\n",
              " Document(page_content='[installed](/getting_started).\\n\\n## Let\\'s Create a Simple Interface!\\n\\nWe will take a look at how we can create a simple UI that predicts failures based on product information. \\n\\n```python\\nimport gradio as gr\\nimport pandas as pd\\nimport joblib\\nimport datasets\\n\\n\\ninputs = [gr.Dataframe(row_count = (2, \"dynamic\"), col_count=(4,\"dynamic\"), label=\"Input Data\", interactive=1)]\\n\\noutputs = [gr.Dataframe(row_count = (2, \"dynamic\"), col_count=(1, \"fixed\"), label=\"Predictions\", headers=[\"Failures\"])]\\n\\nmodel = joblib.load(\"model.pkl\")\\n\\n# we will give our dataframe as example\\ndf = datasets.load_dataset(\"merve/supersoaker-failures\")\\ndf = df[\"train\"].to_pandas()\\n\\ndef infer(input_dataframe):\\n  return pd.DataFrame(model.predict(input_dataframe))\\n  \\ngr.Interface(fn = infer, inputs = inputs, outputs = outputs, examples = [[df.head(2)]]).launch()\\n```\\n\\nLet\\'s break down above code.\\n\\n* `fn`: the inference function that takes input dataframe and returns predictions.\\n* `inputs`: the component we take our input with. We define our input as dataframe with 2 rows and 4 columns, which initially will look like an empty dataframe with the aforementioned shape. When the', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/05_tabular-data-science-and-plots/using-gradio-for-tabular-workflows.md'}, lookup_index=0),\n",
              " Document(page_content='`row_count` is set to `dynamic`, you don\\'t have to rely on the dataset you\\'re inputting to pre-defined component.\\n* `outputs`: The dataframe component that stores outputs. This UI can take single or multiple samples to infer, and returns 0 or 1 for each sample in one column, so we give `row_count` as 2 and `col_count` as 1 above. `headers` is a list made of header names for dataframe.\\n* `examples`: You can either pass the input by dragging and dropping a CSV file, or a pandas DataFrame through examples, which headers will be automatically taken by the interface.\\n\\nWe will now create an example for a minimal data visualization dashboard. You can find a more comprehensive version in the related Spaces.\\n\\n<gradio-app space=\"scikit-learn/tabular-playground\"></gradio-app>\\n\\n```python\\nimport gradio as gr\\nimport pandas as pd\\nimport datasets\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\ndf = datasets.load_dataset(\"merve/supersoaker-failures\")\\ndf = df[\"train\"].to_pandas()\\ndf.dropna(axis=0, inplace=True)\\n\\ndef plot(df):\\n  plt.scatter(df.measurement_13, df.measurement_15, c = df.loading,alpha=0.5)\\n  plt.savefig(\"scatter.png\")\\n ', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/05_tabular-data-science-and-plots/using-gradio-for-tabular-workflows.md'}, lookup_index=0),\n",
              " Document(page_content=' df[\\'failure\\'].value_counts().plot(kind=\\'bar\\')\\n  plt.savefig(\"bar.png\")\\n  sns.heatmap(df.select_dtypes(include=\"number\").corr())\\n  plt.savefig(\"corr.png\")\\n  plots = [\"corr.png\",\"scatter.png\", \"bar.png\"]\\n  return plots\\n  \\ninputs = [gr.Dataframe(label=\"Supersoaker Production Data\")]\\noutputs = [gr.Gallery(label=\"Profiling Dashboard\").style(grid=(1,3))]\\n\\ngr.Interface(plot, inputs=inputs, outputs=outputs, examples=[df.head(100)], title=\"Supersoaker Failures Analysis Dashboard\").launch()\\n```\\n\\n<gradio-app space=\"merve/gradio-analysis-dashboard-minimal\"></gradio-app>\\n\\nWe will use the same dataset we used to train our model, but we will make a dashboard to visualize it this time. \\n\\n* `fn`: The function that will create plots based on data.\\n* `inputs`: We use the same `Dataframe` component we used above.\\n* `outputs`: The `Gallery` component is used to keep our visualizations.\\n* `examples`: We will have the dataset itself as the example.\\n\\n## Easily load tabular data interfaces with one line of code using skops\\n\\n`skops` is a library built on top of `huggingface_hub` and `sklearn`. With the recent `gradio` integration of `skops`, you can build', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/05_tabular-data-science-and-plots/using-gradio-for-tabular-workflows.md'}, lookup_index=0),\n",
              " Document(page_content='tabular data interfaces with one line of code!\\n\\n```python\\nimport gradio as gr\\n\\n# title and description are optional\\ntitle = \"Supersoaker Defective Product Prediction\"\\ndescription = \"This model predicts Supersoaker production line failures. Drag and drop any slice from dataset or edit values as you wish in below dataframe component.\"\\n\\ngr.Interface.load(\"huggingface/scikit-learn/tabular-playground\", title=title, description=description).launch()\\n```\\n\\n<gradio-app space=\"scikit-learn/gradio-skops-integation\"></gradio-app>\\n\\n`sklearn` models pushed to Hugging Face Hub using `skops` include a `config.json` file that contains an example input  with column names, the task being solved (that can either be `tabular-classification` or `tabular-regression`). From the task type, `gradio` constructs the `Interface` and consumes column names and the example input to build it. You can [refer to skops documentation on hosting models on Hub](https://skops.readthedocs.io/en/latest/auto_examples/plot_hf_hub.html#sphx-glr-auto-examples-plot-hf-hub-py) to learn how to push your models to Hub using `skops`.\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/05_tabular-data-science-and-plots/using-gradio-for-tabular-workflows.md'}, lookup_index=0),\n",
              " Document(page_content=\"# How to Use the Plot Component for Maps\\n\\nRelated spaces: \\nTags: PLOTS, MAPS\\n\\n## Introduction\\n\\nThis guide explains how you can use Gradio to plot geographical data on a map using the `gradio.Plot` component. The Gradio `Plot` component works with Matplotlib, Bokeh and Plotly. Plotly is what we will be working with in this guide. Plotly allows developers to easily create all sorts of maps with their geographical data. Take a look [here](https://plotly.com/python/maps/) for some examples.\\n\\n## Overview \\n    \\nWe will be using the New York City Airbnb dataset, which is hosted on kaggle [here](https://www.kaggle.com/datasets/dgomonov/new-york-city-airbnb-open-data). I've uploaded it to the Hugging Face Hub as a dataset [here](https://huggingface.co/datasets/gradio/NYC-Airbnb-Open-Data) for easier use and download. Using this data we will plot Airbnb locations on a map output and allow filtering based on price and location. Below is the demo that we will be building. ⚡️\\n\\n$demo_map_airbnb\\n\\n## Step 1 - Loading CSV data 💾\\n\\nLet's start by loading the Airbnb NYC data from the Hugging Face Hub.\\n\\n```python\\nfrom datasets import load_dataset\\n\\ndataset =\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/05_tabular-data-science-and-plots/plot-component-for-maps.md'}, lookup_index=0),\n",
              " Document(page_content='load_dataset(\"gradio/NYC-Airbnb-Open-Data\", split=\"train\")\\ndf = dataset.to_pandas()\\n\\ndef filter_map(min_price, max_price, boroughs):\\n    new_df = df[(df[\\'neighbourhood_group\\'].isin(boroughs)) & \\n            (df[\\'price\\'] > min_price) & (df[\\'price\\'] < max_price)]\\n    names = new_df[\"name\"].tolist()\\n    prices = new_df[\"price\"].tolist()\\n    text_list = [(names[i], prices[i]) for i in range(0, len(names))]\\n```\\n\\nIn the code above, we first load the csv data into a pandas dataframe. Let\\'s begin by defining a function that we will use as the prediction function for the gradio app. This function will accept the minimum price and maximum price range as well as the list of boroughs to filter the resulting map. We can use the passed in values (`min_price`, `max_price`, and list of `boroughs`) to filter the dataframe and create `new_df`. Next we will create `text_list` of the names and prices of each Airbnb to use as labels on the map.\\n \\n## Step 2 - Map Figure 🌐\\n\\nPlotly makes it easy to work with maps. Let\\'s take a look below how we can create a map figure.\\n\\n```python\\nimport plotly.graph_objects as go\\n\\nfig = go.Figure(go.Scattermapbox(\\n            customdata=text_list,\\n            lat=new_df[\\'latitude\\'].tolist(),\\n           ', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/05_tabular-data-science-and-plots/plot-component-for-maps.md'}, lookup_index=0),\n",
              " Document(page_content='           lon=new_df[\\'longitude\\'].tolist(),\\n            mode=\\'markers\\',\\n            marker=go.scattermapbox.Marker(\\n                size=6\\n            ),\\n            hoverinfo=\"text\",\\n            hovertemplate=\\'<b>Name</b>: %{customdata[0]}<br><b>Price</b>: $%{customdata[1]}\\'\\n        ))\\n\\nfig.update_layout(\\n    mapbox_style=\"open-street-map\",\\n    hovermode=\\'closest\\',\\n    mapbox=dict(\\n        bearing=0,\\n        center=go.layout.mapbox.Center(\\n            lat=40.67,\\n            lon=-73.90\\n        ),\\n        pitch=0,\\n        zoom=9\\n    ),\\n)\\n```\\n\\nAbove, we create a scatter plot on mapbox by passing it our list of latitudes and longitudes to plot markers.  We also pass in our custom data of names and prices for additional info to appear on every marker we hover over. Next we use `update_layout` to specify other map settings such as zoom, and centering.\\n\\nMore info [here](https://plotly.com/python/scattermapbox/) on scatter plots using Mapbox and Plotly.\\n\\n\\n## Step 3 - Gradio App ⚡️\\nWe will use two `gradio.Number` components and a `gradio.CheckboxGroup` to allow users of our app to specify price ranges and borough locations. We will then use the `gr.Plot` component as an output for our Plotly + Mapbox map we created earlier.\\n\\n```python\\nwith gr.Blocks() as demo:\\n    with gr.Column():\\n        with gr.Row():\\n            min_price', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/05_tabular-data-science-and-plots/plot-component-for-maps.md'}, lookup_index=0),\n",
              " Document(page_content='= gr.Number(value=250, label=\"Minimum Price\")\\n            max_price = gr.Number(value=1000, label=\"Maximum Price\")\\n        boroughs = gr.CheckboxGroup(choices=[\"Queens\", \"Brooklyn\", \"Manhattan\", \"Bronx\", \"Staten Island\"], value=[\"Queens\", \"Brooklyn\"], label=\"Select Boroughs:\")\\n        btn = gr.Button(value=\"Update Filter\")\\n        map = gr.Plot()\\n    demo.load(filter_map, [min_price, max_price, boroughs], map)\\n    btn.click(filter_map, [min_price, max_price, boroughs], map)\\n```\\n\\nWe layout these components using the `gr.Column` and `gr.Row` and wel also add event triggers for when the demo first loads and when our \"Update Filter\" button is clicked in order to trigger the map to update with our new filters.\\n\\nThis is what the full demo code looks like:\\n\\n$code_map_airbnb\\n\\n## Step 4 - Deployment 🤗\\nIf you run the code above, your app will start running locally.\\nYou can even get a temporary shareable link by passing the `share=True` parameter to `launch`.\\n\\nBut what if you want to a permanent deployment solution?\\nLet\\'s deploy our Gradio app to the free HuggingFace Spaces platform.\\n\\nIf you haven\\'t used Spaces before, follow the previous guide [here](/using_hugging_face_integrations).\\n\\n##', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/05_tabular-data-science-and-plots/plot-component-for-maps.md'}, lookup_index=0),\n",
              " Document(page_content=\"Conclusion 🎉\\nAnd you're all done! That's all the code you need to build a map demo.\\n\\nHere's a link to the demo [Map demo](https://huggingface.co/spaces/gradio/map_airbnb) and [complete code](https://huggingface.co/spaces/gradio/map_airbnb/blob/main/run.py) (on Hugging Face Spaces)\\n\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/05_tabular-data-science-and-plots/plot-component-for-maps.md'}, lookup_index=0),\n",
              " Document(page_content='# Creating a Real-Time Dashboard from Google Sheets\\n\\nTags: TABULAR, DASHBOARD, PLOTS \\n\\n[Google Sheets](https://www.google.com/sheets/about/) are an easy way to store tabular data in the form of spreadsheets. With Gradio and pandas, it\\'s easy to read data from public or private Google Sheets and then display the data or plot it. In this blog post, we\\'ll build a small *real-time* dashboard, one that updates when the data in the Google Sheets updates. \\n\\nBuilding the dashboard itself will just be 9 lines of Python code using Gradio, and our final dashboard will look like this:\\n\\n<gradio-app space=\"gradio/line-plot\"></gradio-app>\\n\\n**Prerequisites**: This Guide uses [Gradio Blocks](../quickstart/#blocks-more-flexibility-and-control), so make you are familiar with the Blocks class. \\n\\nThe process is a little different depending on if you are working with a publicly accessible or a private Google Sheet. We\\'ll cover both, so let\\'s get started!\\n\\n## Public Google Sheets\\n\\nBuilding a dashboard from a public Google Sheet is very easy, thanks to the [`pandas` library](https://pandas.pydata.org/):\\n\\n1\\\\. Get the URL of the Google Sheets that you want to use. To do this, simply go to the Google', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/05_tabular-data-science-and-plots/creating-a-realtime-dashboard-from-google-sheets.md'}, lookup_index=0),\n",
              " Document(page_content='Sheets, click on the \"Share\" button in the top-right corner, and then click on the \"Get shareable link\" button. This will give you a URL that looks something like this:\\n\\n```html\\nhttps://docs.google.com/spreadsheets/d/1UoKzzRzOCt-FXLLqDKLbryEKEgllGAQUEJ5qtmmQwpU/edit#gid=0\\n```\\n\\n2\\\\. Now, let\\'s modify this URL and then use it to read the data from the Google Sheets into a Pandas DataFrame. (In the code below, replace the `URL` variable with the URL of your public Google Sheet):\\n\\n```python\\nimport pandas as pd\\n\\nURL = \"https://docs.google.com/spreadsheets/d/1UoKzzRzOCt-FXLLqDKLbryEKEgllGAQUEJ5qtmmQwpU/edit#gid=0\"\\ncsv_url = URL.replace(\\'/edit#gid=\\', \\'/export?format=csv&gid=\\')\\n\\ndef get_data():\\n    return pd.read_csv(csv_url)\\n```\\n\\n3\\\\. The data query is a function, which means that it\\'s easy to display it real-time using the the `gr.DataFrame` component, or plot it real-time using the `gr.LinePlot` component (of course, depending on the data, a different plot may be appropriate). To do this, just pass the function into the respective components, and set the `every` parameter based on how frequently (in seconds) you would like the component to refresh. Here\\'s the', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/05_tabular-data-science-and-plots/creating-a-realtime-dashboard-from-google-sheets.md'}, lookup_index=0),\n",
              " Document(page_content='Gradio code:\\n\\n```python\\nimport gradio as gr\\n\\nwith gr.Blocks() as demo:\\n    gr.Markdown(\"# 📈 Real-Time Line Plot\")\\n    with gr.Row():\\n        with gr.Column():\\n            gr.DataFrame(get_data, every=5)\\n        with gr.Column():\\n            gr.LinePlot(get_data, every=5, x=\"Date\", y=\"Sales\", y_title=\"Sales ($ millions)\", overlay_point=True, width=500, height=500)\\n\\ndemo.queue().launch()  # Run the demo with queuing enabled\\n```\\n \\nAnd that\\'s it! You have a dashboard that refreshes every 5 seconds, pulling the data from your Google Sheet.\\n\\n## Private Google Sheets\\n\\nFor private Google Sheets, the process requires a little more work, but not that much! The key difference is that now, you must authenticate yourself to authorize access to the private Google Sheets.\\n\\n### Authentication\\n\\nTo authenticate yourself, obtain credentials from Google Cloud. Here\\'s [how to set up google cloud credentials](https://developers.google.com/workspace/guides/create-credentials):\\n\\n1\\\\. First, log in to your Google Cloud account and go to the Google Cloud Console (https://console.cloud.google.com/)\\n\\n2\\\\. In the Cloud Console, click on the hamburger menu in the top-left corner and select \"APIs & Services\" from the menu.', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/05_tabular-data-science-and-plots/creating-a-realtime-dashboard-from-google-sheets.md'}, lookup_index=0),\n",
              " Document(page_content='If you do not have an existing project, you will need to create one.\\n\\n3\\\\. Then, click the \"+ Enabled APIs & services\" button, which allows you to enable specific services for your project. Search for \"Google Sheets API\", click on it, and click the \"Enable\" button. If you see the \"Manage\" button, then Google Sheets is already enabled, and you\\'re all set. \\n\\n4\\\\. In the APIs & Services menu, click on the \"Credentials\" tab and then click on the \"Create credentials\" button.\\n\\n5\\\\. In the \"Create credentials\" dialog, select \"Service account key\" as the type of credentials to create, and give it a name. **Note down the email of the service account**\\n\\n6\\\\. After selecting the service account, select the \"JSON\" key type and then click on the \"Create\" button. This will download the JSON key file containing your credentials to your computer. It will look something like this:\\n\\n```json\\n{\\n \"type\": \"service_account\",\\n \"project_id\": \"your project\",\\n \"private_key_id\": \"your private key id\",\\n \"private_key\": \"private key\",\\n \"client_email\": \"email\",\\n \"client_id\": \"client id\",\\n \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\\n \"token_uri\": \"https://accounts.google.com/o/oauth2/token\",\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/05_tabular-data-science-and-plots/creating-a-realtime-dashboard-from-google-sheets.md'}, lookup_index=0),\n",
              " Document(page_content='\"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\\n \"client_x509_cert_url\":  \"https://www.googleapis.com/robot/v1/metadata/x509/email_id\"\\n}\\n```\\n\\n### Querying\\n\\nOnce you have the credentials `.json` file, you can use the following steps to query your Google Sheet:\\n\\n1\\\\. Click on the \"Share\" button in the top-right corner of the Google Sheet. Share the Google Sheets with the email address of the service from Step 5 of authentication subsection (this step is important!). Then click on the \"Get shareable link\" button. This will give you a URL that looks something like this:\\n\\n```html\\nhttps://docs.google.com/spreadsheets/d/1UoKzzRzOCt-FXLLqDKLbryEKEgllGAQUEJ5qtmmQwpU/edit#gid=0\\n```\\n\\n\\n2\\\\. Install the [`gspread` library](https://docs.gspread.org/en/v5.7.0/), which makes it easy to work with the [Google Sheets API](https://developers.google.com/sheets/api/guides/concepts) in Python by running in the terminal: `pip install gspread`\\n\\n3\\\\. Write a function to load the data from the Google Sheet, like this (replace the `URL` variable with the URL of your private Google Sheet):\\n\\n```python\\nimport gspread\\nimport pandas as pd\\n\\n#', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/05_tabular-data-science-and-plots/creating-a-realtime-dashboard-from-google-sheets.md'}, lookup_index=0),\n",
              " Document(page_content='Authenticate with Google and get the sheet\\nURL = \\'https://docs.google.com/spreadsheets/d/1_91Vps76SKOdDQ8cFxZQdgjTJiz23375sAT7vPvaj4k/edit#gid=0\\'\\n\\ngc = gspread.service_account(\"path/to/key.json\")\\nsh = gc.open_by_url(URL)\\nworksheet = sh.sheet1 \\n\\ndef get_data():\\n    values = worksheet.get_all_values()\\n    df = pd.DataFrame(values[1:], columns=values[0])\\n    return df\\n\\n```\\n\\n4\\\\. The data query is a function, which means that it\\'s easy to display it real-time using the the `gr.DataFrame` component, or plot it real-time using the `gr.LinePlot` component (of course, depending on the data, a different plot may be appropriate). To do this, we just pass the function into the respective components, and set the `every` parameter based on how frequently (in seconds) we would like the component to refresh. Here\\'s the Gradio code:\\n\\n```python\\nimport gradio as gr\\n\\nwith gr.Blocks() as demo:\\n    gr.Markdown(\"# 📈 Real-Time Line Plot\")\\n    with gr.Row():\\n        with gr.Column():\\n            gr.DataFrame(get_data, every=5)\\n        with gr.Column():\\n            gr.LinePlot(get_data, every=5, x=\"Date\", y=\"Sales\", y_title=\"Sales ($ millions)\", overlay_point=True, width=500,', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/05_tabular-data-science-and-plots/creating-a-realtime-dashboard-from-google-sheets.md'}, lookup_index=0),\n",
              " Document(page_content=\"height=500)\\n\\ndemo.queue().launch()  # Run the demo with queuing enabled\\n```\\n \\nYou now have a Dashboard that refreshes every 5 seconds, pulling the data from your Google Sheet.\\n\\n\\n## Conclusion\\n\\nAnd that's all there is to it! With just a few lines of code, you can use `gradio` and other libraries to read data from a public or private Google Sheet and then display and plot the data in a real-time dashboard.\\n\\n\\n\\n\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/05_tabular-data-science-and-plots/creating-a-realtime-dashboard-from-google-sheets.md'}, lookup_index=0),\n",
              " Document(page_content='# Connecting to a Database\\n\\nRelated spaces: https://huggingface.co/spaces/gradio/chicago-bike-share-dashboard\\nTags: TABULAR, PLOTS \\n\\n## Introduction\\n\\nThis guide explains how you can use Gradio to connect your app to a database. We will be\\nconnecting to a PostgreSQL database hosted on AWS but gradio is completely agnostic to the type of\\ndatabase you are connecting to and where it\\'s hosted. So as long as you can write python code to connect\\nto your data, you can display it in a web UI with gradio 💪\\n\\n## Overview \\n    \\nWe will be analyzing bike share data from Chicago. The data is hosted on kaggle [here](https://www.kaggle.com/datasets/evangower/cyclistic-bike-share?select=202203-divvy-tripdata.csv).\\nOur goal is to create a dashboard that will enable our business stakeholders to answer the following questions:\\n\\n1. Are electric bikes more popular than regular bikes?\\n2. What are the top 5 most popular departure bike stations?\\n\\nAt the end of this guide, we will have a functioning application that looks like this:\\n\\n<gradio-app space=\"gradio/chicago-bike-share-dashboard\"> </gradio-app>\\n\\n\\n## Step 1 - Creating your database\\n\\nWe will be storing our data on a PostgreSQL hosted on', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/05_tabular-data-science-and-plots/01_connecting-to-a-database.md'}, lookup_index=0),\n",
              " Document(page_content=\"Amazon's RDS service. Create an AWS account if you don't already have one\\nand create a PostgreSQL database on the free tier. \\n\\n**Important**: If you plan to host this demo on HuggingFace Spaces, make sure database is on port **8080**. Spaces will\\nblock all outgoing connections unless they are made to port 80, 443, or 8080 as noted [here](https://huggingface.co/docs/hub/spaces-overview#networking).\\nRDS will not let you create a postgreSQL instance on ports 80 or 443.\\n\\nOnce your database is created, download the dataset from Kaggle and upload it to your database.\\nFor the sake of this demo, we will only upload March 2022 data.\\n\\n\\n## Step 2.a - Write your ETL code\\nWe will be querying our database for the total count of rides split by the type of bicycle (electric, standard, or docked).\\nWe will also query for the total count of rides that depart from each station and take the top 5. \\n\\nWe will then take the result of our queries and visualize them in with matplotlib.\\n\\nWe will use the pandas [read_sql](https://pandas.pydata.org/docs/reference/api/pandas.read_sql.html)\\nmethod to connect to the database. This requires the `psycopg2` library to be installed. \\n\\nIn order to connect to our database, we\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/05_tabular-data-science-and-plots/01_connecting-to-a-database.md'}, lookup_index=0),\n",
              " Document(page_content='will specify the database username, password, and host as environment variables.\\nThis will make our app more secure by avoiding storing sensitive information as plain text in our application files.\\n\\n```python\\nimport os\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\n\\nDB_USER = os.getenv(\"DB_USER\")\\nDB_PASSWORD = os.getenv(\"DB_PASSWORD\")\\nDB_HOST = os.getenv(\"DB_HOST\")\\nPORT = 8080\\nDB_NAME = \"bikeshare\"\\n\\nconnection_string = f\"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}?port={PORT}&dbname={DB_NAME}\"\\n\\ndef get_count_ride_type():\\n    df = pd.read_sql(\\n    \"\"\"\\n        SELECT COUNT(ride_id) as n, rideable_type\\n        FROM rides\\n        GROUP BY rideable_type\\n        ORDER BY n DESC\\n    \"\"\",\\n    con=connection_string\\n    )\\n    fig_m, ax = plt.subplots()\\n    ax.bar(x=df[\\'rideable_type\\'], height=df[\\'n\\'])\\n    ax.set_title(\"Number of rides by bycycle type\")\\n    ax.set_ylabel(\"Number of Rides\")\\n    ax.set_xlabel(\"Bicycle Type\")\\n    return fig_m\\n\\n\\ndef get_most_popular_stations():\\n    \\n    df = pd.read_sql(\\n        \"\"\"\\n    SELECT COUNT(ride_id) as n, MAX(start_station_name) as station\\n    FROM RIDES\\n    WHERE start_station_name is NOT NULL\\n    GROUP BY start_station_id\\n    ORDER BY n DESC\\n    LIMIT 5\\n    \"\"\",\\n   ', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/05_tabular-data-science-and-plots/01_connecting-to-a-database.md'}, lookup_index=0),\n",
              " Document(page_content='   con=connection_string\\n    )\\n    fig_m, ax = plt.subplots()\\n    ax.bar(x=df[\\'station\\'], height=df[\\'n\\'])\\n    ax.set_title(\"Most popular stations\")\\n    ax.set_ylabel(\"Number of Rides\")\\n    ax.set_xlabel(\"Station Name\")\\n    ax.set_xticklabels(\\n        df[\\'station\\'], rotation=45, ha=\"right\", rotation_mode=\"anchor\"\\n    )\\n    ax.tick_params(axis=\"x\", labelsize=8)\\n    fig_m.tight_layout()\\n    return fig_m\\n```\\n\\nIf you were to run our script locally, you could pass in your credentials as environment variables like so\\n\\n```bash\\nDB_USER=\\'username\\' DB_PASSWORD=\\'password\\' DB_HOST=\\'host\\' python app.py\\n```\\n\\n\\n## Step 2.c - Write your gradio app\\nWe will display or matplotlib plots in two separate `gr.Plot` components displayed side by side using `gr.Row()`.\\nBecause we have wrapped our function to fetch the data in a `demo.load()` event trigger,\\nour demo will fetch the latest data **dynamically** from the database each time the web page loads. \\U0001fa84\\n\\n```python\\nimport gradio as gr\\n\\nwith gr.Blocks() as demo:\\n    with gr.Row():\\n        bike_type = gr.Plot()\\n        station = gr.Plot()\\n\\n    demo.load(get_count_ride_type, inputs=None, outputs=bike_type)\\n    demo.load(get_most_popular_stations, inputs=None,', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/05_tabular-data-science-and-plots/01_connecting-to-a-database.md'}, lookup_index=0),\n",
              " Document(page_content='outputs=station)\\n\\ndemo.launch()\\n```\\n\\n## Step 3 - Deployment\\nIf you run the code above, your app will start running locally.\\nYou can even get a temporary shareable link by passing the `share=True` parameter to `launch`.\\n\\nBut what if you want to a permanent deployment solution?\\nLet\\'s deploy our Gradio app to the free HuggingFace Spaces platform.\\n\\nIf you haven\\'t used Spaces before, follow the previous guide [here](/using_hugging_face_integrations).\\nYou will have to add the `DB_USER`, `DB_PASSWORD`, and `DB_HOST` variables as \"Repo Secrets\". You can do this in the \"Settings\" tab.\\n\\n![secrets](/assets/guides/secrets.png)\\n\\n## Conclusion\\nCongratulations! You know how to connect your gradio app to a database hosted on the cloud! ☁️\\n\\nOur dashboard is now running on [Spaces](https://huggingface.co/spaces/gradio/chicago-bike-share-dashboard).\\nThe complete code is [here](https://huggingface.co/spaces/gradio/chicago-bike-share-dashboard/blob/main/app.py)\\n \\nAs you can see, gradio gives you the power to connect to your data wherever it lives and display however you want! 🔥', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/05_tabular-data-science-and-plots/01_connecting-to-a-database.md'}, lookup_index=0),\n",
              " Document(page_content='# Image Classification in PyTorch\\n\\nRelated spaces: https://huggingface.co/spaces/abidlabs/pytorch-image-classifier, https://huggingface.co/spaces/pytorch/ResNet, https://huggingface.co/spaces/pytorch/ResNext, https://huggingface.co/spaces/pytorch/SqueezeNet\\nTags: VISION, RESNET, PYTORCH\\n\\n## Introduction\\n\\nImage classification is a central task in computer vision. Building better classifiers to classify what object is present in a picture is an active area of research, as it has applications stretching from autonomous vehicles to medical imaging. \\n\\nSuch models are perfect to use with Gradio\\'s *image* input component, so in this tutorial we will build a web demo to classify images using Gradio. We will be able to build the whole web application in Python, and it will look like this (try one of the examples!):\\n\\n<iframe src=\"https://abidlabs-pytorch-image-classifier.hf.space\" frameBorder=\"0\" height=\"660\" title=\"Gradio app\" class=\"container p-0 flex-grow space-iframe\" allow=\"accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations;', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/image-classification-in-pytorch.md'}, lookup_index=0),\n",
              " Document(page_content='legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking\" sandbox=\"allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads\"></iframe>\\n\\n\\nLet\\'s get started!\\n\\n### Prerequisites\\n\\nMake sure you have the `gradio` Python package already [installed](/getting_started). We will be using a pretrained image classification model, so you should also have `torch` installed.\\n\\n## Step 1 — Setting up the Image Classification Model\\n\\nFirst, we will need an image classification model. For this tutorial, we will use a pretrained Resnet-18 model, as it is easily downloadable from [PyTorch Hub](https://pytorch.org/hub/pytorch_vision_resnet/). You can use a different pretrained model or train your own. \\n\\n```python\\nimport torch\\n\\nmodel = torch.hub.load(\\'pytorch/vision:v0.6.0\\', \\'resnet18\\', pretrained=True).eval()\\n```\\n\\nBecause we will be using the model for inference, we have called the `.eval()` method.\\n\\n## Step 2 — Defining a `predict` function\\n\\nNext, we will need to define a', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/image-classification-in-pytorch.md'}, lookup_index=0),\n",
              " Document(page_content='function that takes in the *user input*, which in this case is an image, and returns the prediction. The prediction should be returned as a dictionary whose keys are class name and values are confidence probabilities. We will load the class names from this [text file](https://git.io/JJkYN).\\n\\nIn the case of our pretrained model, it will look like this:\\n\\n```python\\nimport requests\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\n# Download human-readable labels for ImageNet.\\nresponse = requests.get(\"https://git.io/JJkYN\")\\nlabels = response.text.split(\"\\\\n\")\\n\\ndef predict(inp):\\n  inp = transforms.ToTensor()(inp).unsqueeze(0)\\n  with torch.no_grad():\\n    prediction = torch.nn.functional.softmax(model(inp)[0], dim=0)\\n    confidences = {labels[i]: float(prediction[i]) for i in range(1000)}    \\n  return confidences\\n```\\n\\nLet\\'s break this down. The function takes one parameter:\\n\\n* `inp`: the input image as a `PIL` image\\n\\nThen, the function converts the image to a PIL Image and then eventually a PyTorch `tensor`, passes it through the model, and returns:\\n\\n* `confidences`: the predictions, as a dictionary whose keys are class labels and whose values are confidence', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/image-classification-in-pytorch.md'}, lookup_index=0),\n",
              " Document(page_content='probabilities\\n\\n## Step 3 — Creating a Gradio Interface\\n\\nNow that we have our predictive function set up, we can create a Gradio Interface around it. \\n\\nIn this case, the input component is a drag-and-drop image component. To create this input, we use `Image(type=\"pil\")` which creates the component and handles the preprocessing to convert that to a `PIL` image. \\n\\nThe output component will be a `Label`, which displays the top labels in a nice form. Since we don\\'t want to show all 1,000 class labels, we will customize it to show only the top 3 images by constructing it as `Label(num_top_classes=3)`.\\n\\nFinally, we\\'ll add one more parameter, the `examples`, which allows us to prepopulate our interfaces with a few predefined examples. The code for Gradio looks like this:\\n\\n```python\\nimport gradio as gr\\n\\ngr.Interface(fn=predict, \\n             inputs=gr.Image(type=\"pil\"),\\n             outputs=gr.Label(num_top_classes=3),\\n             examples=[\"lion.jpg\", \"cheetah.jpg\"]).launch()\\n```\\n\\nThis produces the following interface, which you can try right here in your browser (try uploading your own examples!):\\n\\n<iframe src=\"https://abidlabs-pytorch-image-classifier.hf.space\" frameBorder=\"0\" height=\"660\"', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/image-classification-in-pytorch.md'}, lookup_index=0),\n",
              " Document(page_content='title=\"Gradio app\" class=\"container p-0 flex-grow space-iframe\" allow=\"accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking\" sandbox=\"allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads\"></iframe>\\n\\n----------\\n\\nAnd you\\'re done! That\\'s all the code you need to build a web demo for an image classifier. If you\\'d like to share with others, try setting `share=True` when you `launch()` the Interface!\\n\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/image-classification-in-pytorch.md'}, lookup_index=0),\n",
              " Document(page_content='# Image Classification with Vision Transformers\\n\\nRelated spaces: https://huggingface.co/spaces/abidlabs/vision-transformer\\nTags: VISION, TRANSFORMERS, HUB\\n\\n## Introduction\\n\\nImage classification is a central task in computer vision. Building better classifiers to classify what object is present in a picture is an active area of research, as it has applications stretching from facial recognition to manufacturing quality control. \\n\\nState-of-the-art image classifiers are based on the *transformers* architectures, originally popularized for NLP tasks. Such architectures are typically called vision transformers (ViT). Such models are perfect to use with Gradio\\'s *image* input component, so in this tutorial we will build a web demo to classify images using Gradio. We will be able to build the whole web application in a **single line of Python**, and it will look like this (try one of the examples!):\\n\\n<iframe src=\"https://abidlabs-vision-transformer.hf.space\" frameBorder=\"0\" height=\"660\" title=\"Gradio app\" class=\"container p-0 flex-grow space-iframe\" allow=\"accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media;', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/image-classification-with-vision-transformers.md'}, lookup_index=0),\n",
              " Document(page_content='fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking\" sandbox=\"allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads\"></iframe>\\n\\n\\nLet\\'s get started!\\n\\n### Prerequisites\\n\\nMake sure you have the `gradio` Python package already [installed](/getting_started).\\n\\n## Step 1 — Choosing a Vision Image Classification Model\\n\\nFirst, we will need an image classification model. For this tutorial, we will use a model from the [Hugging Face Model Hub](https://huggingface.co/models?pipeline_tag=image-classification). The Hub contains thousands of models covering dozens of different machine learning tasks. \\n\\nExpand the Tasks category on the left sidebar and select \"Image Classification\" as our task of interest. You will then see all of the models on the Hub that are designed to classify images.\\n\\nAt the time of writing, the most popular one is `google/vit-base-patch16-224`, which has been trained on ImageNet images at', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/image-classification-with-vision-transformers.md'}, lookup_index=0),\n",
              " Document(page_content='a resolution of 224x224 pixels. We will use this model for our demo. \\n\\n## Step 2 — Loading the Vision Transformer Model with Gradio\\n\\nWhen using a model from the Hugging Face Hub, we do not need to define the input or output components for the demo. Similarly, we do not need to be concerned with the details of preprocessing or postprocessing. \\nAll of these are automatically inferred from the model tags.\\n\\nBesides the import statement, it only takes a single line of Python to load and launch the demo. \\n\\nWe use the `gr.Interface.load()` method and pass in the path to the model including the  `huggingface/` to designate that it is from the Hugging Face Hub.\\n\\n```python\\nimport gradio as gr\\n\\ngr.Interface.load(\\n             \"huggingface/google/vit-base-patch16-224\",\\n             examples=[\"alligator.jpg\", \"laptop.jpg\"]).launch()\\n```\\n\\nNotice that we have added one more parameter, the `examples`, which allows us to prepopulate our interfaces with a few predefined examples. \\n\\nThis produces the following interface, which you can try right here in your browser. When you input an image, it is automatically preprocessed and sent to the Hugging Face Hub API, where it is passed through the model and returned as a', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/image-classification-with-vision-transformers.md'}, lookup_index=0),\n",
              " Document(page_content='human-interpretable prediction.  Try uploading your own image!\\n\\n<iframe src=\"https://abidlabs-vision-transformer.hf.space\" frameBorder=\"0\" height=\"660\" title=\"Gradio app\" class=\"container p-0 flex-grow space-iframe\" allow=\"accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking\" sandbox=\"allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads\"></iframe>\\n\\n----------\\n\\nAnd you\\'re done! In one line of code, you have built a web demo for an image classifier. If you\\'d like to share with others, try setting `share=True` when you `launch()` the Interface!\\n\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/image-classification-with-vision-transformers.md'}, lookup_index=0),\n",
              " Document(page_content='# Image Classification in TensorFlow and Keras\\n\\nRelated spaces: https://huggingface.co/spaces/abidlabs/keras-image-classifier\\nTags: VISION, MOBILENET, TENSORFLOW\\n\\n## Introduction\\n\\nImage classification is a central task in computer vision. Building better classifiers to classify what object is present in a picture is an active area of research, as it has applications stretching from traffic control systems to satellite imaging. \\n\\nSuch models are perfect to use with Gradio\\'s *image* input component, so in this tutorial we will build a web demo to classify images using Gradio. We will be able to build the whole web application in Python, and it will look like this (try one of the examples!):\\n\\n<iframe src=\"https://abidlabs-keras-image-classifier.hf.space\" frameBorder=\"0\" height=\"660\" title=\"Gradio app\" class=\"container p-0 flex-grow space-iframe\" allow=\"accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get;', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/image-classification-in-tensorflow.md'}, lookup_index=0),\n",
              " Document(page_content='sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking\" sandbox=\"allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads\"></iframe>\\n\\n\\nLet\\'s get started!\\n\\n### Prerequisites\\n\\nMake sure you have the `gradio` Python package already [installed](/getting_started). We will be using a pretrained Keras image classification model, so you should also have `tensorflow` installed.\\n\\n## Step 1 — Setting up the Image Classification Model\\n\\nFirst, we will need an image classification model. For this tutorial, we will use a pretrained Mobile Net model, as it is easily downloadable from [Keras](https://keras.io/api/applications/mobilenet/). You can use a different pretrained model or train your own. \\n\\n```python\\nimport tensorflow as tf\\n\\ninception_net = tf.keras.applications.MobileNetV2()\\n```\\n\\nThis line automatically downloads the MobileNet model and weights using the Keras library.  \\n\\n## Step 2 — Defining a `predict` function\\n\\nNext, we will need to define a function that takes in the *user input*, which in this case is an image, and returns the prediction. The prediction should be returned as a dictionary whose keys', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/image-classification-in-tensorflow.md'}, lookup_index=0),\n",
              " Document(page_content='are class name and values are confidence probabilities. We will load the class names from this [text file](https://git.io/JJkYN).\\n\\nIn the case of our pretrained model, it will look like this:\\n\\n```python\\nimport requests\\n\\n# Download human-readable labels for ImageNet.\\nresponse = requests.get(\"https://git.io/JJkYN\")\\nlabels = response.text.split(\"\\\\n\")\\n\\ndef classify_image(inp):\\n  inp = inp.reshape((-1, 224, 224, 3))\\n  inp = tf.keras.applications.mobilenet_v2.preprocess_input(inp)\\n  prediction = inception_net.predict(inp).flatten()\\n  confidences = {labels[i]: float(prediction[i]) for i in range(1000)}\\n  return confidences\\n```\\n\\nLet\\'s break this down. The function takes one parameter:\\n\\n* `inp`: the input image as a `numpy` array\\n\\nThen, the function adds a batch dimension, passes it through the model, and returns:\\n\\n* `confidences`: the predictions, as a dictionary whose keys are class labels and whose values are confidence probabilities\\n\\n## Step 3 — Creating a Gradio Interface\\n\\nNow that we have our predictive function set up, we can create a Gradio Interface around it. \\n\\nIn this case, the input component is a drag-and-drop image component. To create this input, we', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/image-classification-in-tensorflow.md'}, lookup_index=0),\n",
              " Document(page_content='can use the `\"gradio.inputs.Image\"` class, which creates the component and handles the preprocessing to convert that to a numpy array. We will instantiate the class with a parameter that automatically preprocesses the input image to be 224 pixels by 224 pixels, which is the size that MobileNet expects.\\n\\nThe output component will be a `\"label\"`, which displays the top labels in a nice form. Since we don\\'t want to show all 1,000 class labels, we will customize it to show only the top 3 images.\\n\\nFinally, we\\'ll add one more parameter, the `examples`, which allows us to prepopulate our interfaces with a few predefined examples. The code for Gradio looks like this:\\n\\n```python\\nimport gradio as gr\\n\\ngr.Interface(fn=classify_image, \\n             inputs=gr.Image(shape=(224, 224)),\\n             outputs=gr.Label(num_top_classes=3),\\n             examples=[\"banana.jpg\", \"car.jpg\"]).launch()\\n```\\n\\nThis produces the following interface, which you can try right here in your browser (try uploading your own examples!):\\n\\n<iframe src=\"https://abidlabs-keras-image-classifier.hf.space\" frameBorder=\"0\" height=\"660\" title=\"Gradio app\" class=\"container p-0 flex-grow space-iframe\" allow=\"accelerometer;', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/image-classification-in-tensorflow.md'}, lookup_index=0),\n",
              " Document(page_content='ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking\" sandbox=\"allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads\"></iframe>\\n\\n----------\\n\\nAnd you\\'re done! That\\'s all the code you need to build a web demo for an image classifier. If you\\'d like to share with others, try setting `share=True` when you `launch()` the Interface!\\n\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/image-classification-in-tensorflow.md'}, lookup_index=0),\n",
              " Document(page_content='# Using Hugging Face Integrations\\n\\nRelated spaces: https://huggingface.co/spaces/farukozderim/Model-Comparator-Space-Builder, https://huggingface.co/spaces/osanseviero/helsinki_translation_en_es, https://huggingface.co/spaces/osanseviero/remove-bg-webcam, https://huggingface.co/spaces/mrm8488/GPT-J-6B, https://huggingface.co/spaces/akhaliq/T0pp, https://huggingface.co/spaces/osanseviero/mix_match_gradio\\nTags: HUB, SPACES, EMBED\\n\\nContributed by <a href=\"https://huggingface.co/osanseviero\">Omar Sanseviero</a> 🦙 and <a href=\"https://huggingface.co/farukozderim\">Ömer Faruk Özdemir</a>\\n\\n## Introduction\\n\\nThe Hugging Face Hub is a central platform that has over 90,000 [models](https://huggingface.co/models), 14,000 [datasets](https://huggingface.co/datasets) and 14,000 [demos](https://huggingface.co/spaces), also known as Spaces. From Natural Language Processing to Computer Vision and Speech, the Hub supports multiple domains. Although Hugging Face is famous for its 🤗 transformers and diffusers libraries, the Hub also supports dozens of ML libraries, such as PyTorch, TensorFlow, spaCy, and many', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/01_using-hugging-face-integrations.md'}, lookup_index=0),\n",
              " Document(page_content='others.\\n\\nGradio has multiple features that make it extremely easy to leverage existing models and Spaces on the Hub. This guide walks through these features.\\n\\n## Using regular inference with `pipeline`\\n\\nFirst, let\\'s build a simple interface that translates text from English to Spanish. Between the over a thousand models shared by the University of Helsinki, there is an [existing model](https://huggingface.co/Helsinki-NLP/opus-mt-en-es), `opus-mt-en-es`, that does precisely this!\\n\\nThe 🤗 transformers library has a very easy-to-use abstraction, [`pipeline()`](https://huggingface.co/docs/transformers/v4.16.2/en/main_classes/pipelines#transformers.pipeline) that handles most of the complex code to offer a simple API for common tasks. By specifying the task and an (optional) model, you can use an existing model with few lines:\\n\\n```python\\nimport gradio as gr\\n\\nfrom transformers import pipeline\\n\\npipe = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\")\\n\\ndef predict(text):\\n  return pipe(text)[0][\"translation_text\"]\\n  \\niface = gr.Interface(\\n  fn=predict, \\n  inputs=\\'text\\',\\n  outputs=\\'text\\',\\n  examples=[[\"Hello! My name is', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/01_using-hugging-face-integrations.md'}, lookup_index=0),\n",
              " Document(page_content='Omar\"]]\\n)\\n\\niface.launch()\\n```\\n\\nThe previous code produces the following interface, which you can try right here in your browser: \\n\\n<iframe src=\"https://osanseviero-helsinki-translation-en-es.hf.space\" frameBorder=\"0\" height=\"450\" title=\"Gradio app\" class=\"container p-0 flex-grow space-iframe\" allow=\"accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking\" sandbox=\"allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads\"></iframe>\\n\\nThis demo requires installing four libraries: gradio, torch, transformers, and sentencepiece. Apart from that, this is a Gradio with the structure you\\'re used to! The demo is a usual Gradio `Interface` with a prediction function, a specified input, and a specified output. The prediction function executes the `pipeline` function with the given input, retrieves', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/01_using-hugging-face-integrations.md'}, lookup_index=0),\n",
              " Document(page_content='the first (and only) translation result, and returns the `translation_text` field, which you\\'re interested in.\\n\\n## Using Hugging Face Inference API\\n\\nHugging Face has a free service called the [Inference API](https://huggingface.co/inference-api), which allows you to send HTTP requests to models in the Hub. For transformers or diffusers-based models, the API can be 2 to 10 times faster than running the inference yourself. The API is free (rate limited), and you can switch to dedicated [Inference Endpoints](https://huggingface.co/pricing) when you want to use it in production.\\n\\nLet\\'s try the same demo as above but using the Inference API instead of loading the model yourself. Given a Hugging Face model supported in the Inference API, Gradio can automatically infer the expected input and output and make the underlying server calls, so you don\\'t have to worry about defining the prediction function. Here is what the code would look like!\\n\\n```python\\nimport gradio as gr\\n\\niface = gr.Interface.load(\"huggingface/Helsinki-NLP/opus-mt-en-es\",\\n  examples=[[\"Hello! My name is Omar\"]]\\n)\\n\\niface.launch()\\n```\\n\\nLet\\'s go over some of the key differences:\\n\\n* `Interface.load()` is used', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/01_using-hugging-face-integrations.md'}, lookup_index=0),\n",
              " Document(page_content='instead of the usual `Interface()`.\\n* `Interface.load()` receives a string with the prefix `huggingface/`, and then the model repository ID.\\n* Since the input, output and prediction functions are not needed, you only need to modify the UI parts (such as `title`, `description`, and `examples`).\\n* There is no need to install any dependencies (except Gradio) since you are not loading the model on your computer.\\n\\nYou might notice that the first inference takes about 20 seconds. This happens since the Inference API is loading the model in the server. You get some benefits afterward:\\n\\n* The inference will be much faster.\\n* The server caches your requests.\\n* You get built-in automatic scaling.\\n\\n## Hosting your Gradio demos\\n\\n\\n[Hugging Face Spaces](https://hf.co/spaces) allows anyone to host their Gradio demos freely. The community shares oven 2,000 Spaces. Uploading your Gradio demos take a couple of minutes. You can head to [hf.co/new-space](https://huggingface.co/new-space), select the Gradio SDK, create an `app.py` file, and voila! You have a demo you can share with anyone else.\\n\\n## Building demos based on other demos\\n\\nYou can use the existing Spaces to tweak the UI or combine multiple', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/01_using-hugging-face-integrations.md'}, lookup_index=0),\n",
              " Document(page_content='demos. Let\\'s find how to do this! First, let\\'s take a look at an existing demo that does background removal. \\n\\nThis is a Gradio demo [already shared](https://huggingface.co/spaces/eugenesiow/remove-bg) by a community member. You can load an existing demo using `Interface` in a syntax similar to how it\\'s done for the Inference API. It just takes two lines of code and with the prefix `spaces`.\\n\\n```python\\nimport gradio as gr\\n\\ngr.Interface.load(\"spaces/eugenesiow/remove-bg\").launch()\\n```\\n\\nThe code snippet above will load the same interface as the corresponding Space demo.\\n\\n<iframe src=\"https://eugenesiow-remove-bg.hf.space\" frameBorder=\"0\" height=\"900\" title=\"Gradio app\" class=\"container p-0 flex-grow space-iframe\" allow=\"accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking\" sandbox=\"allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/01_using-hugging-face-integrations.md'}, lookup_index=0),\n",
              " Document(page_content='allow-same-origin allow-scripts allow-downloads\"></iframe>\\n\\n\\nYou can change UI elements, such as the title or theme, but also change the expected type. The previous Space expected users to upload images. What if you would like users to have their webcam and remove the background from there? You can load the Space but change the source of input as follows:\\n\\n```python\\nimport gradio as gr\\n\\ngr.Interface.load(\\n  \"spaces/eugenesiow/remove-bg\", \\n  inputs=[gr.Image(label=\"Input Image\", source=\"webcam\")]\\n).launch()\\n```\\n\\nThe code above generates the following demo.\\n\\n<iframe src=\"https://osanseviero-remove-bg-webcam.hf.space\" frameBorder=\"0\" height=\"600\" title=\"Gradio app\" class=\"container p-0 flex-grow space-iframe\" allow=\"accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking\" sandbox=\"allow-forms allow-modals allow-popups', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/01_using-hugging-face-integrations.md'}, lookup_index=0),\n",
              " Document(page_content='allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads\"></iframe>\\n\\nAs you can see, the demo looks the same, but it uses a webcam input instead of user-uploaded images.\\n\\nYou can learn more about this feature, and how to use it with the new Blocks API in the [Using Gradio Blocks Like Functions guide](/using_blocks_like_functions)\\n\\n## Using multiple Spaces\\n\\nSometimes a single model inference will not be enough: you might want to call multiple models by piping them (using the output of model A as the input of model B). `Series` can achieve this. Other times, you might want to run two models in parallel to compare them. `Parallel` can do this!\\n\\nLet\\'s combine the notion of running things in parallel with the Spaces integration. The [GPT-J-6B](https://huggingface.co/spaces/mrm8488/GPT-J-6B) Space demos a model that generates text using a model called GPT-J. The [T0pp](https://huggingface.co/spaces/akhaliq/T0pp) Space demos another generative model called T0pp. Let\\'s see how to combine both into one.\\n\\n```python\\nimport gradio as gr\\n\\niface1 = gr.Interface.load(\"spaces/mrm8488/GPT-J-6B\")\\niface2 =', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/01_using-hugging-face-integrations.md'}, lookup_index=0),\n",
              " Document(page_content='gr.Interface.load(\"spaces/akhaliq/T0pp\")\\n\\niface3 = gr.mix.Parallel(\\n  iface1, iface2, \\n  examples = [\\n    [\\'Which country will win the 2002 World Cup?\\'],\\n    [\"A is the son\\'s of B\\'s uncle. What is the family relationship between A and B?\"],\\n    [\"In 2030, \"],\\n  ])\\n  \\niface3.launch()\\n```\\n\\n`iface1` and `iface2` are loading existing Spaces. Then, with `Parallel`, you can run the interfaces parallelly. When you click submit, you will get the output for both interfaces. This is how the demo looks like:\\n\\n<iframe src=\"https://osanseviero-mix-match-gradio.hf.space\" frameBorder=\"0\" height=\"450\" title=\"Gradio app\" class=\"container p-0 flex-grow space-iframe\" allow=\"accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking\" sandbox=\"allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads\"></iframe>\\n\\nAlthough both', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/01_using-hugging-face-integrations.md'}, lookup_index=0),\n",
              " Document(page_content='models are generative, you can see that the way both models behave is very different. That\\'s a powerful application of `Parallel`!\\n\\n## Creating Spaces with python\\n\\nMaking use of the [huggingface_hub client library](https://huggingface.co/docs/huggingface_hub/index) library you can create new Spaces or model repositories. You can do this even in a Gradio Space! You can find an example space [here](https://huggingface.co/spaces/farukozderim/Model-Comparator-Space-Builder). This Space creates a new Space comparing different models or spaces with the support of Gradio `load` and `Parallel`. Now you can try creating cool spaces with all kinds of functionality 😎.\\n\\n```python\\nfrom huggingface_hub import (\\n    create_repo,\\n    get_full_repo_name,\\n    upload_file,\\n)\\ncreate_repo(name=target_space_name, token=hf_token, repo_type=\"space\", space_sdk=\"gradio\")\\nrepo_name = get_full_repo_name(model_id=target_space_name, token=hf_token)\\nfile_url = upload_file(\\n    path_or_fileobj=\"file.txt\",\\n    path_in_repo=\"app.py\",\\n    repo_id=repo_name,\\n    repo_type=\"space\",\\n    token=hf_token,\\n)\\n```\\nHere, `create_repo` creates a gradio repo with the target name under a', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/01_using-hugging-face-integrations.md'}, lookup_index=0),\n",
              " Document(page_content='specific account using that account\\'s Write Token. `repo_name` gets the full repo name of the related repo. Finally `upload_file` uploads a file inside the repo with the name `app.py`.\\n\\n<iframe src=\"https://farukozderim-model-comparator-space-builder.hf.space\" frameBorder=\"0\" height=\"800\" title=\"Gradio app\" class=\"container p-0 flex-grow space-iframe\" allow=\"accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking\" sandbox=\"allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads\"></iframe>\\n\\n\\n## Embedding your Space demo on other websites\\n\\nThroughout this guide, you\\'ve seen there are Gradio demos embedded. You can also do this on own website! The first step is to create a Space with the demo you want to showcase. You can embed it in your HTML code, as shown in the following self-contained', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/01_using-hugging-face-integrations.md'}, lookup_index=0),\n",
              " Document(page_content='example.\\n\\n```bash\\n&lt;iframe src=\"https://osanseviero-mix-match-gradio.hf.space\" frameBorder=\"0\" height=\"450\" title=\"Gradio app\" class=\"container p-0 flex-grow space-iframe\" allow=\"accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking\" sandbox=\"allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads\"&gt;&lt;/iframe&gt;\\n```\\n\\n## Recap\\n\\nThat\\'s it! Let\\'s recap what you can do:\\n\\n1. Host your Gradio demos in Spaces.\\n2. Use the Inference API to build demos in two lines of code.\\n3. Load existing Spaces and modify them.\\n4. Combine multiple Spaces by running them sequentially or parallelly.\\n5. Embed your Space demo directly on a website.\\n\\n🤗\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/01_using-hugging-face-integrations.md'}, lookup_index=0),\n",
              " Document(page_content=\"# Using Gradio and Comet\\n\\nTags: COMET, SPACES\\nContributed by the Comet team\\n\\n## Introduction\\n\\nIn this guide we will demonstrate some of the ways you can use Gradio with Comet. We will cover the basics of using Comet with Gradio and show you some of the ways that you can leverage Gradio's advanced features such as [Embedding with iFrames](https://www.gradio.app/sharing-your-app/#embedding-with-iframes) and [State](https://www.gradio.app/docs/#state) to build some amazing model evaluation workflows.\\n\\nHere is a list of the topics covered in this guide.\\n\\n1. Logging Gradio UI's to your Comet Experiments\\n2. Embedding Gradio Applications directly into your Comet Projects\\n3. Embedding Hugging Face Spaces directly into your Comet Projects\\n4. Logging Model Inferences from your Gradio Application to Comet\\n\\n\\n## What is Comet?\\n\\n[Comet](https://www.comet.com?utm_source=gradio&utm_medium=referral&utm_campaign=gradio-integration&utm_content=gradio-docs) is an MLOps Platform that is designed to help Data Scientists and Teams build better models faster! Comet provides tooling to Track, Explain, Manage, and Monitor your models in a single place! It works with Jupyter\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/Gradio-and-Comet.md'}, lookup_index=0),\n",
              " Document(page_content='Notebooks and Scripts and most importantly it\\'s 100% free!\\n\\n\\n## Setup\\n\\nFirst, install the dependencies needed to run these examples\\n\\n```shell\\npip install comet_ml torch torchvision transformers gradio shap requests Pillow\\n```\\n\\nNext, you will need to [sign up for a Comet Account](https://www.comet.com/signup?utm_source=gradio&utm_medium=referral&utm_campaign=gradio-integration&utm_content=gradio-docs). Once you have your account set up, [grab your API Key](https://www.comet.com/docs/v2/guides/getting-started/quickstart/#get-an-api-key?utm_source=gradio&utm_medium=referral&utm_campaign=gradio-integration&utm_content=gradio-docs) and configure your Comet credentials\\n\\nIf you\\'re running these examples as a script, you can either export your credentials as environment variables\\n\\n```shell\\nexport COMET_API_KEY=\"<Your API Key>\"\\nexport COMET_WORKSPACE=\"<Your Workspace Name>\"\\nexport COMET_PROJECT_NAME=\"<Your Project Name>\"\\n```\\n\\nor set them in a `.comet.config` file in your working directory. You file should be formatted in the following way.\\n\\n```shell\\n[comet]\\napi_key=<Your API Key>\\nworkspace=<Your Workspace', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/Gradio-and-Comet.md'}, lookup_index=0),\n",
              " Document(page_content='Name>\\nproject_name=<Your Project Name>\\n```\\n\\nIf you are using the provided Colab Notebooks to run these examples, please run the cell with the following snippet before starting the Gradio UI. Running this cell allows you to interactively add your API key to the notebook.\\n\\n```python\\nimport comet_ml\\ncomet_ml.init()\\n```\\n\\n## 1. Logging Gradio UI\\'s to your Comet Experiments\\n\\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/comet-examples/blob/master/integrations/model-evaluation/gradio/notebooks/Gradio_and_Comet.ipynb)\\n\\nIn this example, we will go over how to log your Gradio Applications to Comet and interact with them using the Gradio Custom Panel.\\n\\nLet\\'s start by building a simple Image Classification example using `resnet18`.\\n\\n```python\\nimport comet_ml\\n\\nimport requests\\nimport torch\\nfrom PIL import Image\\nfrom torchvision import transforms\\n\\ntorch.hub.download_url_to_file(\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\\n\\nif torch.cuda.is_available():\\n    device = \"cuda\"\\nelse:\\n    device = \"cpu\"\\n\\nmodel =', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/Gradio-and-Comet.md'}, lookup_index=0),\n",
              " Document(page_content='torch.hub.load(\"pytorch/vision:v0.6.0\", \"resnet18\", pretrained=True).eval()\\nmodel = model.to(device)\\n\\n# Download human-readable labels for ImageNet.\\nresponse = requests.get(\"https://git.io/JJkYN\")\\nlabels = response.text.split(\"\\\\n\")\\n\\n\\ndef predict(inp):\\n    inp = Image.fromarray(inp.astype(\"uint8\"), \"RGB\")\\n    inp = transforms.ToTensor()(inp).unsqueeze(0)\\n    with torch.no_grad():\\n        prediction = torch.nn.functional.softmax(model(inp.to(device))[0], dim=0)\\n    return {labels[i]: float(prediction[i]) for i in range(1000)}\\n\\n\\ninputs = gr.Image()\\noutputs = gr.Label(num_top_classes=3)\\n\\nio = gr.Interface(\\n    fn=predict, inputs=inputs, outputs=outputs, examples=[\"dog.jpg\"]\\n)\\nio.launch(inline=False, share=True)\\n\\nexperiment = comet_ml.Experiment()\\nexperiment.add_tag(\"image-classifier\")\\n\\nio.integrate(comet_ml=experiment)\\n```\\n\\nThe last line in this snippet will log the URL of the Gradio Appication to your Comet Experiment. You can find the URL in the Text Tab of your Experiment.\\n\\n<video width=\"560\" height=\"315\" controls>\\n    <source', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/Gradio-and-Comet.md'}, lookup_index=0),\n",
              " Document(page_content='src=\"https://user-images.githubusercontent.com/7529846/214328034-09369d4d-8b94-4c4a-aa3c-25e3ed8394c4.mp4\"></source>\\n</video>\\n\\nAdd the Gradio Panel to your Experiment to interact with your application.\\n\\n<video width=\"560\" height=\"315\" controls>\\n    <source src=\"https://user-images.githubusercontent.com/7529846/214328194-95987f83-c180-4929-9bed-c8a0d3563ed7.mp4\"></source>\\n</video>\\n\\n\\n## 2. Embedding Gradio Applications directly into your Comet Projects\\n\\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/KZnpH7msPq0?start=9\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\\n\\nIf you are permanently hosting your Gradio application, you can embed the UI using the Gradio Panel Extended custom Panel.\\n\\nGo to your Comet Project page, and head over to the Panels tab. Click the `+ Add` button to bring up the Panels search page.\\n\\n<img width=\"560\" alt=\"adding-panels\"', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/Gradio-and-Comet.md'}, lookup_index=0),\n",
              " Document(page_content='src=\"https://user-images.githubusercontent.com/7529846/214329314-70a3ff3d-27fb-408c-a4d1-4b58892a3854.jpeg\">\\n\\nNext, search for Gradio Panel Extended in the Public Panels section and click `Add`.\\n\\n<img width=\"560\" alt=\"gradio-panel-extended\" src=\"https://user-images.githubusercontent.com/7529846/214325577-43226119-0292-46be-a62a-0c7a80646ebb.png\">\\n\\nOnce you have added your Panel, click `Edit` to access to the Panel Options page and paste in the URL of your Gradio application.\\n\\n![Edit-Gradio-Panel-Options](https://user-images.githubusercontent.com/7529846/214573001-23814b5a-ca65-4ace-a8a5-b27cdda70f7a.gif)\\n\\n<img width=\"560\" alt=\"Edit-Gradio-Panel-URL\" src=\"https://user-images.githubusercontent.com/7529846/214334843-870fe726-0aa1-4b21-bbc6-0c48f56c48d8.png\">\\n\\n\\n## 3. Embedding Hugging Face Spaces directly into your Comet Projects\\n\\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/KZnpH7msPq0?start=107\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\"', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/Gradio-and-Comet.md'}, lookup_index=0),\n",
              " Document(page_content='allowfullscreen></iframe>\\n\\nYou can also embed Gradio Applications that are hosted on Hugging Faces Spaces into your Comet Projects using the Hugging Face Spaces Panel.\\n\\nGo to your Comet Project page, and head over to the Panels tab. Click the `+ Add` button to bring up the Panels search page. Next, search for the Hugging Face Spaces Panel in the Public Panels section and click `Add`.\\n\\n<img width=\"560\" height=\"315\" alt=\"huggingface-spaces-panel\" src=\"https://user-images.githubusercontent.com/7529846/214325606-99aa3af3-b284-4026-b423-d3d238797e12.png\">\\n\\nOnce you have added your Panel, click Edit to access to the Panel Options page and paste in the path of your Hugging Face Space e.g. `pytorch/ResNet`\\n\\n<img width=\"560\" height=\"315\" alt=\"Edit-HF-Space\" src=\"https://user-images.githubusercontent.com/7529846/214335868-c6f25dee-13db-4388-bcf5-65194f850b02.png\">\\n\\n## 4. Logging Model Inferences to Comet\\n\\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/KZnpH7msPq0?start=176\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope;', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/Gradio-and-Comet.md'}, lookup_index=0),\n",
              " Document(page_content='picture-in-picture; web-share\" allowfullscreen></iframe>\\n\\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/comet-examples/blob/master/integrations/model-evaluation/gradio/notebooks/Logging_Model_Inferences_with_Comet_and_Gradio.ipynb)\\n\\n\\nIn the previous examples, we demonstrated the various ways in which you can interact with a Gradio application through the Comet UI. Additionally,  you can also log model inferences, such as SHAP plots, from your Gradio application to Comet.\\n\\nIn the following snippet, we\\'re going to log inferences from a Text Generation model. We can persist an Experiment across multiple inference calls using Gradio\\'s [State](https://www.gradio.app/docs/#state) object. This will allow you to log multiple inferences from a model to a single Experiment.\\n\\n```python\\nimport comet_ml\\nimport gradio as gr\\nimport shap\\nimport torch\\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\\n\\nif torch.cuda.is_available():\\n    device = \"cuda\"\\nelse:\\n    device = \"cpu\"\\n\\nMODEL_NAME = \"gpt2\"\\n\\nmodel =', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/Gradio-and-Comet.md'}, lookup_index=0),\n",
              " Document(page_content='AutoModelForCausalLM.from_pretrained(MODEL_NAME)\\n\\n# set model decoder to true\\nmodel.config.is_decoder = True\\n# set text-generation params under task_specific_params\\nmodel.config.task_specific_params[\"text-generation\"] = {\\n    \"do_sample\": True,\\n    \"max_length\": 50,\\n    \"temperature\": 0.7,\\n    \"top_k\": 50,\\n    \"no_repeat_ngram_size\": 2,\\n}\\nmodel = model.to(device)\\n\\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\\nexplainer = shap.Explainer(model, tokenizer)\\n\\n\\ndef start_experiment():\\n    \"\"\"Returns an APIExperiment object that is thread safe\\n    and can be used to log inferences to a single Experiment\\n    \"\"\"\\n    try:\\n        api = comet_ml.API()\\n        workspace = api.get_default_workspace()\\n        project_name = comet_ml.config.get_config()[\"comet.project_name\"]\\n\\n        experiment = comet_ml.APIExperiment(\\n            workspace=workspace, project_name=project_name\\n        )\\n        experiment.log_other(\"Created from\", \"gradio-inference\")\\n\\n        message = f\"Started Experiment: [{experiment.name}]({experiment.url})\"\\n\\n        return (experiment, message)\\n\\n    except Exception as e:\\n        return None, None\\n\\n\\ndef predict(text, state, message):\\n    experiment = state\\n\\n    shap_values =', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/Gradio-and-Comet.md'}, lookup_index=0),\n",
              " Document(page_content='explainer([text])\\n    plot = shap.plots.text(shap_values, display=False)\\n\\n    if experiment is not None:\\n        experiment.log_other(\"message\", message)\\n        experiment.log_html(plot)\\n\\n    return plot\\n\\n\\nwith gr.Blocks() as demo:\\n    start_experiment_btn = gr.Button(\"Start New Experiment\")\\n    experiment_status = gr.Markdown()\\n\\n    # Log a message to the Experiment to provide more context\\n    experiment_message = gr.Textbox(label=\"Experiment Message\")\\n    experiment = gr.State()\\n\\n    input_text = gr.Textbox(label=\"Input Text\", lines=5, interactive=True)\\n    submit_btn = gr.Button(\"Submit\")\\n\\n    output = gr.HTML(interactive=True)\\n\\n    start_experiment_btn.click(\\n        start_experiment, outputs=[experiment, experiment_status]\\n    )\\n    submit_btn.click(\\n        predict, inputs=[input_text, experiment, experiment_message], outputs=[output]\\n    )\\n```\\n\\nInferences from this snippet will be saved in the HTML tab of your experiment.\\n\\n<video width=\"560\" height=\"315\" controls>\\n    <source src=\"https://user-images.githubusercontent.com/7529846/214328610-466e5c81-4814-49b9-887c-065aca14dd30.mp4\"></source>\\n</video>\\n\\n## Conclusion\\n\\nWe hope you found this guide useful and that it', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/Gradio-and-Comet.md'}, lookup_index=0),\n",
              " Document(page_content='provides some inspiration to help you build awesome model evaluation workflows with Comet and Gradio.\\n\\n## How to contribute Gradio demos on HF spaces on the Comet organization\\n\\n* Create an account on Hugging Face [here](https://huggingface.co/join).\\n* Add Gradio Demo under your username, see this [course](https://huggingface.co/course/chapter9/4?fw=pt) for setting up Gradio Demo on Hugging Face.\\n* Request to join the Comet organization [here](https://huggingface.co/Comet).\\n\\n## Additional Resources\\n\\n* [Comet Documentation](https://www.comet.com/docs/v2/?utm_source=gradio&utm_medium=referral&utm_campaign=gradio-integration&utm_content=gradio-docs)\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/Gradio-and-Comet.md'}, lookup_index=0),\n",
              " Document(page_content='# Gradio and W&B Integration\\n\\nRelated spaces: https://huggingface.co/spaces/akhaliq/JoJoGAN\\nTags: WANDB, SPACES\\nContributed by Gradio team\\n\\n## Introduction\\n\\nIn this Guide, we\\'ll walk you through:\\n\\n* Introduction of Gradio, and Hugging Face Spaces, and Wandb\\n* How to setup a Gradio demo using the Wandb integration for JoJoGAN\\n* How to contribute your own Gradio demos after tracking your experiments on wandb to the Wandb organization on Hugging Face\\n\\nHere\\'s an example of an model trained and experiments tracked on wandb, try out the JoJoGAN demo below.\\n\\n<iframe src=\"https://akhaliq-jojogan.hf.space\" frameBorder=\"0\" height=\"810\" title=\"Gradio app\" class=\"container p-0 flex-grow space-iframe\" allow=\"accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking\" sandbox=\"allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/Gradio-and-Wandb-Integration.md'}, lookup_index=0),\n",
              " Document(page_content='allow-scripts allow-downloads\"></iframe>\\n\\n## What is Wandb?\\n\\nWeights and Biases (W&B) allows data scientists and machine learning scientists to track their machine learning experiments at every stage, from training to production. Any metric can be aggregated over samples and shown in panels in a customizable and searchable dashboard, like below:\\n\\n<img alt=\"Screen Shot 2022-08-01 at 5 54 59 PM\" src=\"https://user-images.githubusercontent.com/81195143/182252755-4a0e1ca8-fd25-40ff-8c91-c9da38aaa9ec.png\">\\n\\n\\n## What are Hugging Face Spaces & Gradio?\\n\\n### Gradio\\n\\nGradio lets users demo their machine learning models as a web app, all in a few lines of Python. Gradio wraps any Python function (such as a machine learning model\\'s inference function) into a user inferface and the demos can be launched inside jupyter notebooks, colab notebooks, as well as embedded in your own website and hosted on Hugging Face Spaces for free.\\n\\nGet started [here](https://gradio.app/getting_started)\\n\\n### Hugging Face Spaces\\n\\nHugging Face Spaces is a free hosting option for Gradio demos. Spaces comes with 3 SDK options: Gradio, Streamlit and Static HTML demos. Spaces can be public or private and', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/Gradio-and-Wandb-Integration.md'}, lookup_index=0),\n",
              " Document(page_content=\"the workflow is similar to github repos. There are over 2000+ spaces currently on Hugging Face. Learn more about spaces [here](https://huggingface.co/spaces/launch).\\n\\n\\n## Setting up a Gradio Demo for JoJoGAN\\n\\nNow, let's walk you through how to do this on your own. We'll make the assumption that you're new to W&B and Gradio for the purposes of this tutorial. \\n\\nLet's get started!\\n\\n1. Create a W&B account\\n\\n    Follow [these quick instructions](https://app.wandb.ai/login) to create your free account if you don’t have one already. It shouldn't take more than a couple minutes. Once you're done (or if you've already got an account), next, we'll run a quick colab. \\n\\n2. Open Colab Install Gradio and W&B\\n\\n    We'll be following along with the colab provided in the JoJoGAN repo with some minor modifications to use Wandb and Gradio more effectively. \\n\\n    [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mchong6/JoJoGAN/blob/main/stylize.ipynb)\\n\\n    Install Gradio and Wandb at the top:\\n\\n    ```sh\\n\\n    pip install gradio wandb\\n    ```\\n\\n3. Finetune StyleGAN and W&B experiment tracking\\n\\n    This next step will open a W&B dashboard to track\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/Gradio-and-Wandb-Integration.md'}, lookup_index=0),\n",
              " Document(page_content='your experiments and a gradio panel showing pretrained models to choose from a drop down menu from a Gradio Demo hosted on Huggingface Spaces. Here\\'s the code you need for that:\\n\\n    ```python\\n    \\n    alpha =  1.0 \\n    alpha = 1-alpha\\n\\n    preserve_color = True \\n    num_iter = 100 \\n    log_interval = 50 \\n\\n\\n    samples = []\\n    column_names = [\"Referece (y)\", \"Style Code(w)\", \"Real Face Image(x)\"]\\n\\n    wandb.init(project=\"JoJoGAN\")\\n    config = wandb.config\\n    config.num_iter = num_iter\\n    config.preserve_color = preserve_color\\n    wandb.log(\\n    {\"Style reference\": [wandb.Image(transforms.ToPILImage()(target_im))]},\\n    step=0)\\n\\n    # load discriminator for perceptual loss\\n    discriminator = Discriminator(1024, 2).eval().to(device)\\n    ckpt = torch.load(\\'models/stylegan2-ffhq-config-f.pt\\', map_location=lambda storage, loc: storage)\\n    discriminator.load_state_dict(ckpt[\"d\"], strict=False)\\n\\n    # reset generator\\n    del generator\\n    generator = deepcopy(original_generator)\\n\\n    g_optim = optim.Adam(generator.parameters(), lr=2e-3, betas=(0, 0.99))\\n\\n    # Which layers to swap for generating a family of plausible real images -> fake image\\n    if preserve_color:\\n        id_swap = [9,11,15,16,17]\\n    else:\\n        id_swap =', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/Gradio-and-Wandb-Integration.md'}, lookup_index=0),\n",
              " Document(page_content='list(range(7, generator.n_latent))\\n\\n    for idx in tqdm(range(num_iter)):\\n        mean_w = generator.get_latent(torch.randn([latents.size(0), latent_dim]).to(device)).unsqueeze(1).repeat(1, generator.n_latent, 1)\\n        in_latent = latents.clone()\\n        in_latent[:, id_swap] = alpha*latents[:, id_swap] + (1-alpha)*mean_w[:, id_swap]\\n\\n        img = generator(in_latent, input_is_latent=True)\\n\\n        with torch.no_grad():\\n            real_feat = discriminator(targets)\\n        fake_feat = discriminator(img)\\n\\n        loss = sum([F.l1_loss(a, b) for a, b in zip(fake_feat, real_feat)])/len(fake_feat)\\n        \\n\\n        wandb.log({\"loss\": loss}, step=idx)\\n        if idx % log_interval == 0:\\n            generator.eval()\\n            my_sample = generator(my_w, input_is_latent=True)\\n            generator.train()\\n            my_sample = transforms.ToPILImage()(utils.make_grid(my_sample, normalize=True, range=(-1, 1)))\\n            wandb.log(\\n            {\"Current stylization\": [wandb.Image(my_sample)]},\\n            step=idx)\\n        table_data = [\\n                wandb.Image(transforms.ToPILImage()(target_im)),\\n                wandb.Image(img),\\n                wandb.Image(my_sample),\\n            ]\\n        samples.append(table_data)\\n\\n        g_optim.zero_grad()\\n        loss.backward()\\n        g_optim.step()\\n\\n    out_table = wandb.Table(data=samples,', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/Gradio-and-Wandb-Integration.md'}, lookup_index=0),\n",
              " Document(page_content='columns=column_names)\\n    wandb.log({\"Current Samples\": out_table})\\n    ```\\n\\n4. Save, Download, and Load Model\\n\\n    Here\\'s how to save and download your model.\\n\\n    ```python\\n\\n    from PIL import Image\\n    import torch\\n    torch.backends.cudnn.benchmark = True\\n    from torchvision import transforms, utils\\n    from util import *\\n    import math\\n    import random\\n    import numpy as np\\n    from torch import nn, autograd, optim\\n    from torch.nn import functional as F\\n    from tqdm import tqdm\\n    import lpips\\n    from model import *\\n    from e4e_projection import projection as e4e_projection\\n\\n    from copy import deepcopy\\n    import imageio\\n\\n    import os\\n    import sys\\n    import torchvision.transforms as transforms\\n    from argparse import Namespace\\n    from e4e.models.psp import pSp\\n    from util import *\\n    from huggingface_hub import hf_hub_download\\n    from google.colab import files\\n\\n    torch.save({\"g\": generator.state_dict()}, \"your-model-name.pt\")\\n\\n    files.download(\\'your-model-name.pt\\') \\n\\n    latent_dim = 512\\n    device=\"cuda\"\\n    model_path_s = hf_hub_download(repo_id=\"akhaliq/jojogan-stylegan2-ffhq-config-f\", filename=\"stylegan2-ffhq-config-f.pt\")\\n    original_generator = Generator(1024, latent_dim, 8, 2).to(device)\\n   ', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/Gradio-and-Wandb-Integration.md'}, lookup_index=0),\n",
              " Document(page_content='   ckpt = torch.load(model_path_s, map_location=lambda storage, loc: storage)\\n    original_generator.load_state_dict(ckpt[\"g_ema\"], strict=False)\\n    mean_latent = original_generator.mean_latent(10000)\\n\\n    generator = deepcopy(original_generator)\\n\\n    ckpt = torch.load(\"/content/JoJoGAN/your-model-name.pt\", map_location=lambda storage, loc: storage)\\n    generator.load_state_dict(ckpt[\"g\"], strict=False)\\n    generator.eval()\\n\\n    plt.rcParams[\\'figure.dpi\\'] = 150\\n\\n\\n\\n    transform = transforms.Compose(\\n        [\\n            transforms.Resize((1024, 1024)),\\n            transforms.ToTensor(),\\n            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\\n        ]\\n    )\\n\\n\\n    def inference(img):  \\n        img.save(\\'out.jpg\\')  \\n        aligned_face = align_face(\\'out.jpg\\')\\n\\n        my_w = e4e_projection(aligned_face, \"out.pt\", device).unsqueeze(0)  \\n        with torch.no_grad():\\n            my_sample = generator(my_w, input_is_latent=True)\\n                \\n        \\n        npimage = my_sample[0].cpu().permute(1, 2, 0).detach().numpy()\\n        imageio.imwrite(\\'filename.jpeg\\', npimage)\\n        return \\'filename.jpeg\\'\\n    ```\\n\\n5. Build a Gradio Demo\\n\\n    ```python\\n\\n    import gradio as gr\\n\\n    title = \"JoJoGAN\"\\n    description = \"Gradio Demo for JoJoGAN: One Shot Face Stylization. To', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/Gradio-and-Wandb-Integration.md'}, lookup_index=0),\n",
              " Document(page_content='use it, simply upload your image, or click one of the examples to load them. Read more at the links below.\"\\n\\n    demo = gr.Interface(\\n        inference, \\n        gr.Image(type=\"pil\"), \\n        gr.Image(type=\"file\"),\\n        title=title,\\n        description=description\\n    )\\n    \\n    demo.launch(share=True)\\n    ```\\n\\n6. Integrate Gradio into your W&B Dashboard\\n\\n    The last step—integrating your Gradio demo with your W&B dashboard—is just one extra line:\\n\\n    ```python\\n\\n    demo.integrate(wandb=wandb)\\n    ```\\n\\n    Once you call integrate, a demo will be created and you can integrate it into your dashboard or report\\n\\n    Outside of W&B with Web components, using the gradio-app tags allows anyone can embed Gradio demos on HF spaces directly into their blogs, websites, documentation, etc.:\\n\\n    ```html\\n    \\n    &lt;gradio-app space=\"akhaliq/JoJoGAN\"&gt; &lt;gradio-app&gt;\\n    ```\\n\\n## Conclusion\\n\\nWe hope you enjoyed this brief demo of embedding a Gradio demo to a W&B report! Thanks for making it to the end. To recap:\\n\\n* Only one single reference image is needed for fine-tuning JoJoGAN which usually takes about 1 minute on a GPU in colab. After training, style can be applied to any input image. Read more in the paper.\\n\\n* W&B tracks experiments with just a few lines of', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/Gradio-and-Wandb-Integration.md'}, lookup_index=0),\n",
              " Document(page_content='code added to a colab and you can visualize, sort, and understand your experiments in a single, centralized dashboard.\\n\\n* Gradio, meanwhile, demos the model in a user friendly interface to share anywhere on the web. \\n\\n## How to contribute Gradio demos on HF spaces on the Wandb organization\\n\\n* Create an account on Hugging Face [here](https://huggingface.co/join).\\n* Add Gradio Demo under your username, see this [course](https://huggingface.co/course/chapter9/4?fw=pt) for setting up Gradio Demo on Hugging Face. \\n* Request to join wandb organization [here](https://huggingface.co/wandb).\\n* Once approved transfer model from your username to Wandb organization\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/Gradio-and-Wandb-Integration.md'}, lookup_index=0),\n",
              " Document(page_content='# Gradio and ONNX on Hugging Face\\n\\nRelated spaces: https://huggingface.co/spaces/onnx/EfficientNet-Lite4\\nTags: ONNX, SPACES\\nContributed by Gradio and the <a href=\"https://onnx.ai/\">ONNX</a> team\\n\\n## Introduction\\n\\nIn this Guide, we\\'ll walk you through:\\n\\n* Introduction of ONNX, ONNX model zoo, Gradio, and Hugging Face Spaces\\n* How to setup a Gradio demo for EfficientNet-Lite4\\n* How to contribute your own Gradio demos for the ONNX organization on Hugging Face\\n\\nHere\\'s an example of an ONNX model: try out the EfficientNet-Lite4 demo below.\\n\\n<iframe src=\"https://onnx-efficientnet-lite4.hf.space\" frameBorder=\"0\" height=\"810\" title=\"Gradio app\" class=\"container p-0 flex-grow space-iframe\" allow=\"accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking\" sandbox=\"allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/Gradio-and-ONNX-on-Hugging-Face.md'}, lookup_index=0),\n",
              " Document(page_content='allow-scripts allow-downloads\"></iframe>\\n\\n## What is the ONNX Model Zoo?\\nOpen Neural Network Exchange ([ONNX](https://onnx.ai/)) is an open standard format for representing machine learning models. ONNX is supported by a community of partners who have implemented it in many frameworks and tools. For example, if you have trained a model in TensorFlow or PyTorch, you can convert it to ONNX easily, and from there run it on a variety of devices using an engine/compiler like ONNX Runtime.\\n\\nThe [ONNX Model Zoo](https://github.com/onnx/models) is a collection of pre-trained, state-of-the-art models in the ONNX format contributed by community members. Accompanying each model are Jupyter notebooks for model training and running inference with the trained model. The notebooks are written in Python and include links to the training dataset as well as references to the original paper that describes the model architecture.\\n\\n\\n## What are Hugging Face Spaces & Gradio?\\n\\n### Gradio\\n\\nGradio lets users demo their machine learning models as a web app all in python code. Gradio wraps a python function into a user inferface and the demos can be launched inside jupyter notebooks, colab notebooks, as well', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/Gradio-and-ONNX-on-Hugging-Face.md'}, lookup_index=0),\n",
              " Document(page_content='as embedded in your own website and hosted on Hugging Face Spaces for free.\\n\\nGet started [here](https://gradio.app/getting_started)\\n\\n### Hugging Face Spaces\\n\\nHugging Face Spaces is a free hosting option for Gradio demos. Spaces comes with 3 SDK options: Gradio, Streamlit and Static HTML demos. Spaces can be public or private and the workflow is similar to github repos. There are over 2000+ spaces currently on Hugging Face. Learn more about spaces [here](https://huggingface.co/spaces/launch).\\n\\n### Hugging Face Models\\n\\nHugging Face Model Hub also supports ONNX models and ONNX models can be filtered through the [ONNX tag](https://huggingface.co/models?library=onnx&sort=downloads)\\n\\n## How did Hugging Face help the ONNX Model Zoo?\\nThere are a lot of Jupyter notebooks in the ONNX Model Zoo for users to test models. Previously, users needed to download the models themselves and run those notebooks locally for testing. With Hugging Face, the testing process can be much simpler and more user-friendly. Users can easily try certain ONNX Model Zoo model on Hugging Face Spaces and run a quick demo powered by Gradio with ONNX Runtime, all on cloud without downloading anything locally. Note,', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/Gradio-and-ONNX-on-Hugging-Face.md'}, lookup_index=0),\n",
              " Document(page_content='there are various runtimes for ONNX, e.g., [ONNX Runtime](https://github.com/microsoft/onnxruntime), [MXNet](https://github.com/apache/incubator-mxnet).\\n\\n## What is the role of ONNX Runtime?\\nONNX Runtime is a cross-platform inference and training machine-learning accelerator. It makes live Gradio demos with ONNX Model Zoo model on Hugging Face possible.\\n\\nONNX Runtime inference can enable faster customer experiences and lower costs, supporting models from deep learning frameworks such as PyTorch and TensorFlow/Keras as well as classical machine learning libraries such as scikit-learn, LightGBM, XGBoost, etc. ONNX Runtime is compatible with different hardware, drivers, and operating systems, and provides optimal performance by leveraging hardware accelerators where applicable alongside graph optimizations and transforms. For more information please see the [official website](https://onnxruntime.ai/).\\n\\n## Setting up a Gradio Demo for EfficientNet-Lite4\\n\\nEfficientNet-Lite 4 is the largest variant and most accurate of the set of EfficientNet-Lite models. It is an integer-only quantized model that produces the highest accuracy of all of the EfficientNet', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/Gradio-and-ONNX-on-Hugging-Face.md'}, lookup_index=0),\n",
              " Document(page_content='models. It achieves 80.4% ImageNet top-1 accuracy, while still running in real-time (e.g. 30ms/image) on a Pixel 4 CPU. To learn more read the [model card](https://github.com/onnx/models/tree/main/vision/classification/efficientnet-lite4)\\n\\nHere we walk through setting up a example demo for EfficientNet-Lite4 using Gradio\\n\\nFirst we import our dependencies and download and load the efficientnet-lite4 model from the onnx model zoo. Then load the labels from the labels_map.txt file. We then setup our preprocessing functions, load the model for inference, and setup the inference function. Finally, the inference function is wrapped into a gradio inferface for a user to interact with. See the full code below.\\n\\n\\n```python\\nimport numpy as np\\nimport math\\nimport matplotlib.pyplot as plt\\nimport cv2\\nimport json\\nimport gradio as gr\\nfrom huggingface_hub import hf_hub_download\\nfrom onnx import hub\\nimport onnxruntime as ort\\n\\n# loads ONNX model from ONNX Model Zoo\\nmodel = hub.load(\"efficientnet-lite4\")\\n# loads the labels text file\\nlabels = json.load(open(\"labels_map.txt\", \"r\"))\\n\\n# sets image file dimensions to 224x224 by resizing and cropping image from center\\ndef', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/Gradio-and-ONNX-on-Hugging-Face.md'}, lookup_index=0),\n",
              " Document(page_content=\"pre_process_edgetpu(img, dims):\\n    output_height, output_width, _ = dims\\n    img = resize_with_aspectratio(img, output_height, output_width, inter_pol=cv2.INTER_LINEAR)\\n    img = center_crop(img, output_height, output_width)\\n    img = np.asarray(img, dtype='float32')\\n    # converts jpg pixel value from [0 - 255] to float array [-1.0 - 1.0]\\n    img -= [127.0, 127.0, 127.0]\\n    img /= [128.0, 128.0, 128.0]\\n    return img\\n\\n# resizes the image with a proportional scale\\ndef resize_with_aspectratio(img, out_height, out_width, scale=87.5, inter_pol=cv2.INTER_LINEAR):\\n    height, width, _ = img.shape\\n    new_height = int(100. * out_height / scale)\\n    new_width = int(100. * out_width / scale)\\n    if height > width:\\n        w = new_width\\n        h = int(new_height * height / width)\\n    else:\\n        h = new_height\\n        w = int(new_width * width / height)\\n    img = cv2.resize(img, (w, h), interpolation=inter_pol)\\n    return img\\n\\n# crops the image around the center based on given height and width\\ndef center_crop(img, out_height, out_width):\\n    height, width, _ = img.shape\\n    left = int((width - out_width) / 2)\\n    right = int((width + out_width) / 2)\\n    top = int((height - out_height) / 2)\\n    bottom = int((height + out_height) / 2)\\n    img = img[top:bottom,\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/Gradio-and-ONNX-on-Hugging-Face.md'}, lookup_index=0),\n",
              " Document(page_content='left:right]\\n    return img\\n\\n\\nsess = ort.InferenceSession(model)\\n\\ndef inference(img):\\n  img = cv2.imread(img)\\n  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\\n  \\n  img = pre_process_edgetpu(img, (224, 224, 3))\\n  \\n  img_batch = np.expand_dims(img, axis=0)\\n\\n  results = sess.run([\"Softmax:0\"], {\"images:0\": img_batch})[0]\\n  result = reversed(results[0].argsort()[-5:])\\n  resultdic = {}\\n  for r in result:\\n      resultdic[labels[str(r)]] = float(results[0][r])\\n  return resultdic\\n  \\ntitle = \"EfficientNet-Lite4\"\\ndescription = \"EfficientNet-Lite 4 is the largest variant and most accurate of the set of EfficientNet-Lite model. It is an integer-only quantized model that produces the highest accuracy of all of the EfficientNet models. It achieves 80.4% ImageNet top-1 accuracy, while still running in real-time (e.g. 30ms/image) on a Pixel 4 CPU.\"\\nexamples = [[\\'catonnx.jpg\\']]\\ngr.Interface(inference, gr.Image(type=\"filepath\"), \"label\", title=title, description=description, examples=examples).launch()\\n```\\n\\n\\n## How to contribute Gradio demos on HF spaces using ONNX models\\n\\n* Add model to the [onnx model', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/Gradio-and-ONNX-on-Hugging-Face.md'}, lookup_index=0),\n",
              " Document(page_content='zoo](https://github.com/onnx/models/blob/main/.github/PULL_REQUEST_TEMPLATE.md)\\n* Create an account on Hugging Face [here](https://huggingface.co/join).\\n* See list of models left to add to ONNX organization, please refer to the table with the [Models list](https://github.com/onnx/models#models)\\n* Add Gradio Demo under your username, see this [blog post](https://huggingface.co/blog/gradio-spaces) for setting up Gradio Demo on Hugging Face. \\n* Request to join ONNX Organization [here](https://huggingface.co/onnx).\\n* Once approved transfer model from your username to ONNX organization\\n* Add a badge for model in model table, see examples in [Models list](https://github.com/onnx/models#models)\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/04_integrating-other-frameworks/Gradio-and-ONNX-on-Hugging-Face.md'}, lookup_index=0),\n",
              " Document(page_content='# Running Background Tasks \\n\\nRelated spaces: https://huggingface.co/spaces/freddyaboulton/gradio-google-forms\\nTags: TASKS, SCHEDULED, TABULAR, DATA \\n\\n## Introduction\\n\\nThis guide explains how you can run background tasks from your gradio app.\\nBackground tasks are operations that you\\'d like to perform outside the request-response\\nlifecycle of your app either once or on a periodic schedule.\\nExamples of background tasks include periodically synchronizing data to an external database or \\nsending a report of model predictions via email.\\n\\n## Overview \\n    \\nWe will be creating a simple \"Google-forms-style\" application to gather feedback from users of the gradio library.\\nWe will use a local sqlite database to store our data, but we will periodically synchronize the state of the database\\nwith a [HuggingFace Dataset](https://huggingface.co/datasets) so that our user reviews are always backed up.\\nThe synchronization will happen in a background task running every 60 seconds.\\n\\nAt the end of the demo, you\\'ll have a fully working application like this one:\\n\\n<gradio-app space=\"freddyaboulton/gradio-google-forms\"> </gradio-app>\\n\\n\\n## Step 1 - Write your database logic 💾\\nOur', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/running-background-tasks.md'}, lookup_index=0),\n",
              " Document(page_content='application will store the name of the reviewer, their rating of gradio on a scale of 1 to 5, as well as\\nany comments they want to share about the library. Let\\'s write some code that creates a database table to\\nstore this data. We\\'ll also write some functions to insert a review into that table and fetch the latest 10 reviews.\\n\\nWe\\'re going to use the `sqlite3` library to connect to our sqlite database but gradio will work with any library.\\n\\nThe code will look like this:\\n\\n```python\\nDB_FILE = \"./reviews.db\"\\ndb = sqlite3.connect(DB_FILE)\\n\\n# Create table if it doesn\\'t already exist\\ntry:\\n    db.execute(\"SELECT * FROM reviews\").fetchall()\\n    db.close()\\nexcept sqlite3.OperationalError:\\n    db.execute(\\n        \\'\\'\\'\\n        CREATE TABLE reviews (id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,\\n                              created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP NOT NULL,\\n                              name TEXT, review INTEGER, comments TEXT)\\n        \\'\\'\\')\\n    db.commit()\\n    db.close()\\n\\ndef get_latest_reviews(db: sqlite3.Connection):\\n    reviews = db.execute(\"SELECT * FROM reviews ORDER BY id DESC limit 10\").fetchall()\\n    total_reviews = db.execute(\"Select COUNT(id) from reviews\").fetchone()[0]\\n    reviews = pd.DataFrame(reviews, columns=[\"id\", \"date_created\",', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/running-background-tasks.md'}, lookup_index=0),\n",
              " Document(page_content='\"name\", \"review\", \"comments\"])\\n    return reviews, total_reviews\\n\\n\\ndef add_review(name: str, review: int, comments: str):\\n    db = sqlite3.connect(DB_FILE)\\n    cursor = db.cursor()\\n    cursor.execute(\"INSERT INTO reviews(name, review, comments) VALUES(?,?,?)\", [name, review, comments])\\n    db.commit()\\n    reviews, total_reviews = get_latest_reviews(db)\\n    db.close()\\n    return reviews, total_reviews\\n```\\n\\nLet\\'s also write a function to load the latest reviews when the gradio application loads:\\n```python\\ndef load_data():\\n    db = sqlite3.connect(DB_FILE)\\n    reviews, total_reviews = get_latest_reviews(db)\\n    db.close()\\n    return reviews, total_reviews\\n```\\n\\n## Step 2 - Create a gradio app ⚡\\nNow that we have our database logic defined, we can use gradio create a dynamic web page to ask our users for feedback! \\n\\n```python\\nwith gr.Blocks() as demo:\\n    with gr.Row():\\n        with gr.Column():\\n            name = gr.Textbox(label=\"Name\", placeholder=\"What is your name?\")\\n            review = gr.Radio(label=\"How satisfied are you with using gradio?\", choices=[1, 2, 3, 4, 5])\\n            comments = gr.Textbox(label=\"Comments\", lines=10, placeholder=\"Do you have any feedback on gradio?\")\\n            submit = gr.Button(value=\"Submit', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/running-background-tasks.md'}, lookup_index=0),\n",
              " Document(page_content='Feedback\")\\n        with gr.Column():\\n            data = gr.Dataframe(label=\"Most recently created 10 rows\")\\n            count = gr.Number(label=\"Total number of reviews\")\\n    submit.click(add_review, [name, review, comments], [data, count])\\n    demo.load(load_data, None, [data, count])\\n```\\n\\n## Step 3 - Synchronize with HuggingFace Datasets 🤗\\n\\nWe could call `demo.launch()` after step 2 and have a fully functioning application. However,\\nour data would be stored locally on our machine. If the sqlite file were accidentally deleted, we\\'d lose all of our reviews!\\nLet\\'s back up our data to a dataset on the HuggingFace hub.\\n\\nCreate a dataset [here](https://huggingface.co/datasets) before proceeding.\\n\\nNow at the **top** of our script, we\\'ll use the [huggingface hub client library](https://huggingface.co/docs/huggingface_hub/index)\\nto connect to our dataset and pull the latest backup.\\n\\n```python\\nTOKEN = os.environ.get(\\'HUB_TOKEN\\')\\nrepo = huggingface_hub.Repository(\\n    local_dir=\"data\",\\n    repo_type=\"dataset\",\\n    clone_from=\"<name-of-your-dataset>\",\\n    use_auth_token=TOKEN\\n)\\nrepo.git_pull()\\n\\nshutil.copyfile(\"./data/reviews.db\", DB_FILE)\\n```\\n\\nNote that you\\'ll have to get an access', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/running-background-tasks.md'}, lookup_index=0),\n",
              " Document(page_content='token from the \"Settings\" tab of your HuggingFace for the above code to work.\\nIn the script, the token is securely accessed via an environment variable.\\n\\n![access_token](/assets/guides/access_token.png)\\n\\nNow we will create a background task to synch our local database to the dataset hub every 60 seconds.\\nWe will use the [AdvancedPythonScheduler](https://apscheduler.readthedocs.io/en/3.x/) to handle the scheduling.\\nHowever, this is not the only task scheduling library available. Feel free to use whatever you are comfortable with.\\n\\nThe function to back up our data will look like this:\\n\\n```python\\nfrom apscheduler.schedulers.background import BackgroundScheduler\\n\\ndef backup_db():\\n    shutil.copyfile(DB_FILE, \"./data/reviews.db\")\\n    db = sqlite3.connect(DB_FILE)\\n    reviews = db.execute(\"SELECT * FROM reviews\").fetchall()\\n    pd.DataFrame(reviews).to_csv(\"./data/reviews.csv\", index=False)\\n    print(\"updating db\")\\n    repo.push_to_hub(blocking=False, commit_message=f\"Updating data at {datetime.datetime.now()}\")\\n\\n\\nscheduler = BackgroundScheduler()\\nscheduler.add_job(func=backup_db, trigger=\"interval\",', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/running-background-tasks.md'}, lookup_index=0),\n",
              " Document(page_content=\"seconds=60)\\nscheduler.start()\\n```\\n\\n\\n## Step 4 (Bonus) - Deployment to HuggingFace Spaces\\nYou can use the HuggingFace [Spaces](https://huggingface.co/spaces) platform to deploy this application for free ✨\\n\\nIf you haven't used Spaces before, follow the previous guide [here](/using_hugging_face_integrations).\\nYou will have to use the `HUB_TOKEN` environment variable as a secret in the Guides.\\n\\n## Conclusion\\nCongratulations! You know how to run background tasks from your gradio app on a schedule ⏲️.  \\n\\nCheckout the application running on Spaces [here](https://huggingface.co/spaces/freddyaboulton/gradio-google-forms).\\nThe complete code is [here](https://huggingface.co/spaces/freddyaboulton/gradio-google-forms/blob/main/app.py)\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/running-background-tasks.md'}, lookup_index=0),\n",
              " Document(page_content='# Building a Pictionary App\\n\\nRelated spaces: https://huggingface.co/spaces/nateraw/quickdraw\\nTags: SKETCHPAD, LABELS, LIVE\\n\\n## Introduction\\n\\nHow well can an algorithm guess what you\\'re drawing? A few years ago, Google released the **Quick Draw** dataset, which contains drawings made by humans of a variety of every objects. Researchers have used this dataset to train models to guess Pictionary-style drawings. \\n\\nSuch models are perfect to use with Gradio\\'s *sketchpad* input, so in this tutorial we will build a Pictionary web application using Gradio. We will be able to build the whole web application in Python, and will look like this (try drawing something!):\\n\\n<iframe src=\"https://abidlabs-draw2.hf.space\" frameBorder=\"0\" height=\"450\" title=\"Gradio app\" class=\"container p-0 flex-grow space-iframe\" allow=\"accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking\"', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/building-a-pictionary-app.md'}, lookup_index=0),\n",
              " Document(page_content='sandbox=\"allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads\"></iframe>\\n\\nLet\\'s get started! This guide covers how to build a pictionary app (step-by-step): \\n\\n1. [Set up the Sketch Recognition Model](#1-set-up-the-sketch-recognition-model)\\n2. [Define a `predict` function](#2-define-a-predict-function)\\n3. [Create a Gradio Interface](#3-create-a-gradio-interface)\\n\\n### Prerequisites\\n\\nMake sure you have the `gradio` Python package already [installed](/getting_started). To use the pretrained sketchpad model, also install `torch`.\\n\\n## 1. Set up the Sketch Recognition Model\\n\\nFirst, you will need a sketch recognition model. Since many researchers have already trained their own models on the Quick Draw dataset, we will use a pretrained model in this tutorial. Our model is a light 1.5 MB  model trained by Nate Raw, that [you can download here](https://huggingface.co/spaces/nateraw/quickdraw/blob/main/pytorch_model.bin). \\n\\nIf you are interested, here [is the code](https://github.com/nateraw/quickdraw-pytorch) that was used to train the model. We will simply load the pretrained model', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/building-a-pictionary-app.md'}, lookup_index=0),\n",
              " Document(page_content=\"in PyTorch, as follows:\\n\\n```python\\nimport torch\\nfrom torch import nn\\n\\nmodel = nn.Sequential(\\n    nn.Conv2d(1, 32, 3, padding='same'),\\n    nn.ReLU(),\\n    nn.MaxPool2d(2),\\n    nn.Conv2d(32, 64, 3, padding='same'),\\n    nn.ReLU(),\\n    nn.MaxPool2d(2),\\n    nn.Conv2d(64, 128, 3, padding='same'),\\n    nn.ReLU(),\\n    nn.MaxPool2d(2),\\n    nn.Flatten(),\\n    nn.Linear(1152, 256),\\n    nn.ReLU(),\\n    nn.Linear(256, len(LABELS)),\\n)\\nstate_dict = torch.load('pytorch_model.bin',    map_location='cpu')\\nmodel.load_state_dict(state_dict, strict=False)\\nmodel.eval()\\n```\\n\\n## 2. Define a `predict` function\\n\\nNext, you will need to define a function that takes in the *user input*, which in this case is a sketched image, and returns the prediction. The prediction should be returned as a dictionary whose keys are class name and values are confidence probabilities. We will load the class names from this [text file](https://huggingface.co/spaces/nateraw/quickdraw/blob/main/class_names.txt).\\n\\nIn the case of our pretrained model, it will look like this:\\n\\n```python\\nfrom pathlib import Path\\n\\nLABELS = Path('class_names.txt').read_text().splitlines()\\n\\ndef predict(img):\\n    x = torch.tensor(img,\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/building-a-pictionary-app.md'}, lookup_index=0),\n",
              " Document(page_content='dtype=torch.float32).unsqueeze(0).unsqueeze(0) / 255.\\n    with torch.no_grad():\\n        out = model(x)\\n    probabilities = torch.nn.functional.softmax(out[0], dim=0)\\n    values, indices = torch.topk(probabilities, 5)\\n    confidences = {LABELS[i]: v.item() for i, v in zip(indices, values)}\\n    return confidences\\n```\\n\\nLet\\'s break this down. The function takes one parameters:\\n\\n* `img`: the input image as a `numpy` array\\n\\nThen, the function converts the image to a PyTorch `tensor`, passes it through the model, and returns:\\n\\n* `confidences`: the top five predictions, as a dictionary whose keys are class labels and whose values are confidence probabilities\\n\\n## 3. Create a Gradio Interface\\n\\nNow that we have our predictive function set up, we can create a Gradio Interface around it. \\n\\nIn this case, the input component is a sketchpad. To create a sketchpad input, we can use the convenient string shortcut, `\"sketchpad\"` which creates a canvas for a user to draw on and handles the preprocessing to convert that to a numpy array. \\n\\nThe output component will be a `\"label\"`, which displays the top labels in a nice form.\\n\\nFinally, we\\'ll add one more parameter, setting `live=True`, which allows our interface to run', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/building-a-pictionary-app.md'}, lookup_index=0),\n",
              " Document(page_content='in real time, adjusting its predictions every time a user draws on the sketchpad. The code for Gradio looks like this:\\n\\n```python\\nimport gradio as gr\\n\\ngr.Interface(fn=predict, \\n             inputs=\"sketchpad\",\\n             outputs=\"label\",\\n             live=True).launch()\\n```\\n\\nThis produces the following interface, which you can try right here in your browser (try drawing something, like a \"snake\" or a \"laptop\"):\\n\\n<iframe src=\"https://abidlabs-draw2.hf.space\" frameBorder=\"0\" height=\"450\" title=\"Gradio app\" class=\"container p-0 flex-grow space-iframe\" allow=\"accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking\" sandbox=\"allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads\"></iframe>\\n\\n----------\\n\\nAnd you\\'re done! That\\'s all the code you need to build a Pictionary-style guessing app. Have fun and try to find some edge', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/building-a-pictionary-app.md'}, lookup_index=0),\n",
              " Document(page_content='cases 🧐\\n\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/building-a-pictionary-app.md'}, lookup_index=0),\n",
              " Document(page_content='# How to Use the 3D Model Component\\n\\nRelated spaces: https://huggingface.co/spaces/dawood/Model3D, https://huggingface.co/spaces/radames/PIFu-Clothed-Human-Digitization, https://huggingface.co/spaces/radames/dpt-depth-estimation-3d-obj\\nTags: VISION, IMAGE\\n\\n## Introduction\\n\\n3D models are becoming more popular in machine learning and make for some of the most fun demos to experiment with. Using `gradio`, you can easily build a demo of your 3D image model and share it with anyone. The Gradio 3D Model component accepts 3 file types including: *.obj*, *.glb*, & *.gltf*.\\n\\nThis guide will show you how to build a demo for your 3D image model in a few lines of code; like the one below. Play around with 3D object by clicking around, dragging and zooming:\\n\\n<gradio-app space=\"dawood/Model3D\"> </gradio-app>\\n\\n### Prerequisites\\n\\nMake sure you have the `gradio` Python package already [installed](https://gradio.app/quickstart).\\n\\n\\n## Taking a Look at the Code\\n\\nLet\\'s take a look at how to create the minimal interface above. The prediction function in this case will just return the original 3D model mesh, but you can change this function to run inference on your machine learning', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/how-to-use-3D-model-component.md'}, lookup_index=0),\n",
              " Document(page_content='model. We\\'ll take a look at more complex examples below.\\n\\n```python\\nimport gradio as gr\\n\\ndef load_mesh(mesh_file_name):\\n    return mesh_file_name\\n\\ndemo = gr.Interface(\\n    fn=load_mesh,\\n    inputs=gr.Model3D(),\\n    outputs=gr.Model3D(clear_color=[0.0, 0.0, 0.0, 0.0],  label=\"3D Model\"),\\n    examples=[\\n        [\"files/Bunny.obj\"],\\n        [\"files/Duck.glb\"],\\n        [\"files/Fox.gltf\"],\\n        [\"files/face.obj\"],\\n    ],\\n    cache_examples=True,\\n)\\n\\ndemo.launch()\\n```\\n\\nLet\\'s break down the code above:\\n\\n`load_mesh`: This is our \\'prediction\\' function and for simplicity, this function will take in the 3D model mesh and return it.\\n\\nCreating the Interface:\\n\\n* `fn`: the prediction function that is used when the user clicks submit. In our case this is the `load_mesh` function.\\n* `inputs`: create a model3D input component. The input expects an uploaded file as a {str} filepath.\\n* `outputs`: create a model3D output component. The output component also expects a file as a {str} filepath.\\n  * `clear_color`: this is the background color of the 3D model canvas. Expects RGBa values.\\n  * `label`: the label that appears on the top left of the component.\\n* `examples`: list of 3D model files. The 3D model component can accept', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/how-to-use-3D-model-component.md'}, lookup_index=0),\n",
              " Document(page_content='*.obj*, *.glb*, & *.gltf* file types.\\n* `cache_examples`: saves the predicted output for the examples, to save time on inference.\\n\\n\\n## Exploring mode complex Model3D Demos:\\n\\nBelow is a demo that uses the DPT model to predict the depth of an image and then uses 3D Point Cloud to create a 3D object. Take a look at the [app.py](https://huggingface.co/spaces/radames/dpt-depth-estimation-3d-obj/blob/main/app.py) file for a peek into the code and the model prediction function.\\n<gradio-app space=\"radames/dpt-depth-estimation-3d-obj\"> </gradio-app>\\n\\nBelow is a demo that uses the PIFu model to convert an image of a clothed human into a 3D digitized model. Take a look at the [spaces.py](https://huggingface.co/spaces/radames/PIFu-Clothed-Human-Digitization/blob/main/PIFu/spaces.py) file for a peek into the code and the model prediction function.\\n\\n<gradio-app space=\"radames/PIFu-Clothed-Human-Digitization\"> </gradio-app>\\n\\n----------\\n\\nAnd you\\'re done! That\\'s all the code you need to build an interface for your Model3D model. Here are some references that you may find useful:\\n\\n* Gradio\\'s [\"Getting Started\" guide](https://gradio.app/getting_started/)\\n* The', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/how-to-use-3D-model-component.md'}, lookup_index=0),\n",
              " Document(page_content='first [3D Model Demo](https://huggingface.co/spaces/dawood/Model3D) and [complete code](https://huggingface.co/spaces/dawood/Model3D/tree/main) (on Hugging Face Spaces)\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/how-to-use-3D-model-component.md'}, lookup_index=0),\n",
              " Document(page_content='# How to Create a Chatbot\\n\\nRelated spaces: https://huggingface.co/spaces/abidlabs/chatbot-minimal, https://huggingface.co/spaces/ThomasSimonini/Chat-with-Gandalf-GPT-J6B, https://huggingface.co/spaces/gorkemgoknar/moviechatbot, https://huggingface.co/spaces/Kirili4ik/chat-with-Kirill\\nTags: NLP, TEXT, HTML\\n\\n## Introduction\\n\\nChatbots are widely studied in natural language processing (NLP) research and are a common use case of NLP in industry. Because chatbots are designed to be used directly by customers and end users, it is important to validate that chatbots are behaving as expected when confronted with a wide variety of input prompts. \\n\\nUsing `gradio`, you can easily build a demo of your chatbot model and share that with a testing team, or test it yourself using an intuitive chatbot GUI.\\n\\nThis tutorial will show how to take a pretrained chatbot model and deploy it with a Gradio interface in 4 steps. The live chatbot interface that we create will look something like this (try it!):\\n\\n<iframe src=\"https://abidlabs-chatbot-stylized.hf.space\" frameBorder=\"0\" height=\"350\" title=\"Gradio app\" class=\"container p-0 flex-grow space-iframe\"', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/creating-a-chatbot.md'}, lookup_index=0),\n",
              " Document(page_content='allow=\"accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking\" sandbox=\"allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads\"></iframe>\\n\\nChatbots are *stateful*, meaning that the model\\'s prediction can change depending on how the user has previously interacted with the model. So, in this tutorial, we will also cover how to use **state** with Gradio demos. \\n\\n### Prerequisites\\n\\nMake sure you have the `gradio` Python package already [installed](/quickstart). To use a pretrained chatbot model, also install `transformers` and `torch`. \\n\\nLet\\'s get started! Here\\'s how to build your own chatbot: \\n\\n1. [Set up the Chatbot Model](#1-set-up-the-chatbot-model)\\n2. [Define a `predict` function](#2-define-a-predict-function)\\n3. [Create a Gradio Interface](#3-create-a-gradio-interface)\\n\\n## 1. Set up the', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/creating-a-chatbot.md'}, lookup_index=0),\n",
              " Document(page_content='Chatbot Model\\n\\nFirst, you will need to have a chatbot model that you have either trained yourself or you will need to download a pretrained model. In this tutorial, we will use a pretrained chatbot model, `DialoGPT`, and its tokenizer from the [Hugging Face Hub](https://huggingface.co/microsoft/DialoGPT-medium), but you can replace this with your own model. \\n\\nHere is the code to load `DialoGPT` from Hugging Face `transformers`.\\n\\n```python\\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\\nimport torch\\n\\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\\nmodel = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\")\\n```\\n\\n## 2. Define a `predict` function\\n\\nNext, you will need to define a function that takes in the *user input* as well as the previous *chat history* to generate a response.\\n\\nIn the case of our pretrained model, it will look like this:\\n\\n```python\\ndef predict(input, history=[]):\\n    # tokenize the new input sentence\\n    new_user_input_ids = tokenizer.encode(input + tokenizer.eos_token, return_tensors=\\'pt\\')\\n\\n    # append the new user input tokens to the chat history\\n    bot_input_ids =', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/creating-a-chatbot.md'}, lookup_index=0),\n",
              " Document(page_content='torch.cat([torch.LongTensor(history), new_user_input_ids], dim=-1)\\n\\n    # generate a response \\n    history = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id).tolist()\\n\\n    # convert the tokens to text, and then split the responses into lines\\n    response = tokenizer.decode(history[0]).split(\"<|endoftext|>\")\\n    response = [(response[i], response[i+1]) for i in range(0, len(response)-1, 2)]  # convert to tuples of list\\n    return response, history\\n```\\n\\nLet\\'s break this down. The function takes two parameters:\\n\\n* `input`: which is what the user enters (through the Gradio GUI) in a particular step of the conversation. \\n* `history`: which represents the **state**, consisting of the list of user and bot responses. To create a stateful Gradio demo, we *must* pass in a parameter to represent the state, and we set the default value of this parameter to be the initial value of the state (in this case, the empty list since this is what we would like the chat history to be at the start).\\n\\nThen, the function tokenizes the input and concatenates it with the tokens corresponding to the previous user and bot responses. Then, this is fed into the pretrained model to get a', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/creating-a-chatbot.md'}, lookup_index=0),\n",
              " Document(page_content='prediction. Finally, we do some cleaning up so that we can return two values from our function:\\n\\n* `response`: which is a list of tuples of strings corresponding to all of the user and bot responses. This will be rendered as the output in the Gradio demo.\\n* `history` variable, which is the token representation of all of the user and bot responses. In stateful Gradio demos, we *must* return the updated state at the end of the function. \\n\\n## 3. Create a Gradio Interface\\n\\nNow that we have our predictive function set up, we can create a Gradio Interface around it. \\n\\nIn this case, our function takes in two values, a text input and a state input. The corresponding input components in `gradio` are `\"text\"` and `\"state\"`. \\n\\nThe function also returns two values. We will display the list of responses using the dedicated `\"chatbot\"` component and use the `\"state\"` output component type for the second return value.\\n\\nNote that the `\"state\"` input and output components are not displayed. \\n\\n```python\\nimport gradio as gr\\n\\ngr.Interface(fn=predict,\\n             inputs=[\"text\", \"state\"],\\n             outputs=[\"chatbot\", \"state\"]).launch()\\n```\\n\\nThis produces the following interface, which you can try right here in your browser (try', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/creating-a-chatbot.md'}, lookup_index=0),\n",
              " Document(page_content='typing in some simple greetings like \"Hi!\" to get started):\\n\\n<iframe src=\"https://abidlabs-chatbot-stylized.hf.space\" frameBorder=\"0\" height=\"350\" title=\"Gradio app\" class=\"container p-0 flex-grow space-iframe\" allow=\"accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking\" sandbox=\"allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads\"></iframe>\\n\\n\\n----------\\n\\nAnd you\\'re done! That\\'s all the code you need to build an interface for your chatbot model. Here are some references that you may find useful:\\n\\n* Gradio\\'s [Quickstart guide](https://gradio.app/quickstart/)\\n* The final [chatbot demo](https://huggingface.co/spaces/abidlabs/chatbot-stylized) and [complete code](https://huggingface.co/spaces/abidlabs/chatbot-stylized/tree/main) (on Hugging Face Spaces)\\n\\n\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/creating-a-chatbot.md'}, lookup_index=0),\n",
              " Document(page_content='# Using Flagging\\n\\nRelated spaces: https://huggingface.co/spaces/gradio/calculator-flagging-crowdsourced, https://huggingface.co/spaces/gradio/calculator-flagging-options, https://huggingface.co/spaces/gradio/calculator-flag-basic\\nTags: FLAGGING, DATA\\n\\n## Introduction\\n\\nWhen you demo a machine learning model, you might want to collect data from users who try the model, particularly data points in which the model is not behaving as expected. Capturing these \"hard\" data points is valuable because it allows you to improve your machine learning model and make it more reliable and robust.\\n\\nGradio simplifies the collection of this data by including a **Flag** button with every `Interface`. This allows a user or tester to easily send data back to the machine where the demo is running. In this Guide, we discuss more about how to use the flagging feature, both with `gradio.Interface` as well as with `gradio.Blocks`.\\n\\n## The **Flag** button in `gradio.Interface`\\n\\nFlagging with Gradio\\'s `Interface` is especially easy. By default, underneath the output components, there is a button marked **Flag**. When a user testing your model sees input with interesting output, they', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/using-flagging.md'}, lookup_index=0),\n",
              " Document(page_content='can click the flag button to send the input and output data back to the machine where the demo is running. The sample is saved to a CSV log file (by default). If the demo involves images, audio, video, or other types of files, these are saved separately in a parallel directory and the paths to these files are saved in the CSV file.\\n\\nThere are [four parameters](https://gradio.app/docs/#interface-header) in `gradio.Interface` that control how flagging works. We will go over them in greater detail.\\n\\n* `allow_flagging`: this parameter can be set to either `\"manual\"` (default), `\"auto\"`, or `\"never\"`.                 \\n    * `manual`: users will see a button to flag, and samples are only flagged when the button is clicked.\\n    * `auto`: users will not see a button to flag, but every sample will be flagged automatically. \\n    * `never`: users will not see a button to flag, and no sample will be flagged. \\n* `flagging_options`: this parameter can be either `None` (default) or a list of strings.\\n    * If `None`, then the user simply clicks on the **Flag** button and no additional options are shown.\\n    * If a list of strings are provided, then the user sees several buttons, corresponding to each of the strings that are provided. For example, if the', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/using-flagging.md'}, lookup_index=0),\n",
              " Document(page_content='value of this parameter is `[\"Incorrect\", \"Ambiguous\"]`, then buttons labeled **Flag as Incorrect** and **Flag as Ambiguous** appear. This only applies if `allow_flagging` is `\"manual\"`.\\n    * The chosen option is then logged along with the input and output.\\n* `flagging_dir`: this parameter takes a string.\\n    * It represents what to name the directory where flagged data is stored.\\n* `flagging_callback`: this parameter takes an instance of a subclass of the `FlaggingCallback` class\\n    * Using this parameter allows you to write custom code that gets run when the flag button is clicked\\n    * By default, this is set to an instance of `gr.CSVLogger`\\n    * One example is setting it to an instance of `gr.HuggingFaceDatasetSaver` which can allow you to pipe any flagged data into a HuggingFace Dataset. (See more below.)\\n\\n## What happens to flagged data?\\n\\nWithin the directory provided by the `flagging_dir` argument, a CSV file will log the flagged data. \\n\\nHere\\'s an example: The code below creates the calculator interface embedded below it:\\n\\n```python\\nimport gradio as gr\\n\\n\\ndef calculator(num1, operation, num2):\\n    if operation == \"add\":\\n        return num1 + num2\\n    elif operation == \"subtract\":\\n        return num1 - num2\\n    elif', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/using-flagging.md'}, lookup_index=0),\n",
              " Document(page_content='operation == \"multiply\":\\n        return num1 * num2\\n    elif operation == \"divide\":\\n        return num1 / num2\\n\\n\\niface = gr.Interface(\\n    calculator,\\n    [\"number\", gr.Radio([\"add\", \"subtract\", \"multiply\", \"divide\"]), \"number\"],\\n    \"number\",\\n    allow_flagging=\"manual\"\\n)\\n\\niface.launch()\\n```\\n\\n<gradio-app space=\"gradio/calculator-flag-basic/\"></gradio-app>\\n\\nWhen you click the flag button above, the directory where the interface was launched will include a new flagged subfolder, with a csv file inside it. This csv file includes all the data that was flagged. \\n\\n```directory\\n+-- flagged/\\n|   +-- logs.csv\\n```\\n_flagged/logs.csv_\\n```csv\\nnum1,operation,num2,Output,timestamp\\n5,add,7,12,2022-01-31 11:40:51.093412\\n6,subtract,1.5,4.5,2022-01-31 03:25:32.023542\\n```\\n\\nIf the interface involves file data, such as for Image and Audio components, folders will be created to store those flagged data as well. For example an `image` input to `image` output interface will create the following structure.\\n\\n```directory\\n+-- flagged/\\n|   +-- logs.csv\\n|   +-- image/\\n|   |   +-- 0.png\\n|   |   +-- 1.png\\n|   +-- Output/\\n|   |   +-- 0.png\\n|   |   +-- 1.png\\n```\\n_flagged/logs.csv_\\n```csv\\nim,Output', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/using-flagging.md'}, lookup_index=0),\n",
              " Document(page_content='timestamp\\nim/0.png,Output/0.png,2022-02-04 19:49:58.026963\\nim/1.png,Output/1.png,2022-02-02 10:40:51.093412\\n```\\n\\nIf you wish for the user to provide a reason for flagging, you can pass a list of strings to the `flagging_options` argument of Interface. Users will have to select one of these choices when flagging, and the option will be saved as an additional column to the CSV.\\n\\nIf we go back to the calculator example, the following code will create the interface embedded below it.  \\n```python\\niface = gr.Interface(\\n    calculator,\\n    [\"number\", gr.Radio([\"add\", \"subtract\", \"multiply\", \"divide\"]), \"number\"],\\n    \"number\",\\n    allow_flagging=\"manual\",\\n    flagging_options=[\"wrong sign\", \"off by one\", \"other\"]\\n)\\n\\niface.launch()\\n```\\n<gradio-app space=\"gradio/calculator-flagging-options/\"></gradio-app>\\n\\nWhen users click the flag button, the csv file will now include a column indicating the selected option.\\n\\n_flagged/logs.csv_\\n```csv\\nnum1,operation,num2,Output,flag,timestamp\\n5,add,7,-12,wrong sign,2022-02-04 11:40:51.093412\\n6,subtract,1.5,3.5,off by one,2022-02-04 11:42:32.062512\\n```\\n\\n## The HuggingFaceDatasetSaver Callback\\n\\nSometimes,', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/using-flagging.md'}, lookup_index=0),\n",
              " Document(page_content='saving the data to a local CSV file doesn\\'t make sense. For example, on Hugging Face\\nSpaces, developers typically don\\'t have access to the underlying ephemeral machine hosting the Gradio\\ndemo. That\\'s why, by default, flagging is turned off in Hugging Face Space. However,\\nyou may want to do something else with the flagged data.\\n\\nWe\\'ve made this super easy with the `flagging_callback` parameter.\\n\\nFor example, below we\\'re going to pipe flagged data from our calculator example into a Hugging Face Dataset, e.g. so that we can build a \"crowd-sourced\" dataset:\\n\\n\\n```python\\nimport os\\n\\nHF_TOKEN = os.getenv(\\'HF_TOKEN\\')\\nhf_writer = gr.HuggingFaceDatasetSaver(HF_TOKEN, \"crowdsourced-calculator-demo\")\\n\\niface = gr.Interface(\\n    calculator,\\n    [\"number\", gr.Radio([\"add\", \"subtract\", \"multiply\", \"divide\"]), \"number\"],\\n    \"number\",\\n    description=\"Check out the crowd-sourced dataset at: [https://huggingface.co/datasets/aliabd/crowdsourced-calculator-demo](https://huggingface.co/datasets/aliabd/crowdsourced-calculator-demo)\",\\n    allow_flagging=\"manual\",\\n    flagging_options=[\"wrong sign\", \"off by one\", \"other\"],\\n   ', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/using-flagging.md'}, lookup_index=0),\n",
              " Document(page_content='   flagging_callback=hf_writer\\n)\\n\\niface.launch()\\n```\\n\\nNotice that we define our own \\ninstance of  `gradio.HuggingFaceDatasetSaver` using our Hugging Face token and\\nthe name of a dataset we\\'d like to save samples to. In addition, we also set `allow_flagging=\"manual\"`\\nbecause on Hugging Face Spaces, `allow_flagging` is set to `\"never\"` by default. Here\\'s our demo:\\n\\n<gradio-app space=\"gradio/calculator-flagging-crowdsourced/\"></gradio-app>\\n\\nYou can now see all the examples flagged above in this [public Hugging Face dataset](https://huggingface.co/datasets/aliabd/crowdsourced-calculator-demo).\\n\\n![flagging callback hf](/assets/guides/flagging-callback-hf.png)\\n\\nWe created the `gradio.HuggingFaceDatasetSaver` class, but you can pass your own custom class as long as it inherits from `FLaggingCallback` defined in [this file](https://github.com/gradio-app/gradio/blob/master/gradio/flagging.py). If you create a cool callback, contribute it to the repo! \\n\\n## Flagging with Blocks\\n\\nWhat about if you are using `gradio.Blocks`? On one hand, you have even more flexibility\\nwith Blocks -- you can write whatever Python code you want to run when a button is', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/using-flagging.md'}, lookup_index=0),\n",
              " Document(page_content=\"clicked,\\nand assign that using the built-in events in Blocks.\\n\\nAt the same time, you might want to use an existing `FlaggingCallback` to avoid writing extra code.\\nThis requires two steps:\\n\\n1. You have to run your callback's `.setup()` somewhere in the code prior to the \\nfirst time you flag data\\n2. When the flagging button is clicked, then you trigger the callback's `.flag()` method,\\nmaking sure to collect the arguments correctly and disabling the typical preprocessing. \\n\\nHere is an example with an image sepia filter Blocks demo that lets you flag\\ndata using the default `CSVLogger`:\\n\\n$code_blocks_flag\\n$demo_blocks_flag\\n\\n## Privacy\\n\\nImportant Note: please make sure your users understand when the data they submit is being saved, and what you plan on doing with it. This is especially important when you use `allow_flagging=auto` (when all of the data submitted through the demo is being flagged)\\n\\n### That's all! Happy building :) \\n\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/using-flagging.md'}, lookup_index=0),\n",
              " Document(page_content=\"# Setting Up a Demo for Maximum Performance\\n\\nTags: QUEUE, PERFORMANCE\\n\\n\\nLet's say that your Gradio demo goes *viral* on social media -- you have lots of users trying it out simultaneously, and you want to provide your users with the best possible experience or, in other words, minimize the amount of time that each user has to wait in the queue to see their prediction.\\n\\nHow can you configure your Gradio demo to handle the most traffic? In this Guide, we dive into some of the parameters of Gradio's `.queue()` method as well as some other related configurations, and discuss how to set these parameters in a way that allows you to serve lots of users simultaneously with minimal latency.\\n\\nThis is an advanced guide, so make sure you know the basics of Gradio already, such as [how to create and launch a Gradio Interface](https://gradio.app/quickstart/). Most of the information in this Guide is relevant whether you are hosting your demo on [Hugging Face Spaces](https://hf.space) or on your own server.\\n\\n## Enabling Gradio's Queueing System\\n\\nBy default, a Gradio demo does not use queueing and instead sends prediction requests via a POST request to the server where your Gradio server and Python code are running.\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/setting-up-a-demo-for-maximum-performance.md'}, lookup_index=0),\n",
              " Document(page_content='However, regular POST requests have two big limitations:\\n\\n(1) They time out -- most browsers raise a timeout error\\nif they do not get a response to a POST request after a short period of time (e.g. 1 min).\\nThis can be a problem if your inference function takes longer than 1 minute to run or\\nif many people are trying out your demo at the same time, resulting in increased latency.\\n\\n(2) They do not allow bi-directional communication between the Gradio demo and the Gradio server. This means, for example, that you cannot get a real-time ETA of how long your prediction will take to complete.\\n\\nTo address these limitations, any Gradio app can be converted to use **websockets** instead, simply by adding `.queue()` before launching an Interface or a Blocks. Here\\'s an example:\\n\\n```py\\napp = gr.Interface(lambda x:x, \"image\", \"image\")\\napp.queue()  # <-- Sets up a queue with default parameters\\napp.launch()\\n```\\n\\nIn the demo `app` above, predictions will now be sent over a websocket instead.\\nUnlike POST requests, websockets do not timeout and they allow bidirectional traffic. On the Gradio server, a **queue** is set up, which adds each request that comes to a list. When a worker is free, the first available request', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/setting-up-a-demo-for-maximum-performance.md'}, lookup_index=0),\n",
              " Document(page_content=\"is passed into the worker for inference. When the inference is complete, the queue sends the prediction back through the websocket to the particular Gradio user who called that prediction. \\n\\nNote: If you host your Gradio app on [Hugging Face Spaces](https://hf.space), the queue is already **enabled by default**. You can still call the `.queue()` method manually in order to configure the queue parameters described below.\\n\\n## Queuing Parameters\\n\\nThere are several parameters that can be used to configure the queue and help reduce latency. Let's go through them one-by-one.\\n\\n### The `concurrency_count` parameter\\n\\nThe first parameter we will explore is the `concurrency_count` parameter of `queue()`. This parameter is used to set the number of worker threads in the Gradio server that will be processing your requests in parallel. By default, this parameter is set to `1` but increasing this can **linearly multiply the capacity of your server to handle requests**.\\n\\nSo why not set this parameter much higher? Keep in mind that since requests are processed in parallel, each request will consume memory to store the data and weights for processing. This means that you might get out-of-memory errors if\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/setting-up-a-demo-for-maximum-performance.md'}, lookup_index=0),\n",
              " Document(page_content='you increase the `concurrency_count` too high. You may also start to get diminishing returns if the `concurrency_count` is too high because of costs of switching between different worker threads.\\n\\n**Recommendation**: Increase the `concurrency_count` parameter as high as you can while you continue to see performance gains or until you hit memory limits on your machine. You can [read about Hugging Face Spaces machine specs here](https://huggingface.co/docs/hub/spaces-overview). \\n\\n*Note*: there is a second parameter which controls the *total* number of threads that Gradio can generate, whether or not queuing is enabled. This is the `max_threads` parameter in the `launch()` method. When you increase the `concurrency_count` parameter in `queue()`, this is automatically increased as well. However, in some cases, you may want to manually increase this, e.g. if queuing is not enabled. \\n\\n### The `max_size` parameter\\n\\nA more blunt way to reduce the wait times is simply to prevent too many people from joining the queue in the first place. You can set the maximum number of requests that the queue processes using the `max_size` parameter of `queue()`. If a request arrives when the queue is already', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/setting-up-a-demo-for-maximum-performance.md'}, lookup_index=0),\n",
              " Document(page_content='of the maximum size, it will not be allowed to join the queue and instead, the user will receive an error saying that the queue is full and to try again. By default, `max_size=None`, meaning that there is no limit to the number of users that can join the queue.\\n\\nParadoxically, setting a `max_size` can often improve user experience because it prevents users from being dissuaded by very long queue wait times. Users who are more interested and invested in your demo will keep trying to join the queue, and will be able to get their results faster. \\n\\n**Recommendation**: For a better user experience, set a `max_size` that is reasonable given your expectations of how long users might be willing to wait for a prediction. \\n\\n### The `max_batch_size` parameter\\n\\nAnother way to increase the parallelism of your Gradio demo is to write your function so that it can accept **batches** of inputs. Most deep learning models can process batches of samples more efficiently than processing individual samples. \\n\\nIf you write your function to process a batch of samples, Gradio will automatically batch incoming requests together and pass them into your function as a batch of samples. You need to set `batch` to `True` (by default it is', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/setting-up-a-demo-for-maximum-performance.md'}, lookup_index=0),\n",
              " Document(page_content=\"`False`) and set a `max_batch_size` (by default it is `4`) based on the maximum number of samples your function is able to handle. These two parameters can be passed into `gr.Interface()` or to an event in Blocks such as `.click()`. \\n\\nWhile setting a batch is conceptually similar to having workers process requests in parallel, it is often *faster* than setting the `concurrency_count` for deep learning models. The downside is that you might need to adapt your function a little bit to accept batches of samples instead of individual samples. \\n\\nHere's an example of a function that does *not* accept a batch of inputs -- it processes a single input at a time:\\n\\n```py\\nimport time\\n\\ndef trim_words(word, length):\\n    return w[:int(length)]\\n\\n```\\n\\nHere's the same function rewritten to take in a batch of samples:\\n\\n```py\\nimport time\\n\\ndef trim_words(words, lengths):\\n    trimmed_words = []\\n    for w, l in zip(words, lengths):\\n        trimmed_words.append(w[:int(l)])        \\n    return [trimmed_words]\\n\\n```\\n\\nThe second function can be used with `batch=True` and an appropriate `max_batch_size` parameter.\\n\\n**Recommendation**: If possible, write your function to accept batches of samples, and then set `batch` to `True` and\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/setting-up-a-demo-for-maximum-performance.md'}, lookup_index=0),\n",
              " Document(page_content=\"the `max_batch_size` as high as possible based on your machine's memory limits. If you set `max_batch_size` as high as possible, you will most likely need to set `concurrency_count` back to `1` since you will no longer have the memory to have multiple workers running in parallel. \\n\\n### The `api_open` parameter\\n\\nWhen creating a Gradio demo, you may want to restrict all traffic to happen through the user interface as opposed to the [programmatic API](/sharing_your_app/#api-page) that is automatically created for your Gradio demo. This is important because when people make requests through the programmatic API, they can potentially bypass users who are waiting in the queue and degrade the experience of these users. \\n\\n**Recommendation**: set the `api_open` parameter in `queue()` to `False` in your demo to prevent programmatic requests.\\n\\n\\n\\n### Upgrading your Hardware (GPUs, TPUs, etc.)\\n\\nIf you have done everything above, and your demo is still not fast enough, you can upgrade the hardware that your model is running on. Changing the model from running on CPUs to running on GPUs will usually provide a 10x-50x increase in inference time for deep learning models.\\n\\nIt is particularly\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/setting-up-a-demo-for-maximum-performance.md'}, lookup_index=0),\n",
              " Document(page_content='straightforward to upgrade your Hardware on Hugging Face Spaces. Simply click on the \"Settings\" tab in your Space and choose the Space Hardware you\\'d like.\\n\\n![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/spaces-gpu-settings.png)\\n\\nWhile you might need to adapt portions of your machine learning inference code to run on a GPU (here\\'s a [handy guide](https://cnvrg.io/pytorch-cuda/) if you are using PyTorch), Gradio is completely agnostic to the choice of hardware and will work completely fine if you use it with CPUs, GPUs, TPUs, or any other hardware!\\n\\nNote: your GPU memory is different than your CPU memory, so if you upgrade your hardware,\\nyou might need to adjust the value of the `concurrency_count` parameter described above.\\n\\n## Conclusion\\n\\nCongratulations! You know how to set up a Gradio demo for maximum performance. Good luck on your next viral demo! \\n\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/setting-up-a-demo-for-maximum-performance.md'}, lookup_index=0),\n",
              " Document(page_content='# Create Your Own Friends with a GAN\\n\\nRelated spaces: https://huggingface.co/spaces/NimaBoscarino/cryptopunks, https://huggingface.co/spaces/nateraw/cryptopunks-generator\\nTags: GAN, IMAGE, HUB\\n\\nContributed by <a href=\"https://huggingface.co/NimaBoscarino\">Nima Boscarino</a> and <a href=\"https://huggingface.co/nateraw\">Nate Raw</a>\\n\\n\\n## Introduction\\n\\nIt seems that cryptocurrencies, [NFTs](https://www.nytimes.com/interactive/2022/03/18/technology/nft-guide.html), and the web3 movement are all the rage these days! Digital assets are being listed on marketplaces for astounding amounts of money, and just about every celebrity is debuting their own NFT collection. While your crypto assets [may be taxable, such as in Canada](https://www.canada.ca/en/revenue-agency/programs/about-canada-revenue-agency-cra/compliance/digital-currency/cryptocurrency-guide.html), today we\\'ll explore some fun and tax-free ways to generate your own assortment of procedurally generated [CryptoPunks](https://www.larvalabs.com/cryptopunks).\\n\\nGenerative Adversarial Networks, often known just as *GANs*, are a specific class of deep-learning', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/create-your-own-friends-with-a-gan.md'}, lookup_index=0),\n",
              " Document(page_content='models that are designed to learn from an input dataset to create (*generate!*) new material that is convincingly similar to elements of the original training set. Famously, the website [thispersondoesnotexist.com](https://thispersondoesnotexist.com/) went viral with lifelike, yet synthetic, images of people generated with a model called StyleGAN2. GANs have gained traction in the machine learning world, and are now being used to generate all sorts of images, text, and even [music](https://salu133445.github.io/musegan/)!\\n\\nToday we\\'ll briefly look at the high-level intuition behind GANs, and then we\\'ll build a small demo around a pre-trained GAN to see what all the fuss is about. Here\\'s a peek at what we\\'re going to be putting together:\\n\\n<iframe src=\"https://nimaboscarino-cryptopunks.hf.space\" frameBorder=\"0\" height=\"855\" title=\"Gradio app\" class=\"container p-0 flex-grow space-iframe\" allow=\"accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture;', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/create-your-own-friends-with-a-gan.md'}, lookup_index=0),\n",
              " Document(page_content='publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking\" sandbox=\"allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads\"></iframe>\\n\\n### Prerequisites\\n\\nMake sure you have the `gradio` Python package already [installed](/getting_started). To use the pretrained model, also install `torch` and `torchvision`.\\n\\n## GANs: a very brief introduction\\n\\nOriginally proposed in [Goodfellow et al. 2014](https://arxiv.org/abs/1406.2661), GANs are made up of neural networks which compete with the intention of outsmarting each other. One network, known as the *generator*, is responsible for generating images. The other network, the *discriminator*, receives an image at a time from the generator along with a **real** image from the training data set. The discriminator then has to guess: which image is the fake?\\n\\nThe generator is constantly training to create images which are trickier for the discriminator to identify, while the discriminator raises the bar for the generator every time it correctly detects a fake. As the networks engage in this competitive (*adversarial!*) relationship,', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/create-your-own-friends-with-a-gan.md'}, lookup_index=0),\n",
              " Document(page_content=\"the images that get generated improve to the point where they become indistinguishable to human eyes!\\n\\nFor a more in-depth look at GANs, you can take a look at [this excellent post on Analytics Vidhya](https://www.analyticsvidhya.com/blog/2021/06/a-detailed-explanation-of-gan-with-implementation-using-tensorflow-and-keras/) or this [PyTorch tutorial](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html). For now, though, we'll dive into a demo!\\n\\n## Step 1 — Create the Generator model\\n\\nTo generate new images with a GAN, you only need the generator model. There are many different architectures that the generator could use, but for this demo we'll use a pretrained GAN generator model with the following architecture:\\n\\n```python\\nfrom torch import nn\\n\\nclass Generator(nn.Module):\\n    # Refer to the link below for explanations about nc, nz, and ngf\\n    # https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html#inputs\\n    def __init__(self, nc=4, nz=100, ngf=64):\\n        super(Generator, self).__init__()\\n        self.network = nn.Sequential(\\n            nn.ConvTranspose2d(nz, ngf * 4, 3, 1, 0, bias=False),\\n            nn.BatchNorm2d(ngf * 4),\\n            nn.ReLU(True),\\n           \", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/create-your-own-friends-with-a-gan.md'}, lookup_index=0),\n",
              " Document(page_content=\"           nn.ConvTranspose2d(ngf * 4, ngf * 2, 3, 2, 1, bias=False),\\n            nn.BatchNorm2d(ngf * 2),\\n            nn.ReLU(True),\\n            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 0, bias=False),\\n            nn.BatchNorm2d(ngf),\\n            nn.ReLU(True),\\n            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\\n            nn.Tanh(),\\n        )\\n\\n    def forward(self, input):\\n        output = self.network(input)\\n        return output\\n```\\n\\nWe're taking the generator from [this repo by @teddykoker](https://github.com/teddykoker/cryptopunks-gan/blob/main/train.py#L90), where you can also see the original discriminator model structure.\\n\\nAfter instantiating the model, we'll load in the weights from the Hugging Face Hub, stored at [nateraw/cryptopunks-gan](https://huggingface.co/nateraw/cryptopunks-gan):\\n\\n```python\\nfrom huggingface_hub import hf_hub_download\\nimport torch\\n\\nmodel = Generator()\\nweights_path = hf_hub_download('nateraw/cryptopunks-gan', 'generator.pth')\\nmodel.load_state_dict(torch.load(weights_path, map_location=torch.device('cpu'))) # Use 'cuda' if you have a GPU available\\n```\\n\\n## Step 2 — Defining a `predict` function\\n\\nThe `predict` function is the key to making Gradio work! Whatever inputs we choose through the\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/create-your-own-friends-with-a-gan.md'}, lookup_index=0),\n",
              " Document(page_content='Gradio interface will get passed through our `predict` function, which should operate on the inputs and generate outputs that we can display with Gradio output components. For GANs it\\'s common to pass random noise into our model as the input, so we\\'ll generate a tensor of random numbers and pass that through the model. We can then use `torchvision`\\'s `save_image` function to save the output of the model as a `png` file, and return the file name:\\n\\n```python\\nfrom torchvision.utils import save_image\\n\\ndef predict(seed):\\n    num_punks = 4\\n    torch.manual_seed(seed)\\n    z = torch.randn(num_punks, 100, 1, 1)\\n    punks = model(z)\\n    save_image(punks, \"punks.png\", normalize=True)\\n    return \\'punks.png\\'\\n```\\n\\nWe\\'re giving our `predict` function a `seed` parameter, so that we can fix the random tensor generation with a seed. We\\'ll then be able to reproduce punks if we want to see them again by passing in the same seed.\\n\\n*Note!* Our model needs an input tensor of dimensions 100x1x1 to do a single inference, or (BatchSize)x100x1x1 for generating a batch of images. In this demo we\\'ll start by generating 4 punks at a time.\\n\\n## Step 3 — Creating a Gradio interface\\n\\nAt this point you can even run the code you have with', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/create-your-own-friends-with-a-gan.md'}, lookup_index=0),\n",
              " Document(page_content='`predict(<SOME_NUMBER>)`, and you\\'ll find your freshly generated punks in your file system at `./punks.png`. To make a truly interactive demo, though, we\\'ll build out a simple interface with Gradio. Our goals here are to:\\n\\n* Set a slider input so users can choose the \"seed\" value\\n* Use an image component for our output to showcase the generated punks\\n* Use our `predict()` to take the seed and generate the images\\n\\nWith `gr.Interface()`, we can define all of that with a single function call:\\n\\n```python\\nimport gradio as gr\\n\\ngr.Interface(\\n    predict,\\n    inputs=[\\n        gr.Slider(0, 1000, label=\\'Seed\\', default=42),\\n    ],\\n    outputs=\"image\",\\n).launch()\\n```\\n\\nLaunching the interface should present you with something like this:\\n\\n<iframe src=\"https://nimaboscarino-cryptopunks-1.hf.space\" frameBorder=\"0\" height=\"365\" title=\"Gradio app\" class=\"container p-0 flex-grow space-iframe\" allow=\"accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture;', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/create-your-own-friends-with-a-gan.md'}, lookup_index=0),\n",
              " Document(page_content='publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking\" sandbox=\"allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads\"></iframe>\\n\\n## Step 4 — Even more punks!\\n\\nGenerating 4 punks at a time is a good start, but maybe we\\'d like to control how many we want to make each time. Adding more inputs to our Gradio interface is as simple as adding another item to the `inputs` list that we pass to `gr.Interface`:\\n\\n```python\\ngr.Interface(\\n    predict,\\n    inputs=[\\n        gr.Slider(0, 1000, label=\\'Seed\\', default=42),\\n        gr.Slider(4, 64, label=\\'Number of Punks\\', step=1, default=10), # Adding another slider!\\n    ],\\n    outputs=\"image\",\\n).launch()\\n```\\n\\nThe new input will be passed to our `predict()` function, so we have to make some changes to that function to accept a new parameter:\\n\\n```python\\ndef predict(seed, num_punks):\\n    torch.manual_seed(seed)\\n    z = torch.randn(num_punks, 100, 1, 1)\\n    punks = model(z)\\n    save_image(punks, \"punks.png\", normalize=True)\\n    return \\'punks.png\\'\\n```\\n\\nWhen you relaunch your interface, you should see a second slider that\\'ll let you control the number of punks!\\n\\n## Step 5 -', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/create-your-own-friends-with-a-gan.md'}, lookup_index=0),\n",
              " Document(page_content='Polishing it up\\n\\nYour Gradio app is pretty much good to go, but you can add a few extra things to really make it ready for the spotlight ✨\\n\\nWe can add some examples that users can easily try out by adding this to the `gr.Interface`:\\n\\n```python\\ngr.Interface(\\n    # ...\\n    # keep everything as it is, and then add\\n    examples=[[123, 15], [42, 29], [456, 8], [1337, 35]],\\n).launch(cache_examples=True) # cache_examples is optional\\n```\\n\\nThe `examples` parameter takes a list of lists, where each item in the sublists is ordered in the same order that we\\'ve listed the `inputs`. So in our case, `[seed, num_punks]`. Give it a try!\\n\\nYou can also try adding a `title`, `description`, and `article` to the `gr.Interface`. Each of those parameters accepts a string, so try it out and see what happens 👀 `article` will also accept HTML, as [explored in a previous guide](./key_features/#descriptive-content)!\\n\\nWhen you\\'re all done, you may end up with something like this:\\n\\n<iframe src=\"https://nimaboscarino-cryptopunks.hf.space\" frameBorder=\"0\" height=\"855\" title=\"Gradio app\" class=\"container p-0 flex-grow space-iframe\" allow=\"accelerometer; ambient-light-sensor; autoplay; battery; camera;', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/create-your-own-friends-with-a-gan.md'}, lookup_index=0),\n",
              " Document(page_content='document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking\" sandbox=\"allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads\"></iframe>\\n\\nFor reference, here is our full code:\\n\\n```python\\nimport torch\\nfrom torch import nn\\nfrom huggingface_hub import hf_hub_download\\nfrom torchvision.utils import save_image\\nimport gradio as gr\\n\\nclass Generator(nn.Module):\\n    # Refer to the link below for explanations about nc, nz, and ngf\\n    # https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html#inputs\\n    def __init__(self, nc=4, nz=100, ngf=64):\\n        super(Generator, self).__init__()\\n        self.network = nn.Sequential(\\n            nn.ConvTranspose2d(nz, ngf * 4, 3, 1, 0, bias=False),\\n            nn.BatchNorm2d(ngf * 4),\\n            nn.ReLU(True),\\n            nn.ConvTranspose2d(ngf * 4, ngf * 2, 3, 2, 1, bias=False),\\n            nn.BatchNorm2d(ngf * 2),\\n            nn.ReLU(True),\\n            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 0,', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/create-your-own-friends-with-a-gan.md'}, lookup_index=0),\n",
              " Document(page_content='bias=False),\\n            nn.BatchNorm2d(ngf),\\n            nn.ReLU(True),\\n            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\\n            nn.Tanh(),\\n        )\\n\\n    def forward(self, input):\\n        output = self.network(input)\\n        return output\\n\\nmodel = Generator()\\nweights_path = hf_hub_download(\\'nateraw/cryptopunks-gan\\', \\'generator.pth\\')\\nmodel.load_state_dict(torch.load(weights_path, map_location=torch.device(\\'cpu\\'))) # Use \\'cuda\\' if you have a GPU available\\n\\ndef predict(seed, num_punks):\\n    torch.manual_seed(seed)\\n    z = torch.randn(num_punks, 100, 1, 1)\\n    punks = model(z)\\n    save_image(punks, \"punks.png\", normalize=True)\\n    return \\'punks.png\\'\\n\\ngr.Interface(\\n    predict,\\n    inputs=[\\n        gr.Slider(0, 1000, label=\\'Seed\\', default=42),\\n        gr.Slider(4, 64, label=\\'Number of Punks\\', step=1, default=10),\\n    ],\\n    outputs=\"image\",\\n    examples=[[123, 15], [42, 29], [456, 8], [1337, 35]],\\n).launch(cache_examples=True)\\n```\\n----------\\n\\nCongratulations! You\\'ve built out your very own GAN-powered CryptoPunks generator, with a fancy Gradio interface that makes it easy for anyone to use. Now you can [scour the Hub for more GANs](https://huggingface.co/models?other=gan) (or train your own) and continue making', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/create-your-own-friends-with-a-gan.md'}, lookup_index=0),\n",
              " Document(page_content='even more awesome demos 🤗', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/create-your-own-friends-with-a-gan.md'}, lookup_index=0),\n",
              " Document(page_content=\"# How to Create a New Component\\n\\n## Introduction\\n\\nThe purpose of this guide is to illustrate how to add a new component, which you can use in your Gradio applications. The guide will be complemented by code snippets showing step by step how the [ColorPicker](https://gradio.app/docs/#colorpicker) component was added.\\n\\n## Prerequisites\\n\\nMake sure you have followed the [CONTRIBUTING.md](https://github.com/gradio-app/gradio/blob/main/CONTRIBUTING.md) guide in order to setup your local development environment (both client and server side).\\n\\nHere's how to create a new component on Gradio: \\n\\n1. [Create a New Python Class and Import it](#1-create-a-new-python-class-and-import-it)\\n2. [Create a New Svelte Component](#2-create-a-new-svelte-component)\\n3. [Create a New Demo](#3-create-a-new-demo)\\n\\n## 1. Create a New Python Class and Import it\\n\\nThe first thing to do is to create a new class within the [components.py](https://github.com/gradio-app/gradio/blob/main/gradio/components.py) file. This Python class should inherit from a list of base components and should be placed within the file in the correct section with respect to the type of component you want to add\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/creating-a-new-component.md'}, lookup_index=0),\n",
              " Document(page_content='(e.g. input, output or static components).\\nIn general, it is advisable to take an existing component as a reference (e.g. [TextBox](https://github.com/gradio-app/gradio/blob/main/gradio/components.py#L290)), copy its code as a skeleton and then adapt it to the case at hand.\\n\\nLet\\'s take a look at the class added to the [components.py](https://github.com/gradio-app/gradio/blob/main/gradio/components.py) file for the ColorPicker component:\\n\\n```python\\n@document()\\nclass ColorPicker(Changeable, Submittable, IOComponent):\\n    \"\"\"\\n    Creates a color picker for user to select a color as string input.\\n    Preprocessing: passes selected color value as a {str} into the function.\\n    Postprocessing: expects a {str} returned from function and sets color picker value to it.\\n    Examples-format: a {str} with a hexadecimal representation of a color, e.g. \"#ff0000\" for red.\\n    Demos: color_picker, color_generator\\n    \"\"\"\\n\\n    def __init__(\\n        self,\\n        value: str = None,\\n        *,\\n        label: Optional[str] = None,\\n        show_label: bool = True,\\n        interactive: Optional[bool] = None,\\n        visible: bool = True,\\n        elem_id: Optional[str] = None,\\n        **kwargs,\\n    ):\\n        \"\"\"\\n        Parameters:\\n            value: default text to provide in color', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/creating-a-new-component.md'}, lookup_index=0),\n",
              " Document(page_content='picker.\\n            label: component name in interface.\\n            show_label: if True, will display label.\\n            interactive: if True, will be rendered as an editable color picker; if False, editing will be disabled. If not provided, this is inferred based on whether the component is used as an input or output.\\n            visible: If False, component will be hidden.\\n            elem_id: An optional string that is assigned as the id of this component in the HTML DOM. Can be used for targeting CSS styles.\\n        \"\"\"\\n        self.value = self.postprocess(value)\\n        self.cleared_value = \"#000000\"\\n        self.test_input = value\\n        IOComponent.__init__(\\n            self,\\n            label=label,\\n            show_label=show_label,\\n            interactive=interactive,\\n            visible=visible,\\n            elem_id=elem_id,\\n            **kwargs,\\n        )\\n\\n    def get_config(self):\\n        return {\\n            \"value\": self.value,\\n            **IOComponent.get_config(self),\\n        }\\n\\n    @staticmethod\\n    def update(\\n        value: Optional[Any] = None,\\n        label: Optional[str] = None,\\n        show_label: Optional[bool] = None,\\n        visible: Optional[bool] = None,\\n        interactive: Optional[bool] = None,\\n    ):\\n        updated_config = {\\n            \"value\": value,\\n            \"label\": label,\\n            \"show_label\": show_label,\\n            \"visible\": visible,\\n            \"__type__\": \"update\",\\n        }\\n        return', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/creating-a-new-component.md'}, lookup_index=0),\n",
              " Document(page_content='IOComponent.add_interactive_to_config(updated_config, interactive)\\n\\n    # Input Functionalities\\n    def preprocess(self, x: str | None) -> Any:\\n        \"\"\"\\n        Any preprocessing needed to be performed on function input.\\n        Parameters:\\n        x (str): text\\n        Returns:\\n        (str): text\\n        \"\"\"\\n        if x is None:\\n            return None\\n        else:\\n            return str(x)\\n\\n    def preprocess_example(self, x: str | None) -> Any:\\n        \"\"\"\\n        Any preprocessing needed to be performed on an example before being passed to the main function.\\n        \"\"\"\\n        if x is None:\\n            return None\\n        else:\\n            return str(x)\\n\\n    def generate_sample(self) -> str:\\n        return \"#000000\"\\n\\n    # Output Functionalities\\n    def postprocess(self, y: str | None):\\n        \"\"\"\\n        Any postprocessing needed to be performed on function output.\\n        Parameters:\\n        y (str | None): text\\n        Returns:\\n        (str | None): text\\n        \"\"\"\\n        if y is None:\\n            return None\\n        else:\\n            return str(y)\\n\\n    def deserialize(self, x):\\n        \"\"\"\\n        Convert from serialized output (e.g. base64 representation) from a call() to the interface to a human-readable version of the output (path of an image, etc.)\\n        \"\"\"\\n        return x\\n```\\n\\n\\nOnce defined, it is necessary to import the new class inside the', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/creating-a-new-component.md'}, lookup_index=0),\n",
              " Document(page_content='[\\\\_\\\\_init\\\\_\\\\_](https://github.com/gradio-app/gradio/blob/main/gradio/__init__.py) module class in order to make it module visible.\\n\\n```python\\n\\nfrom gradio.components import (\\n    ...\\n    ColorPicker,\\n    ...\\n)\\n\\n```\\n\\n### 1.1 Writing Unit Test for Python Class\\n\\nWhen developing new components, you should also write a suite of unit tests for it. The tests should be placed in the [gradio/test/test_components.py](https://github.com/gradio-app/gradio/blob/main/test/test_components.py) file. Again, as above, take a cue from the tests of other components (e.g. [Textbox](https://github.com/gradio-app/gradio/blob/main/test/test_components.py)) and add as many unit tests as you think are appropriate to test all the different aspects and functionalities of the new component. For example, the following tests were added for the ColorPicker component:\\n\\n```python\\nclass TestColorPicker(unittest.TestCase):\\n    def test_component_functions(self):\\n        \"\"\"\\n        Preprocess, postprocess, serialize, save_flagged, restore_flagged, tokenize, generate_sample, get_config\\n        \"\"\"\\n        color_picker_input = gr.ColorPicker()\\n       ', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/creating-a-new-component.md'}, lookup_index=0),\n",
              " Document(page_content='       self.assertEqual(color_picker_input.preprocess(\"#000000\"), \"#000000\")\\n        self.assertEqual(color_picker_input.preprocess_example(\"#000000\"), \"#000000\")\\n        self.assertEqual(color_picker_input.postprocess(None), None)\\n        self.assertEqual(color_picker_input.postprocess(\"#FFFFFF\"), \"#FFFFFF\")\\n        self.assertEqual(color_picker_input.serialize(\"#000000\", True), \"#000000\")\\n\\n        color_picker_input.interpretation_replacement = \"unknown\"\\n\\n        self.assertEqual(\\n            color_picker_input.get_config(),\\n            {\\n                \"value\": None,\\n                \"show_label\": True,\\n                \"label\": None,\\n                \"style\": {},\\n                \"elem_id\": None,\\n                \"visible\": True,\\n                \"interactive\": None,\\n                \"name\": \"colorpicker\",\\n            },\\n        )\\n        self.assertIsInstance(color_picker_input.generate_sample(), str)\\n\\n    def test_in_interface_as_input(self):\\n        \"\"\"\\n        Interface, process, interpret,\\n        \"\"\"\\n        iface = gr.Interface(lambda x: x, \"colorpicker\", \"colorpicker\")\\n        self.assertEqual(iface.process([\"#000000\"]), [\"#000000\"])\\n\\n    def test_in_interface_as_output(self):\\n        \"\"\"\\n        Interface, process\\n\\n        \"\"\"\\n        iface = gr.Interface(lambda x: x, \"colorpicker\", gr.ColorPicker())\\n        self.assertEqual(iface.process([\"#000000\"]),', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/creating-a-new-component.md'}, lookup_index=0),\n",
              " Document(page_content='[\"#000000\"])\\n\\n    def test_static(self):\\n        \"\"\"\\n        postprocess\\n        \"\"\"\\n        component = gr.ColorPicker(\"#000000\")\\n        self.assertEqual(component.get_config().get(\"value\"), \"#000000\")\\n```\\n\\n## 2. Create a New Svelte Component\\n\\nLet\\'s see the steps you need to follow to create the frontend of your new component and to map it to its python code:\\n- Create a new UI-side Svelte component and figure out where to place it. The options are: create a package for the new component in the [ui/packages folder](https://github.com/gradio-app/gradio/tree/main/ui/packages), if this is completely different from existing components or add the new component to an existing package, such as to the [form package](https://github.com/gradio-app/gradio/tree/main/ui/packages/form). The ColorPicker component for example, was included in the form package because it is similar to components that already exist.\\n- Create a file with an appropriate name in the src folder of the package where you placed the Svelte component, note: the name must start with a capital letter. This is the \\'core\\' component and it\\'s the generic component that has no knowledge of Gradio specific functionality. Initially add any text/html to', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/creating-a-new-component.md'}, lookup_index=0),\n",
              " Document(page_content='this file so that the component renders something. The Svelte application code for the ColorPicker looks like this:\\n\\n```typescript\\n<script lang=\"ts\">\\n\\timport { createEventDispatcher } from \"svelte\";\\n\\timport { get_styles } from \"@gradio/utils\";\\n\\timport { BlockTitle } from \"@gradio/atoms\";\\n\\timport type { Styles } from \"@gradio/utils\";\\n\\n\\texport let value: string = \"#000000\";\\n\\texport let style: Styles = {};\\n\\texport let label: string;\\n\\texport let disabled = false;\\n\\texport let show_label: boolean = true;\\n\\n\\t$: value;\\n\\t$: handle_change(value);\\n\\n\\tconst dispatch = createEventDispatcher<{\\n\\t\\tchange: string;\\n\\t\\tsubmit: undefined;\\n\\t}>();\\n\\n\\tfunction handle_change(val: string) {\\n\\t\\tdispatch(\"change\", val);\\n\\t}\\n\\n\\t$: ({ styles } = get_styles(style, [\"rounded\", \"border\"]));\\n</script>\\n\\n<!-- svelte-ignore a11y-label-has-associated-control -->\\n<label class=\"block\">\\n\\t<BlockTitle {show_label}>{label}</BlockTitle>\\n\\t<input\\n\\t\\ttype=\"color\"\\n\\t\\tclass=\"gr-box-unrounded {classes}\"\\n\\t\\tbind:value\\n\\t\\t{disabled}\\n\\t/>\\n</label>\\n```\\n\\n- Export this file inside the index.ts file of the package where you placed the Svelte component by doing `export { default as', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/creating-a-new-component.md'}, lookup_index=0),\n",
              " Document(page_content='FileName } from \"./FileName.svelte\"`. The ColorPicker file is exported in the [index.ts](https://github.com/gradio-app/gradio/blob/main/ui/packages/form/src/index.ts) file and the export is performed by doing: `export { default as ColorPicker } from \"./ColorPicker.svelte\";`.\\n- Create the Gradio specific component in [ui/packages/app/src/components](https://github.com/gradio-app/gradio/tree/main/ui/packages/app/src/components). This is a Gradio wrapper that handles the specific logic of the library, passes the necessary data down to the core component and attaches any necessary event listeners. Copy the folder of another component, rename it and edit the code inside it, keeping the structure. \\n\\nHere you will have three files, the first file is for the Svelte application, and it will look like this:\\n\\n```typescript\\n<svelte:options accessors={true} />\\n\\n<script lang=\"ts\">\\n\\timport { ColorPicker } from \"@gradio/form\";\\n\\timport { Block } from \"@gradio/atoms\";\\n\\timport StatusTracker from \"../StatusTracker/StatusTracker.svelte\";\\n\\timport type { LoadingStatus } from \"../StatusTracker/types\";\\n\\timport type { Styles } from \"@gradio/utils\";\\n\\n\\texport', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/creating-a-new-component.md'}, lookup_index=0),\n",
              " Document(page_content='let label: string = \"ColorPicker\";\\n\\texport let elem_id: string = \"\";\\n\\texport let visible: boolean = true;\\n\\texport let value: string;\\n\\texport let form_position: \"first\" | \"last\" | \"mid\" | \"single\" = \"single\";\\n\\texport let show_label: boolean;\\n\\n\\texport let style: Styles = {};\\n\\n\\texport let loading_status: LoadingStatus;\\n\\n\\texport let mode: \"static\" | \"dynamic\";\\n</script>\\n\\n<Block\\n\\t{visible}\\n\\t{form_position}\\n\\t{elem_id}\\n\\tdisable={typeof style.container === \"boolean\" && !style.container}\\n>\\n\\t<StatusTracker {...loading_status} />\\n\\n\\t<ColorPicker\\n\\t\\t{style}\\n\\t\\tbind:value\\n\\t\\t{label}\\n\\t\\t{show_label}\\n\\t\\ton:change\\n\\t\\ton:submit\\n\\t\\tdisabled={mode === \"static\"}\\n\\t/>\\n</Block>\\n```\\n\\nThe second one contains the tests for the frontend, for example for the ColorPicker component:\\n\\n```typescript\\nimport { test, describe, assert, afterEach } from \"vitest\";\\nimport { cleanup, render } from \"@gradio/tootils\";\\n\\nimport ColorPicker from \"./ColorPicker.svelte\";\\nimport type { LoadingStatus } from \"../StatusTracker/types\";\\n\\nconst loading_status = {\\n\\teta: 0,\\n\\tqueue_position: 1,\\n\\tstatus: \"complete\" as LoadingStatus[\"status\"],\\n\\tscroll_to_output:', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/creating-a-new-component.md'}, lookup_index=0),\n",
              " Document(page_content='false,\\n\\tvisible: true,\\n\\tfn_index: 0\\n};\\n\\ndescribe(\"ColorPicker\", () => {\\n\\tafterEach(() => cleanup());\\n\\n\\ttest(\"renders provided value\", () => {\\n\\t\\tconst { getByDisplayValue } = render(ColorPicker, {\\n\\t\\t\\tloading_status,\\n\\t\\t\\tshow_label: true,\\n\\t\\t\\tmode: \"dynamic\",\\n\\t\\t\\tvalue: \"#000000\",\\n\\t\\t\\tlabel: \"ColorPicker\"\\n\\t\\t});\\n\\n\\t\\tconst item: HTMLInputElement = getByDisplayValue(\"#000000\");\\n\\t\\tassert.equal(item.value, \"#000000\");\\n\\t});\\n\\n\\ttest(\"changing the color should update the value\", async () => {\\n\\t\\tconst { component, getByDisplayValue } = render(ColorPicker, {\\n\\t\\t\\tloading_status,\\n\\t\\t\\tshow_label: true,\\n\\t\\t\\tmode: \"dynamic\",\\n\\t\\t\\tvalue: \"#000000\",\\n\\t\\t\\tlabel: \"ColorPicker\"\\n\\t\\t});\\n\\n\\t\\tconst item: HTMLInputElement = getByDisplayValue(\"#000000\");\\n\\n\\t\\tassert.equal(item.value, \"#000000\");\\n\\n\\t\\tawait component.$set({\\n\\t\\t\\tvalue: \"#FFFFFF\"\\n\\t\\t});\\n\\n\\t\\tassert.equal(component.value, \"#FFFFFF\");\\n\\t});\\n});\\n```\\n\\nThe third one is the index.ts file:\\n\\n```typescript\\nexport { default as Component } from \"./ColorPicker.svelte\";\\nexport const modes = [\"static\", \"dynamic\"];\\n```\\n\\n- Add the mapping for your component in the [directory.ts', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/creating-a-new-component.md'}, lookup_index=0),\n",
              " Document(page_content='file](https://github.com/gradio-app/gradio/blob/main/ui/packages/app/src/components/directory.ts). To do this, copy and paste the mapping line of any component and edit its text. The key name must be the lowercase version of the actual component name in the Python library. So for example, for the ColorPicker component the mapping looks like this: \\n\\n```typescript\\nexport const component_map = {\\n...\\ncolorpicker: () => import(\"./ColorPicker\"),\\n...\\n}\\n```\\n\\n### 2.1 Writing Unit Test for Svelte Component\\n\\nWhen developing new components, you should also write a suite of unit tests for it. The tests should be placed in the new component\\'s folder in a file named MyAwesomeComponent.test.ts. Again, as above, take a cue from the tests of other components (e.g. [Textbox.test.ts](https://github.com/gradio-app/gradio/blob/main/ui/packages/app/src/components/Textbox/Textbox.test.ts)) and add as many unit tests as you think are appropriate to test all the different aspects and functionalities of the new component.\\n\\n### 3. Create a New Demo\\n\\nThe last step is to create a demo in the [gradio/demo folder](https://github.com/gradio-app/gradio/tree/main/demo), which will use', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/creating-a-new-component.md'}, lookup_index=0),\n",
              " Document(page_content='the newly added component. Again, the suggestion is to reference an existing demo. Write the code for the demo in a file called run.py, add the necessary requirements and an image showing the application interface. Finally add a gif showing its usage. \\nYou can take a look at the [demo](https://github.com/gradio-app/gradio/tree/main/demo/color_picker) created for the ColorPicker, where an icon and a color selected through the new component is taken as input, and the same icon colored with the selected color is returned as output.\\n\\nTo test the application:\\n\\n- run on a terminal `python path/demo/run.py` which starts the backend at the address [http://localhost:7860](http://localhost:7860);\\n- in another terminal, from the ui folder, run `pnpm dev` to start the frontend at [http://localhost:9876](http://localhost:9876) with hot reload functionalities.\\n\\n## Conclusion\\n\\nIn this guide, we have shown how simple it is to add a new component to Gradio, seeing step by step how the ColorPicker component was added. For further details, you can refer to PR: [#1695](https://github.com/gradio-app/gradio/pull/1695).\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/creating-a-new-component.md'}, lookup_index=0),\n",
              " Document(page_content='# Named-Entity Recognition \\n\\nRelated spaces: https://huggingface.co/spaces/rajistics/biobert_ner_demo, https://huggingface.co/spaces/abidlabs/ner, https://huggingface.co/spaces/rajistics/Financial_Analyst_AI\\nTags: NER, TEXT, HIGHLIGHT\\n\\n## Introduction\\n\\nNamed-entity recognition (NER), also known as token classification or text tagging, is the task of taking a sentence and classifying every word (or \"token\") into different categories, such as names of people or names of locations, or different parts of speech. \\n\\nFor example, given the sentence:\\n\\n> Does Chicago have any Pakistani restaurants?\\n\\nA named-entity recognition algorithm may  identify:\\n\\n* \"Chicago\" as a **location**\\n* \"Pakistani\" as an **ethnicity**  \\n\\n\\nand so on. \\n\\nUsing `gradio` (specifically the `HighlightedText` component), you can easily build a web demo of your NER model and share that with the rest of your team.\\n\\nHere is an example of a demo that you\\'ll be able to build:\\n\\n$demo_ner_pipeline\\n\\nThis tutorial will show how to take a pretrained NER model and deploy it with a Gradio interface. We will show two different ways to use the `HighlightedText` component -- depending on your NER model, either', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/named-entity-recognition.md'}, lookup_index=0),\n",
              " Document(page_content='of these two ways may be easier to learn! \\n\\n### Prerequisites\\n\\nMake sure you have the `gradio` Python package already [installed](/getting_started). You will also need a pretrained named-entity recognition model. You can use your own, while in this tutorial, we will use one from the `transformers` library.\\n\\n### Approach 1: List of Entity Dictionaries\\n\\nMany named-entity recognition models output a list of dictionaries. Each dictionary consists of an *entity*, a \"start\" index, and an \"end\" index. This is, for example, how NER models in the `transformers` library operate:\\n\\n```py\\nfrom transformers import pipeline \\nner_pipeline = pipeline(\"ner\")\\nner_pipeline(\"Does Chicago have any Pakistani restaurants\")\\n```\\n\\nOutput:\\n\\n```bash\\n[{\\'entity\\': \\'I-LOC\\',\\n  \\'score\\': 0.9988978,\\n  \\'index\\': 2,\\n  \\'word\\': \\'Chicago\\',\\n  \\'start\\': 5,\\n  \\'end\\': 12},\\n {\\'entity\\': \\'I-MISC\\',\\n  \\'score\\': 0.9958592,\\n  \\'index\\': 5,\\n  \\'word\\': \\'Pakistani\\',\\n  \\'start\\': 22,\\n  \\'end\\': 31}]\\n```\\n\\nIf you have such a model, it is very easy to hook it up to Gradio\\'s `HighlightedText` component. All you need to do is pass in this **list of entities**, along with the **original text** to the model, together as dictionary, with the keys', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/named-entity-recognition.md'}, lookup_index=0),\n",
              " Document(page_content='being `\"entities\"` and `\"text\"` respectively.\\n\\nHere is a complete example:\\n\\n$code_ner_pipeline\\n$demo_ner_pipeline\\n\\n### Approach 2: List of Tuples\\n\\nAn alternative way to pass data into the `HighlightedText` component is a list of tuples. The first element of each tuple should be the word or words that are being classified into a particular entity. The second element should be the entity label (or `None` if they should be unlabeled). The `HighlightedText` component automatically strings together the words and labels to display the entities.\\n\\nIn some cases, this can be easier than the first approach. Here is a demo showing this approach using Spacy\\'s parts-of-speech tagger:\\n\\n$code_text_analysis\\n$demo_text_analysis\\n\\n\\n--------------------------------------------\\n\\n\\nAnd you\\'re done! That\\'s all you need to know to build a web-based GUI for your NER model. \\n\\nFun tip: you can share your NER demo instantly with others simply by setting `share=True` in `launch()`. \\n\\n\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/named-entity-recognition.md'}, lookup_index=0),\n",
              " Document(page_content='# Custom Machine Learning Interpretations with Blocks\\nTags: INTERPRETATION, SENTIMENT ANALYSIS\\n\\n**Prerequisite**: This Guide requires you to know about Blocks and the interpretation feature of Interfaces.\\nMake sure to [read the Guide to Blocks first](https://gradio.app/quickstart/#blocks-more-flexibility-and-control) as well as the\\ninterpretation section of the [Advanced Interface Features Guide](/advanced-interface-features#interpreting-your-predictions).\\n\\n## Introduction\\n\\nIf you have experience working with the Interface class, then you know that interpreting the prediction of your machine learning model\\nis as easy as setting the `interpretation` parameter to either \"default\" or \"shap\".\\n\\nYou may be wondering if it is possible to add the same interpretation functionality to an app built with the Blocks API.\\nNot only is it possible, but the flexibility of Blocks lets you display the interpretation output in ways that are\\nimpossible to do with Interfaces!\\n\\nThis guide will show how to:\\n\\n1. Recreate the behavior of Interfaces\\'s interpretation feature in a Blocks app.\\n2. Customize how interpretations are displayed in a Blocks app.\\n\\nLet\\'s get started!\\n\\n##', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/custom-interpretations-with-blocks.md'}, lookup_index=0),\n",
              " Document(page_content='Setting up the Blocks app\\n\\nLet\\'s build a sentiment classification app with the Blocks API.\\nThis app will take text as input and output the probability that this text expresses either negative or positive sentiment.\\nWe\\'ll have a single input `Textbox` and a single output `Label` component.\\nBelow is the code for the app as well as the app itself.\\n\\n```python\\nimport gradio as gr \\nfrom transformers import pipeline\\n\\nsentiment_classifier = pipeline(\"text-classification\", return_all_scores=True)\\n\\ndef classifier(text):\\n    pred = sentiment_classifier(text)\\n    return {p[\"label\"]: p[\"score\"] for p in pred[0]}\\n\\nwith gr.Blocks() as demo:\\n    with gr.Row():\\n        with gr.Column():\\n            input_text = gr.Textbox(label=\"Input Text\")\\n            with gr.Row():\\n                classify = gr.Button(\"Classify Sentiment\")\\n        with gr.Column():\\n            label = gr.Label(label=\"Predicted Sentiment\")\\n\\n    classify.click(classifier, input_text, label)\\ndemo.launch()\\n```\\n\\n<gradio-app space=\"freddyaboulton/sentiment-classification\"> </gradio-app>\\n\\n## Adding interpretations to the app\\n\\nOur goal is to present to our users how the words in the input contribute to the model\\'s prediction.\\nThis will help our users understand how', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/custom-interpretations-with-blocks.md'}, lookup_index=0),\n",
              " Document(page_content='the model works and also evaluate its effectiveness.\\nFor example, we should expect our model to identify the words \"happy\" and \"love\" with positive sentiment - if not it\\'s a sign we made a mistake in training it!\\n\\nFor each word in the input, we will compute a score of how much the model\\'s prediction of positive sentiment is changed by that word.\\nOnce we have those `(word, score)` pairs we can use gradio to visualize them for the user.\\n\\nThe [shap](https://shap.readthedocs.io/en/stable/index.html) library will help us compute the `(word, score)` pairs and\\ngradio will take care of displaying the output to the user.\\n\\nThe following code computes the `(word, score)` pairs:\\n\\n```python\\ndef interpretation_function(text):\\n    explainer = shap.Explainer(sentiment_classifier)\\n    shap_values = explainer([text])\\n    \\n    # Dimensions are (batch size, text size, number of classes)\\n    # Since we care about positive sentiment, use index 1\\n    scores = list(zip(shap_values.data[0], shap_values.values[0, :, 1]))\\n    # Scores contains (word, score) pairs\\n    \\n    \\n    # Format expected by gr.components.Interpretation\\n    return {\"original\": text, \"interpretation\": scores}\\n```\\n\\nNow, all we have to do is add a button that', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/custom-interpretations-with-blocks.md'}, lookup_index=0),\n",
              " Document(page_content='runs this function when clicked.\\nTo display the interpretation, we will use `gr.components.Interpretation`.\\nThis will color each word in the input either red or blue.\\nRed if it contributes to positive sentiment and blue if it contributes to negative sentiment.\\nThis is how `Interface` displays the interpretation output for text.\\n\\n```python\\nwith gr.Blocks() as demo:\\n    with gr.Row():\\n        with gr.Column():\\n            input_text = gr.Textbox(label=\"Input Text\")\\n            with gr.Row():\\n                classify = gr.Button(\"Classify Sentiment\")\\n                interpret = gr.Button(\"Interpret\")\\n        with gr.Column():\\n            label = gr.Label(label=\"Predicted Sentiment\")\\n        with gr.Column():\\n            interpretation = gr.components.Interpretation(input_text)\\n    classify.click(classifier, input_text, label)\\n    interpret.click(interpretation_function, input_text, interpretation)\\n\\ndemo.launch()\\n```\\n\\n<gradio-app space=\"freddyaboulton/sentiment-classification-interpretation\"> </gradio-app>\\n\\n\\n## Customizing how the interpretation is displayed\\n\\nThe `gr.components.Interpretation` component does a good job of showing how individual words contribute to the sentiment prediction,\\nbut what if we also wanted to', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/custom-interpretations-with-blocks.md'}, lookup_index=0),\n",
              " Document(page_content='display the score themselves along with the words?\\n\\nOne way to do this would be to generate a bar plot where the words are on the horizontal axis and the bar height corresponds\\nto the shap score.\\n\\nWe can do this by modifying our `interpretation_function` to additionally return a matplotlib bar plot.\\nWe will display it with the `gr.Plot` component in a separate tab.\\n\\nThis is how the interpretation function will look:\\n```python\\ndef interpretation_function(text):\\n    explainer = shap.Explainer(sentiment_classifier)\\n    shap_values = explainer([text])\\n    # Dimensions are (batch size, text size, number of classes)\\n    # Since we care about positive sentiment, use index 1\\n    scores = list(zip(shap_values.data[0], shap_values.values[0, :, 1]))\\n\\n    scores_desc = sorted(scores, key=lambda t: t[1])[::-1]\\n\\n    # Filter out empty string added by shap\\n    scores_desc = [t for t in scores_desc if t[0] != \"\"]\\n\\n    fig_m = plt.figure()\\n    \\n    # Select top 5 words that contribute to positive sentiment\\n    plt.bar(x=[s[0] for s in scores_desc[:5]],\\n            height=[s[1] for s in scores_desc[:5]])\\n    plt.title(\"Top words contributing to positive sentiment\")\\n    plt.ylabel(\"Shap Value\")\\n    plt.xlabel(\"Word\")\\n    return {\"original\":', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/custom-interpretations-with-blocks.md'}, lookup_index=0),\n",
              " Document(page_content='text, \"interpretation\": scores}, fig_m\\n```\\n\\nAnd this is how the app code will look:\\n```python\\nwith gr.Blocks() as demo:\\n    with gr.Row():\\n        with gr.Column():\\n            input_text = gr.Textbox(label=\"Input Text\")\\n            with gr.Row():\\n                classify = gr.Button(\"Classify Sentiment\")\\n                interpret = gr.Button(\"Interpret\")\\n        with gr.Column():\\n            label = gr.Label(label=\"Predicted Sentiment\")\\n        with gr.Column():\\n            with gr.Tabs():\\n                with gr.TabItem(\"Display interpretation with built-in component\"):\\n                    interpretation = gr.components.Interpretation(input_text)\\n                with gr.TabItem(\"Display interpretation with plot\"):\\n                    interpretation_plot = gr.Plot()\\n\\n    classify.click(classifier, input_text, label)\\n    interpret.click(interpretation_function, input_text, [interpretation, interpretation_plot])\\n\\ndemo.launch()\\n```\\n\\nYou can see the demo below!\\n\\n<gradio-app space=\"freddyaboulton/sentiment-classification-interpretation-tabs\"> </gradio-app>\\n\\n## Beyond Sentiment Classification\\nAlthough we have focused on sentiment classification so far, you can add interpretations to almost any machine learning model.\\nThe output must be an `gr.Image` or `gr.Label` but the input can be', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/custom-interpretations-with-blocks.md'}, lookup_index=0),\n",
              " Document(page_content='almost anything (`gr.Number`, `gr.Slider`, `gr.Radio`, `gr.Image`).\\n\\nHere is a demo built with blocks of interpretations for an image classification model:\\n\\n<gradio-app space=\"freddyaboulton/image-classification-interpretation-blocks\"> </gradio-app>\\n\\n\\n## Closing remarks\\n\\nWe did a deep dive 🤿 into how interpretations work and how you can add them to your Blocks app.\\n\\nWe also showed how the Blocks API gives you the power to control how the interpretation is visualized in your app.\\n\\nAdding interpretations is a helpful way to make your users understand and gain trust in your model.\\nNow you have all the tools you need to add them to all of your apps!\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/custom-interpretations-with-blocks.md'}, lookup_index=0),\n",
              " Document(page_content='# Real Time Speech Recognition \\n\\nRelated spaces: https://huggingface.co/spaces/abidlabs/streaming-asr-paused, https://huggingface.co/spaces/abidlabs/full-context-asr\\nTags: ASR, SPEECH, STREAMING\\n\\n## Introduction\\n\\nAutomatic speech recognition (ASR), the conversion of spoken speech to text, is a very important and thriving area of machine learning. ASR algorithms run on practically every smartphone, and are becoming increasingly embedded in professional workflows, such as digital assistants for nurses and doctors. Because ASR algorithms are designed to be used directly by customers and end users, it is important to validate that they are behaving as expected when confronted with a wide variety of speech patterns (different accents, pitches, and background audio conditions).\\n\\nUsing `gradio`, you can easily build a demo of your ASR model and share that with a testing team, or test it yourself by speaking through the microphone on your device.\\n\\nThis tutorial will show how to take a pretrained speech-to-text model and deploy it with a Gradio interface. We will start with a ***full-context*** model, in which the user speaks the entire audio before the prediction runs. Then we', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/real-time-speech-recognition.md'}, lookup_index=0),\n",
              " Document(page_content='will adapt the demo to make it ***streaming***, meaning that the audio model will convert speech as you speak. The streaming demo that we create will look something like this (try it below or [in a new tab](https://huggingface.co/spaces/abidlabs/streaming-asr-paused)!):\\n\\n<iframe src=\"https://abidlabs-streaming-asr-paused.hf.space\" frameBorder=\"0\" height=\"350\" title=\"Gradio app\" class=\"container p-0 flex-grow space-iframe\" allow=\"accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking\" sandbox=\"allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads\"></iframe>\\n\\nReal-time ASR is inherently *stateful*, meaning that the model\\'s predictions change depending on what words the user previously spoke. So, in this tutorial, we will also cover how to use **state** with Gradio demos. \\n\\n###', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/real-time-speech-recognition.md'}, lookup_index=0),\n",
              " Document(page_content=\"Prerequisites\\n\\nMake sure you have the `gradio` Python package already [installed](/getting_started). You will also need a pretrained speech recognition model. In this tutorial, we will build demos from 2 ASR libraries:\\n\\n* Transformers (for this, `pip install transformers` and `pip install torch`) \\n* DeepSpeech (`pip install deepspeech==0.8.2`)\\n\\nMake sure you have at least one of these installed so that you can follow along the tutorial. You will also need `ffmpeg` [installed on your system](https://www.ffmpeg.org/download.html), if you do not already have it, to process files from the microphone.\\n\\nHere's how to build a real time speech recognition (ASR) app: \\n\\n1. [Set up the Transformers ASR Model](#1-set-up-the-transformers-asr-model)\\n2. [Create a Full-Context ASR Demo with Transformers](#2-create-a-full-context-asr-demo-with-transformers) \\n3. [Create a Streaming ASR Demo  with Transformers](#3-create-a-streaming-asr-demo-with-transformers)\\n4. [Create a Streaming ASR Demo with DeepSpeech](#4-create-a-streaming-asr-demo-with-deepspeech)\\n\\n\\n## 1. Set up the Transformers ASR Model\\n\\nFirst, you will need to have an ASR model that you have either trained\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/real-time-speech-recognition.md'}, lookup_index=0),\n",
              " Document(page_content='yourself or you will need to download a pretrained model. In this tutorial, we will start by using a pretrained ASR model from the Hugging Face model, `Wav2Vec2`. \\n\\nHere is the code to load `Wav2Vec2` from Hugging Face `transformers`.\\n\\n```python\\nfrom transformers import pipeline\\n\\np = pipeline(\"automatic-speech-recognition\")\\n```\\n\\nThat\\'s it! By default, the automatic speech recognition model pipeline loads Facebook\\'s `facebook/wav2vec2-base-960h` model.\\n\\n## 2. Create a Full-Context ASR Demo with Transformers \\n\\nWe will start by creating a *full-context* ASR demo, in which the user speaks the full audio before using the ASR model to run inference. This is very easy with Gradio -- we simply create a function around the `pipeline` object above.\\n\\nWe will use `gradio`\\'s built in `Audio` component, configured to take input from the user\\'s microphone and return a filepath for the recorded audio. The output component will be a plain `Textbox`.\\n\\n```python\\nimport gradio as gr\\n\\ndef transcribe(audio):\\n    text = p(audio)[\"text\"]\\n    return text\\n\\ngr.Interface(\\n    fn=transcribe, \\n    inputs=gr.Audio(source=\"microphone\", type=\"filepath\"), \\n    outputs=\"text\").launch()\\n```\\n\\nSo what\\'s', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/real-time-speech-recognition.md'}, lookup_index=0),\n",
              " Document(page_content='happening here? The `transcribe` function takes a single parameter, `audio`, which is a filepath to the audio file that the user has recorded. The `pipeline` object expects a filepath and converts it to text, which is returned to the frontend and displayed in a textbox. \\n\\nLet\\'s see it in action! (Record a short audio clip and then click submit, or [open in a new tab](https://huggingface.co/spaces/abidlabs/full-context-asr)):\\n\\n<iframe src=\"https://abidlabs-full-context-asr.hf.space\" frameBorder=\"0\" height=\"350\" title=\"Gradio app\" class=\"container p-0 flex-grow space-iframe\" allow=\"accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking\" sandbox=\"allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads\"></iframe>\\n\\n## 3. Create a Streaming ASR Demo  with Transformers\\n\\nOk great! We\\'ve built an ASR', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/real-time-speech-recognition.md'}, lookup_index=0),\n",
              " Document(page_content='model that works well for short audio clips. However, if you are recording longer audio clips, you probably want a *streaming* interface, one that transcribes audio as the user speaks instead of just all-at-once at the end.\\n\\nThe good news is that it\\'s not too difficult to adapt the demo we just made to make it streaming, using the same `Wav2Vec2` model. \\n\\nThe biggest change is that we must now introduce a `state` parameter, which holds the audio that has been *transcribed so far*. This allows us to only the latest chunk of audio and simply append it to the audio we previously transcribed. \\n\\nWhen adding state to a Gradio demo, you need to do a total of 3 things:\\n\\n* Add a `state` parameter to the function\\n* Return the updated `state` at the end of the function\\n* Add the `\"state\"` components to the `inputs` and `outputs` in `Interface` \\n\\nHere\\'s what the code looks like:\\n\\n```python\\ndef transcribe(audio, state=\"\"):\\n    text = p(audio)[\"text\"]\\n    state += text + \" \"\\n    return state, state\\n\\n# Set the starting state to an empty string\\n\\ngr.Interface(\\n    fn=transcribe, \\n    inputs=[\\n        gr.Audio(source=\"microphone\", type=\"filepath\", streaming=True), \\n        \"state\" \\n    ],\\n    outputs=[\\n        \"textbox\",\\n        \"state\"\\n    ],\\n   ', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/real-time-speech-recognition.md'}, lookup_index=0),\n",
              " Document(page_content='   live=True).launch()\\n```\\n\\nNotice that we\\'ve also made one other change, which is that we\\'ve set `live=True`. This keeps the Gradio interface running constantly, so it automatically transcribes audio without the user having to repeatedly hit the submit button.\\n\\nLet\\'s see how it does (try below or [in a new tab](https://huggingface.co/spaces/abidlabs/streaming-asr))!\\n\\n<iframe src=\"https://abidlabs-streaming-asr.hf.space\" frameBorder=\"0\" height=\"350\" title=\"Gradio app\" class=\"container p-0 flex-grow space-iframe\" allow=\"accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations; legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking\" sandbox=\"allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads\"></iframe>\\n\\n\\nOne thing that you may notice is that the transcription quality has dropped since the chunks of audio are so small, they lack the context to', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/real-time-speech-recognition.md'}, lookup_index=0),\n",
              " Document(page_content='properly be transcribed. A \"hacky\" fix to this is to simply increase the runtime of the `transcribe()` function so that longer audio chunks are processed. We can do this by adding a `time.sleep()` inside the function, as shown below (we\\'ll see a proper fix next) \\n\\n```python\\nfrom transformers import pipeline\\nimport gradio as gr\\nimport time\\n\\np = pipeline(\"automatic-speech-recognition\")\\n\\ndef transcribe(audio, state=\"\"):\\n    time.sleep(2)\\n    text = p(audio)[\"text\"]\\n    state += text + \" \"\\n    return state, state\\n\\ngr.Interface(\\n    fn=transcribe, \\n    inputs=[\\n        gr.Audio(source=\"microphone\", type=\"filepath\", streaming=True), \\n        \"state\"\\n    ],\\n    outputs=[\\n        \"textbox\",\\n        \"state\"\\n    ],\\n    live=True).launch()\\n```\\n\\nTry the demo below to see the difference (or [open in a new tab](https://huggingface.co/spaces/abidlabs/streaming-asr-paused))!\\n\\n<iframe src=\"https://abidlabs-streaming-asr-paused.hf.space\" frameBorder=\"0\" height=\"350\" title=\"Gradio app\" class=\"container p-0 flex-grow space-iframe\" allow=\"accelerometer; ambient-light-sensor; autoplay; battery; camera; document-domain; encrypted-media; fullscreen; geolocation; gyroscope; layout-animations;', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/real-time-speech-recognition.md'}, lookup_index=0),\n",
              " Document(page_content='legacy-image-formats; magnetometer; microphone; midi; oversized-images; payment; picture-in-picture; publickey-credentials-get; sync-xhr; usb; vr ; wake-lock; xr-spatial-tracking\" sandbox=\"allow-forms allow-modals allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-downloads\"></iframe>\\n\\n\\n## 4. Create a Streaming ASR Demo with DeepSpeech\\n\\nYou\\'re not restricted to ASR models from the `transformers` library -- you can use your own models or models from other libraries. The `DeepSpeech` library contains models that are specifically designed to handle streaming audio data. These models perform really well with  streaming data as they are able to account for previous chunks of audio data when making predictions.\\n\\nGoing through the DeepSpeech library is beyond the scope of this Guide (check out their [excellent documentation here](https://deepspeech.readthedocs.io/en/r0.9/)), but you can use Gradio very similarly with a DeepSpeech ASR model as with a Transformers ASR model. \\n\\nHere\\'s a complete example (on Linux):\\n\\nFirst install the DeepSpeech library and download the pretrained models from the terminal:\\n\\n```bash\\nwget', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/real-time-speech-recognition.md'}, lookup_index=0),\n",
              " Document(page_content='https://github.com/mozilla/DeepSpeech/releases/download/v0.8.2/deepspeech-0.8.2-models.pbmm\\nwget https://github.com/mozilla/DeepSpeech/releases/download/v0.8.2/deepspeech-0.8.2-models.scorer\\napt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg\\npip install deepspeech==0.8.2\\n```\\n\\nThen, create a similar `transcribe()` function as before:\\n\\n```python\\nfrom deepspeech import Model\\nimport numpy as np\\n\\nmodel_file_path = \"deepspeech-0.8.2-models.pbmm\"\\nlm_file_path = \"deepspeech-0.8.2-models.scorer\"\\nbeam_width = 100\\nlm_alpha = 0.93\\nlm_beta = 1.18\\n\\nmodel = Model(model_file_path)\\nmodel.enableExternalScorer(lm_file_path)\\nmodel.setScorerAlphaBeta(lm_alpha, lm_beta)\\nmodel.setBeamWidth(beam_width)\\n\\n\\ndef reformat_freq(sr, y):\\n    if sr not in (\\n        48000,\\n        16000,\\n    ):  # Deepspeech only supports 16k, (we convert 48k -> 16k)\\n        raise ValueError(\"Unsupported rate\", sr)\\n    if sr == 48000:\\n        y = (\\n            ((y / max(np.max(y), 1)) * 32767)\\n            .reshape((-1, 3))\\n            .mean(axis=1)\\n            .astype(\"int16\")\\n        )\\n        sr = 16000\\n    return sr, y\\n\\n\\ndef transcribe(speech, stream):\\n    _, y = reformat_freq(*speech)\\n    if stream is None:\\n        stream =', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/real-time-speech-recognition.md'}, lookup_index=0),\n",
              " Document(page_content='model.createStream()\\n    stream.feedAudioContent(y)\\n    text = stream.intermediateDecode()\\n    return text, stream\\n\\n```\\n\\nThen, create a Gradio Interface as before (the only difference being that the return type should be `numpy` instead of a `filepath` to be compatible with the DeepSpeech models)\\n\\n```python\\nimport gradio as gr\\n\\ngr.Interface(\\n    fn=transcribe, \\n    inputs=[\\n        gr.Audio(source=\"microphone\", type=\"numpy\"), \\n        \"state\" \\n    ], \\n    outputs= [\\n        \"text\", \\n        \"state\"\\n    ], \\n    live=True).launch()\\n```\\n\\nRunning all of this should allow you to deploy your realtime ASR model with a nice GUI. Try it out and see how well it works for you.\\n\\n--------------------------------------------\\n\\n\\nAnd you\\'re done! That\\'s all the code you need to build a web-based GUI for your ASR model. \\n\\nFun tip: you can share your ASR model instantly with others simply by setting `share=True` in `launch()`. \\n\\n\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/real-time-speech-recognition.md'}, lookup_index=0),\n",
              " Document(page_content='# Developing Faster with Auto-Reloading\\n\\n**Prerequisite**: This Guide requires you to know about Blocks. Make sure to [read the Guide to Blocks first](https://gradio.app/quickstart/#blocks-more-flexibility-and-control).\\n\\nThis guide covers auto reloading, reloading in a Python IDE, and using gradio with Jupyter Notebooks.\\n\\n## Why Auto-Reloading?\\n\\nWhen you are building a Gradio demo, particularly out of Blocks, you may find it cumbersome to keep re-running your code to test your changes.\\n\\nTo make it faster and more convenient to write your code, we\\'ve made it easier to \"reload\" your Gradio apps instantly when you are developing in a **Python IDE** (like VS Code, Sublime Text, PyCharm, or so on) or generally running your Python code from the terminal. We\\'ve also developed an analogous \"magic command\" that allows you to re-run cells faster if you use **Jupyter Notebooks** (or any similar environment like Colab).\\n\\nThis short Guide will cover both of these methods, so no matter how you write Python, you\\'ll leave knowing how to build Gradio apps faster.\\n\\n## Python IDE Reload 🔥\\n\\nIf you are building Gradio Blocks using a Python IDE, your file of code (let\\'s name it `app.py`) might look', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/developing-faster-with-reload-mode.md'}, lookup_index=0),\n",
              " Document(page_content='something like this: \\n\\n```python\\nimport gradio as gr\\n\\nwith gr.Blocks() as demo:\\n    gr.Markdown(\"# Greetings from Gradio!\")\\n    inp = gr.Textbox(placeholder=\"What is your name?\")\\n    out = gr.Textbox()\\n\\n    inp.change(fn=lambda x: f\"Welcome, {x}!\", \\n               inputs=inp, \\n               outputs=out)\\n\\nif __name__ == \"__main__\":\\n    demo.launch()    \\n```\\n\\nThe problem is that anytime that you want to make a change to your layout, events, or components, you have to close and rerun your app by writing `python app.py`.\\n\\nInstead of doing this, you can run your code in **reload mode** by changing 1 word: `python` to `gradio`:\\n\\nIn the terminal, run `gradio app.py`. That\\'s it! \\n\\nNow, you\\'ll see that after you\\'ll see something like this:\\n\\n```bash\\nLaunching in *reload mode* on: http://127.0.0.1:7860 (Press CTRL+C to quit)\\n\\nWatching...\\n\\nWARNING:  The --reload flag should not be used in production on Windows.\\n```\\n\\nThe important part here is the line that says `Watching...` What\\'s happening here is that Gradio will be observing the directory where `app.py` file lives, and if the file changes, it will automatically rerun the file for you. So you can focus on writing your code, and your Gradio demo will refresh automatically 🥳\\n\\n⚠️ Now,', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/developing-faster-with-reload-mode.md'}, lookup_index=0),\n",
              " Document(page_content='there is one important thing to keep in mind when using the reload mode: Gradio specifically looks for a Gradio Blocks/Interface demo called `demo` in your code. If you have named your demo something else, you can pass that as the 2nd parameter in your code, like this: `gradio app.py my_demo`\\n\\nAs a small aside, this auto-reloading happens if you change your `app.py` source code or the Gradio source code. Meaning that this can be useful if you decide to [contribute to Gradio itself](https://github.com/gradio-app/gradio/blob/main/CONTRIBUTING.md) ✅\\n\\n## Jupyter Notebook Magic 🔮\\n\\nWhat about if you use Jupyter Notebooks (or Colab Notebooks, etc.) to develop code? We got something for you too!\\n\\nWe\\'ve developed a **magic command** that will create and run a Blocks demo for you. To use this, load the gradio extension at the top of your notebook: \\n\\n`%load_ext gradio`\\n\\nThen, in the cell that you are developing your Gradio demo, simply write the magic command **`%%blocks`** at the top, and then write the layout and components like you would normally:\\n\\n```py\\n%%blocks \\n\\nimport gradio as gr\\n\\ngr.Markdown(\"# Greetings from Gradio!\")\\ninp = gr.Textbox(placeholder=\"What is your name?\")\\nout =', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/developing-faster-with-reload-mode.md'}, lookup_index=0),\n",
              " Document(page_content='gr.Textbox()\\n\\ninp.change(fn=lambda x: f\"Welcome, {x}!\", \\n           inputs=inp, \\n           outputs=out)\\n```\\n\\nNotice that:\\n\\n* You do not need to put the boiler plate `with gr.Blocks() as demo:` and `demo.launch()` code — Gradio does that for you automatically!\\n\\n* Every time you rerun the cell, Gradio will re-launch your app on the same port and using the same underlying web server. This means you\\'ll see your changes *much, much faster* than if you were rerunning the cell normally. \\n\\nHere\\'s what it looks like in a jupyter notebook:\\n\\n![](https://i.ibb.co/nrszFws/Blocks.gif)\\n\\n\\U0001fa84 This works in colab notebooks too! [Here\\'s a colab notebook](https://colab.research.google.com/drive/1jUlX1w7JqckRHVE-nbDyMPyZ7fYD8488?authuser=1#scrollTo=zxHYjbCTTz_5) where you can see the Blocks magic in action. Try making some changes and re-running the cell with the Gradio code! \\n\\nThe Notebook Magic is now the author\\'s preferred way of building Gradio demos. Regardless of how you write Python code, we hope either of these methods will give you a much better development experience using Gradio. \\n\\n--------\\n\\n## Next Steps\\n\\nNow that you know how to develop quickly using Gradio, start building your own! \\n\\nIf you are', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/developing-faster-with-reload-mode.md'}, lookup_index=0),\n",
              " Document(page_content='looking for inspiration, try exploring demos other people have built with Gradio, [browse public Hugging Face Spaces](http://hf.space/) 🤗\\n\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/developing-faster-with-reload-mode.md'}, lookup_index=0),\n",
              " Document(page_content=\"# Advanced Interface Features\\n\\nThere's more to cover on the [Interface](https://gradio.app/docs#interface) class. This guide covers all the advanced features: Using [Interpretation](https://gradio.app/docs#interpretation), custom styling, loading from the [Hugging Face Hub](https://hf.co), and using [Parallel](https://gradio.app/docs#parallel) and [Series](https://gradio.app/docs#series). \\n\\n## Interpreting your Predictions\\n\\nMost models are black boxes such that the internal logic of the function is hidden from the end user. To encourage transparency, we've made it very easy to add interpretation to your model by  simply setting the `interpretation` keyword in the `Interface` class to `default`. This allows your users to understand what parts of the input are responsible for the output. Take a look at the simple interface below which shows an image classifier that also includes interpretation:\\n\\n$code_image_classifier_interpretation\\n\\n\\nIn addition to `default`, Gradio also includes [Shapley-based interpretation](https://christophm.github.io/interpretable-ml-book/shap.html), which provides more accurate interpretations, albeit usually with\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/02_building-interfaces/04_advanced-interface-features.md'}, lookup_index=0),\n",
              " Document(page_content='a slower runtime. To use this, simply set the `interpretation` parameter to `\"shap\"` (note: also make sure the python package `shap` is installed). Optionally, you can modify the `num_shap` parameter, which controls the tradeoff between accuracy and runtime (increasing this value generally increases accuracy). Here is an example:\\n\\n```python\\ngr.Interface(fn=classify_image, inputs=image, outputs=label, interpretation=\"shap\", num_shap=5).launch()\\n```\\n\\nThis will work for any function, even if internally, the model is a complex neural network or some other black box. If you use Gradio\\'s `default` or `shap` interpretation, the output component must be a `Label`. All common input components are supported. Here is an example with text input.\\n\\n$code_gender_sentence_default_interpretation\\n\\nSo what is happening under the hood? With these interpretation methods, Gradio runs the prediction multiple times with modified versions of the input. Based on the results, you\\'ll see that the interface automatically highlights the parts of the text (or image, etc.) that contributed increased the likelihood of the class as red. The intensity of color corresponds to the importance of that', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/02_building-interfaces/04_advanced-interface-features.md'}, lookup_index=0),\n",
              " Document(page_content='part of the input. The parts that decrease the class confidence are highlighted blue.\\n\\nYou can also write your own interpretation function. The demo below adds custom interpretation to the previous demo. This function will take the same inputs as the main wrapped function. The output of this interpretation function will be used to highlight the input of each input component - therefore the function must return a list where the number of elements corresponds to the number of input components. To see the format for interpretation for each input component, check the Docs.\\n\\n$code_gender_sentence_custom_interpretation\\n\\nLearn more about Interpretation in the [docs](https://gradio.app/docs#interpretation). \\n\\n## Custom Styling\\n\\nIf you\\'d like to have more fine-grained control over any aspect of your demo, you can also write your own css or pass in a filepath to a css file, with the `css` parameter of the `Interface` class.\\n\\n```python\\ngr.Interface(..., css=\"body {background-color: red}\")\\n```\\n\\nIf you\\'d like to reference external files in your css, preface the file path (which can be a relative or absolute path) with `\"file=\"`, for example:\\n\\n```python\\ngr.Interface(..., css=\"body', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/02_building-interfaces/04_advanced-interface-features.md'}, lookup_index=0),\n",
              " Document(page_content='{background-image: url(\\'file=clouds.jpg\\')}\")\\n```\\n\\n## Loading Hugging Face Models and Spaces\\n\\nGradio integrates nicely with the [Hugging Face Hub](https://hf.co), allowing you to load models and Spaces with just one line of code. To use this, simply use the `load()` method in the `Interface` class. So:\\n\\n- To load any model from the Hugging Face Hub and create an interface around it, you pass `\"model/\"` or `\"huggingface/\"` followed by the model name, like these examples:\\n\\n```python\\ngr.Interface.load(\"huggingface/gpt2\").launch();\\n```\\n\\n```python\\ngr.Interface.load(\"huggingface/EleutherAI/gpt-j-6B\", \\n    inputs=gr.Textbox(lines=5, label=\"Input Text\")  # customizes the input component\\n).launch()\\n```\\n\\n- To load any Space from the Hugging Face Hub and recreate it locally (so that you can customize the inputs and outputs for example), you pass `\"spaces/\"` followed by the model name:\\n\\n```python\\ngr.Interface.load(\"spaces/eugenesiow/remove-bg\", inputs=\"webcam\", title=\"Remove your webcam background!\").launch()\\n```\\n\\nOne of the great things about loading Hugging Face models or spaces using Gradio is that you can then immediately use the resulting `Interface`', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/02_building-interfaces/04_advanced-interface-features.md'}, lookup_index=0),\n",
              " Document(page_content='object just like function in your Python code (this works for every type of model/space: text, images, audio, video, and even multimodal models):\\n\\n```python\\nio = gr.Interface.load(\"models/EleutherAI/gpt-neo-2.7B\")\\nio(\"It was the best of times\")  # outputs model completion\\n```\\n\\n## Putting Interfaces in Parallel and Series\\n\\nGradio also lets you mix interfaces very easily using the `gradio.Parallel` and `gradio.Series` classes. `Parallel` lets you put two similar models (if they have the same input type) in parallel to compare model predictions:\\n\\n```python\\ngenerator1 = gr.Interface.load(\"huggingface/gpt2\")\\ngenerator2 = gr.Interface.load(\"huggingface/EleutherAI/gpt-neo-2.7B\")\\ngenerator3 = gr.Interface.load(\"huggingface/EleutherAI/gpt-j-6B\")\\n\\ngr.Parallel(generator1, generator2, generator3).launch()\\n```\\n\\n`Series` lets you put models and spaces in series, piping the output of one model into the input of the next model. \\n\\n```python\\ngenerator = gr.Interface.load(\"huggingface/gpt2\")\\ntranslator = gr.Interface.load(\"huggingface/t5-small\")\\n\\ngr.Series(generator, translator).launch()  # this demo generates text, then translates it to', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/02_building-interfaces/04_advanced-interface-features.md'}, lookup_index=0),\n",
              " Document(page_content='German, and outputs the final result.\\n```\\n\\nAnd of course, you can also mix `Parallel` and `Series` together whenever that makes sense!\\n\\nLearn more about Parallel and Series in the [docs](https://gradio.app/docs#parallel). ', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/02_building-interfaces/04_advanced-interface-features.md'}, lookup_index=0),\n",
              " Document(page_content=\"# The 4 Kinds of Gradio Interfaces\\n\\nSo far, we've always assumed that in order to build an Gradio demo, you need both inputs and outputs. But this isn't always the case for machine learning demos: for example, *unconditional image generation models* don't take any input but produce an image as the output.\\n\\nIt turns out that the `gradio.Interface` class can actually handle 4 different kinds of demos:\\n\\n1. **Standard demos**: which have both separate inputs and outputs (e.g. an image classifier or speech-to-text model)\\n2. **Output-only demos**: which don't take any input but produce on output (e.g. an unconditional image generation model)\\n3. **Input-only demos**: which don't produce any output but do take in some sort of input (e.g. a demo that saves images that you upload to a persistent external database)\\n4. **Unified demos**: which have both input and output components, but the input and output components *are the same*. This means that the output produced overrides the input (e.g. a text autocomplete model)\\n\\nDepending on the kind of demo, the user interface (UI) looks slightly\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/02_building-interfaces/05_four-kinds-of-interfaces.md'}, lookup_index=0),\n",
              " Document(page_content=\"different:\\n\\n![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/gradio-guides/interfaces4.png)\\n\\n\\nLet's see how to build each kind of demo using the `Interface` class, along with examples:\\n\\n\\n## Standard demos\\n\\nTo create a demo that has both the input and the output components, you simply need to set the values of the `inputs` and `outputs` parameter in `Interface()`. Here's an example demo of a simple image filter:\\n\\n$code_sepia_filter\\n$demo_sepia_filter\\n\\n\\n## Output-only demos\\n\\nWhat about demos that only contain outputs? In order to build such a demo, you simply set the value of the `inputs` parameter in `Interface()` to `None`. Here's an example demo of a mock image generation model:\\n\\n$code_fake_gan_no_input\\n$demo_fake_gan_no_input\\n\\n## Input-only demos\\n\\nSimilarly, to create a demo that only contains inputs, set the value of `outputs` parameter in `Interface()` to be `None`. Here's an example demo that saves any uploaded image to disk:\\n\\n$code_save_file_no_output\\n$demo_save_file_no_output\\n\\n## Unified demos\\n\\nA demo that has a single component as both the input and the output. It can simply be created by setting the values of the\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/02_building-interfaces/05_four-kinds-of-interfaces.md'}, lookup_index=0),\n",
              " Document(page_content=\"`inputs` and `outputs` parameter as the same component. Here's an example demo of a text generation model:\\n\\n$code_unified_demo_text_generation\\n$demo_unified_demo_text_generation\\n\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/02_building-interfaces/05_four-kinds-of-interfaces.md'}, lookup_index=0),\n",
              " Document(page_content='# More on Examples\\n\\nThis guide covers what more you can do with Examples: Loading examples from a directory, providing partial examples, and caching. If Examples is new to you, check out the intro in the [Key Features](../key-features/#example-inputs) guide. \\n\\n## Providing Examples\\n\\nAs covered in the [Key Features](../key-features/#example-inputs) guide, adding examples to an Interface is as easy as providing a list of lists to the `examples`\\nkeyword argument. \\nEach sublist is a data sample, where each element corresponds to an input of the prediction function.\\nThe inputs must be ordered in the same order as the prediction function expects them.\\n\\nIf your interface only has one input component, then you can provide your examples as a regular list instead of a list of lists.\\n\\n### Loading Examples from a Directory\\n\\nYou can also specify a path to a directory containing your examples. If your Interface takes only a single file-type input, e.g. an image classifier, you can simply pass a directory filepath to the `examples=` argument, and the `Interface` will load the images in the directory as examples. \\nIn the case of multiple inputs, this directory must\\ncontain a log.csv file with the example', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/02_building-interfaces/03_more-on-examples.md'}, lookup_index=0),\n",
              " Document(page_content='values.\\nIn the context of the calculator demo, we can set  `examples=\\'/demo/calculator/examples\\'` and in that directory we include the following `log.csv` file:\\n```csv\\nnum,operation,num2\\n5,\"add\",3\\n4,\"divide\",2\\n5,\"multiply\",3\\n```\\n\\nThis can be helpful when browsing flagged data. Simply point to the flagged directory and the `Interface` will load the examples from the flagged data.\\n\\n### Providing Partial Examples\\n\\nSometimes your app has many input components, but you would only like to provide examples for a subset of them. In order to exclude some inputs from the examples, pass `None` for all data samples corresponding to those particular components.\\n\\n## Caching examples\\n\\nYou may wish to provide some cached examples of your model for users to quickly try out, in case your model takes a while to run normally.\\nIf `cache_examples=True`, the `Interface` will run all of your examples through your app and save the outputs when you call the `launch()` method. This data will be saved in a directory called `gradio_cached_examples`. \\n\\nWhenever a user clicks on an example, the output will automatically be populated in the app now, using data from this cached directory instead of actually', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/02_building-interfaces/03_more-on-examples.md'}, lookup_index=0),\n",
              " Document(page_content='running the function. This is useful so users can quickly try out your model without adding any load!  \\n\\nKeep in mind once the cache is generated, it will not be updated in future launches. If the examples or function logic change, delete the cache folder to clear the cache and rebuild it with another `launch()`.\\n\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/02_building-interfaces/03_more-on-examples.md'}, lookup_index=0),\n",
              " Document(page_content='# Interface State\\n\\nThis guide covers how State is handled in Gradio. Learn the difference between Global and Session states, and how to use both.\\n\\n## Global State\\n\\nYour function may use data that persists beyond a single function call. If the data is something accessible to all function calls and all users, you can create a variable outside the function call and access it inside the function. For example, you may load a large model outside the function and use it inside the function so that every function call does not need to reload the model. \\n\\n$code_score_tracker\\n\\nIn the code above, the `scores` array is shared between all users. If multiple users are accessing this demo, their scores will all be added to the same list, and the returned top 3 scores will be collected from this shared reference. \\n\\n## Session State\\n\\nAnother type of data persistence Gradio supports is session **state**, where data persists across multiple submits within a page session. However, data is *not* shared between different users of your model. To store data in a session state, you need to do three things:\\n\\n1. Pass in an extra parameter into your function, which represents the state of the interface.\\n2. At the end of the function,', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/02_building-interfaces/01_interface-state.md'}, lookup_index=0),\n",
              " Document(page_content=\"return the updated value of the state as an extra return value.\\n3. Add the `'state'` input and `'state'` output components when creating your `Interface`\\n\\nA chatbot is an example where you would need session state - you want access to a users previous submissions, but you cannot store chat history in a global variable, because then chat history would get jumbled between different users. \\n\\n$code_chatbot_demo\\n$demo_chatbot_demo\\n\\nNotice how the state persists across submits within each page, but if you load this demo in another tab (or refresh the page), the demos will not share chat history. \\n\\nThe default value of `state` is None. If you pass a default value to the state parameter of the function, it is used as the default value of the state instead. The `Interface` class only supports a single input and outputs state variable, though it can be a list with multiple elements. For more complex use cases, you can use Blocks, [which supports multiple `State` variables](/state_in_blocks/).\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/02_building-interfaces/01_interface-state.md'}, lookup_index=0),\n",
              " Document(page_content='# Reactive Interfaces\\n\\nThis guide covers how to get Gradio interfaces to refresh automatically or continuously stream data.\\n\\n## Live Interfaces\\n\\nYou can make interfaces automatically refresh by setting `live=True` in the interface. Now the interface will recalculate as soon as the user input changes.\\n\\n$code_calculator_live\\n$demo_calculator_live\\n\\nNote there is no submit button, because the interface resubmits automatically on change.\\n\\n## Streaming Components\\n\\nSome components have a \"streaming\" mode, such as `Audio` component in microphone mode, or the `Image` component in webcam mode. Streaming means data is sent continuously to the backend and the `Interface` function is continuously being rerun. \\n\\nThe difference between `gr.Audio(source=\\'microphone\\')` and `gr.Audio(source=\\'microphone\\', streaming=True)`, when both are used in `gr.Interface(live=True)`, is that the first  `Component` will automatically submit data and run the `Interface` function when the user stops recording, whereas the second `Component` will continuously send data and run the `Interface` function *during* recording.\\n\\nHere is example code of streaming images from the', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/02_building-interfaces/02_reactive-interfaces.md'}, lookup_index=0),\n",
              " Document(page_content='webcam.\\n\\n$code_stream_frames', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/02_building-interfaces/02_reactive-interfaces.md'}, lookup_index=0),\n",
              " Document(page_content='# Description\\n\\nPlease include: \\n* relevant motivation\\n* a summary of the change \\n* which issue is fixed. \\n* any additional dependencies that are required for this change.\\n\\nCloses: # (issue)\\n\\n# Checklist:\\n\\n- [ ] I have performed a self-review of my own code\\n- [ ] I have added a short summary of my change to the CHANGELOG.md\\n- [ ] My code follows the style guidelines of this project\\n- [ ] I have commented my code in hard-to-understand areas\\n- [ ] I have made corresponding changes to the documentation\\n- [ ] I have added tests that prove my fix is effective or that my feature works\\n- [ ] New and existing unit tests pass locally with my changes\\n\\n\\n# A note about the CHANGELOG\\n\\nHello 👋 and thank you for contributing to Gradio!\\n\\nAll pull requests must update the change log located in CHANGELOG.md, unless the pull request is labeled with the \"no-changelog-update\" label.\\n\\nPlease add a brief summary of the change to the Upcoming Release > Full Changelog section of the CHANGELOG.md file and include\\na link to the PR (formatted in markdown) and a link to your github profile (if you like). For example, \"* Added a cool new feature by `[@myusername](link-to-your-github-profile)` in `[PR', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/.github/PULL_REQUEST_TEMPLATE.md'}, lookup_index=0),\n",
              " Document(page_content='11111](https://github.com/gradio-app/gradio/pull/11111)`\".\\n\\nIf you would like to elaborate on your change further, feel free to include a longer explanation in the other sections.\\nIf you would like an image/gif/video showcasing your feature, it may be best to edit the CHANGELOG file using the \\nGitHub web UI since that lets you upload files directly via drag-and-drop.', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/.github/PULL_REQUEST_TEMPLATE.md'}, lookup_index=0),\n",
              " Document(page_content=\"---\\nname: ⚡ Feature request\\nabout: Suggest an improvement or new feature or a new Guide for Gradio\\ntitle: ''\\nlabels: ''\\nassignees: ''\\n\\n---\\n- [ ] I have searched to see if a similar issue already exists.\\n\\n\\n**Is your feature request related to a problem? Please describe.**  \\nA clear and concise description of what the problem is. Ex. I'm always frustrated when [...]\\n\\n**Describe the solution you'd like**  \\nA clear and concise description of what you want to happen.\\n\\n**Additional context**  \\nAdd any other context or screenshots about the feature request here.\\n\", lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/.github/ISSUE_TEMPLATE/feature_request.md'}, lookup_index=0),\n",
              " Document(page_content='# The Gradio Website\\n\\nThe Gradio website ([https://gradio.app](https://gradio.app)) is built from the contents of this folder. The website is tightly coupled with the rest of the repository through several ways:\\n\\n- The documentation loaded from the docstrings of the objects themselves, and is generated using the gradio library in the gradio folder of this repository. If you want to see changes you made to the docstrings in the library, please install an editable version of the library from root of the directory: `pip install gradio -e .`\\n- The demos are loaded from the `gradio/demo` folder, hosted on spaces, and linked to the documentation in the docstrings of the documented object. \\n- The guide pages are loaded from the `gradio/guides` folder\\n\\nThe website is launched through the `docker-compose.yml` file in this directory. \\n\\nYou can run the entire website by:\\n- Installing nginx\\n- Copying gradio.nginx.conf from this folder to /etc/nginx/conf.d/gradio.nginx.conf \\n- Running `docker-compose build && docker-compose up`\\n- (Re)starting nginx\\n\\nThis will serve the website on port 80 (you can change the port from the gradio.nginx.conf file)\\n\\nAlternatively, for development, read the', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/website/README.md'}, lookup_index=0),\n",
              " Document(page_content='`homepage` section below:\\n\\n## The `homepage` docker\\n\\nThe homepage folder builds the static content of the website into standalone files, served by nginx in docker. For development purposes, instead of running docker to test changes, just run `sh scripts/launch_website.sh` from the root of the repo. \\n\\n## Auto-Reloading\\n\\nThe website is built from the main branch and automatically reloads on commits to main.\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/website/README.md'}, lookup_index=0),\n",
              " Document(page_content='# Building Gradio Website\\n\\nRun the following commands in order:\\n- `pip install -r requirements.txt`\\n- `npm install`\\n- `npm run build` (or `npm run build-mac` on Mac OSX)\\n\\nThe website will be built in the build/ folder as a static website. To launch, run: `cd build && python3 -m http.server`\\n', lookup_str='', metadata={'source': 'https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/website/homepage/README.md'}, lookup_index=0)]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#new\n",
        "source_chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3-xK48f-TwO"
      },
      "outputs": [],
      "source": [
        "#old\n",
        "source_chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPLKWKGOQYN7",
        "outputId": "229200aa-9188-4b3c-a7a7-6e44be145603"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " You can create a scatter plot in gradio by using the `gr.ScatterPlot` component, which accepts a pandas dataframe and some optional configuration parameters.\n",
            "SOURCES: https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/CHANGELOG.md\n"
          ]
        }
      ],
      "source": [
        "#new\n",
        "print_answer(\"how do you create a scatter plot in gradio?\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jt5w6-FCQaYX",
        "outputId": "5bc11fc5-1d8a-485b-a9b6-abb10a0cb680"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " I don't know.\n",
            "SOURCES: N/A\n"
          ]
        }
      ],
      "source": [
        "#new \n",
        "print_answer(\"how can i build a demo for handwritten digit recognition?\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwZYHRL9QsZQ",
        "outputId": "3fe0f593-4a2b-455f-e8e4-68c8dd9580f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " This guide covers how to build a pictionary app (step-by-step): \n",
            "\n",
            "1. [Set up the Sketch Recognition Model](#1-set-up-the-sketch-recognition-model)\n",
            "2. [Define a `predict` function](#2-define-a-predict-function)\n",
            "3. [Create a Gradio Interface](#3-create-a-gradio-interface)\n",
            "\n",
            "SOURCES: https://github.com/gradio-app/gradio/blob/431a987d612d5e43097898d13523fb72bdf84214/guides/06_other-tutorials/building-a-pictionary-app.md\n"
          ]
        }
      ],
      "source": [
        "#new\n",
        "print_answer(\"how to build a demo for sketching?\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Uq5ArBXG3dV"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "#saving FAISS search index to disk\n",
        "with open(\"search_index.pickle\", \"wb\") as f:\n",
        "        pickle.dump(search_index, f) #(FAISS.from_documents(source_chunks, OpenAIEmbeddings()), f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meKCZrx5G3aS"
      },
      "outputs": [],
      "source": [
        "#loading FAISS search index from disk\n",
        "with open(\"search_index.pickle\", \"rb\") as f:\n",
        "    search_index = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3Frat7AaBxl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESbipDhycl6c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuYWZK28cm1u"
      },
      "outputs": [],
      "source": [
        "gr.HTML(\"\"\"<div style=\"text-align: center; max-width: 700px; margin: 0 auto;\">\n",
        "        <div\n",
        "        style=\"\n",
        "            display: inline-flex;\n",
        "            align-items: center;\n",
        "            gap: 0.8rem;\n",
        "            font-size: 1.75rem;\n",
        "        \"\n",
        "        >\n",
        "        <h1 style=\"font-weight: 900; margin-bottom: 7px; margin-top: 5px;\">\n",
        "            Gradio QandA - LangChain Bot\n",
        "        </h1>\n",
        "        </div>\n",
        "        <p style=\"margin-bottom: 10px; font-size: 94%\">\n",
        "        Hi, I'm a Q and A Gradio expert bot, start by typing in your OpenAI API key, questions/issues you are facing in your Gradio implementations and then press enter.<br>\n",
        "        <a href=\"https://huggingface.co/spaces/ysharma/InstructPix2Pix_Chatbot?duplicate=true\"><img src=\"https://bit.ly/3gLdBN6\" alt=\"Duplicate Space\"></a>Duplicate Space with GPU Upgrade for fast Inference & no queue<br> \n",
        "        Built using <a href=\"https://langchain.readthedocs.io/en/latest/\" target=\"_blank\">LangChain</a> and <a href=\"https://github.com/gradio-app/gradio\" target=\"_blank\">Gradio Github repo</a>\n",
        "        </p>\n",
        "    </div>\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4B-xow2cpHX"
      },
      "source": [
        "## Gradio demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "id": "s6vliez8enDI",
        "outputId": "88e67c43-2095-4118-df5b-cbb6270bbc1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Examples in Gradio Blocks layout can be provided using the `gr.Examples` component, which takes two required parameters: `examples` which takes in a nested list, and `inputs` which takes in a component or list of components.\n",
            "SOURCES: https://github.com/gradio-app/gradio/blob/792289cdf77ed0dfaa6592a58b106bd66e743e38/guides/01_getting-started/02_key-features.md\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' Examples in Gradio Blocks layout can be provided using the `gr.Examples` component, which takes two required parameters: `examples` which takes in a nested list, and `inputs` which takes in a component or list of components.\\nSOURCES: https://github.com/gradio-app/gradio/blob/792289cdf77ed0dfaa6592a58b106bd66e743e38/guides/01_getting-started/02_key-features.md'"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = print_answer(\"How to provide examples in Gradio Blocks layout?\")\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNOpJEGVcl3E"
      },
      "outputs": [],
      "source": [
        "def print_answer(question):\n",
        "    response = (\n",
        "        chain(\n",
        "            {\n",
        "                \"input_documents\": search_index.similarity_search(question, k=4),\n",
        "                \"question\": question,\n",
        "            },\n",
        "            return_only_outputs=True,\n",
        "        )[\"output_text\"]\n",
        "    )\n",
        "    #print(response)\n",
        "    if len(r.split('\\n')[-1].split())>2:\n",
        "        response = response.split('\\n')[0] + ', '.join([' <a href=\"' + response.split('\\n')[-1].split()[i] + '\" target=\"_blank\"><u>Click Link' + str(i) + '</u></a>' for i in range(1,len(response.split('\\n')[-1].split()))])\n",
        "    else: \n",
        "        response = response.split('\\n')[0] + ' <a href=\"' + response.split('\\n')[-1].split() + '\" target=\"_blank\"><u>Click Link</u></a>'\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2LwjmcQrBWF"
      },
      "outputs": [],
      "source": [
        "!pip install --q gradio\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "Siw5EyanwSn2",
        "outputId": "fe6fdf7c-7f61-4a00-8224-3452388c0497"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7879, \"/\", \"100%\", 500, false, window.element)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "def chat(message, history):\n",
        "    history = history or []\n",
        "    message = message.lower()\n",
        "    response = print_answer(message) #\"I don't know\"\n",
        "    history.append((message, response))\n",
        "    return history, history\n",
        "\n",
        "chatbot = gr.Chatbot().style(color_map=(\"green\", \"pink\"))\n",
        "#demo = gr.Interface(chat, [\"text\", \"state\"], [chatbot, \"state\"], allow_flagging=\"never\",)\n",
        "with gr.Blocks() as demo:\n",
        "  gr.Markdown(\"\"\"'Yes, it is possible to auto log inputs and outputs using the \"allow_flagging\" parameter. <a href=\"https://github.com/gradio-app/gradio/blob/792289cdf77ed0dfaa6592a58b106bd66e743e38/guides/06_other-tutorials/using-flagging.md,\" target=\"_blank\"><u>Click Link1</u></a>,  <a href=\"https://github.com/gradio-app/gradio/blob/792289cdf77ed0dfaa6592a58b106bd66e743e38/guides/01_getting-started/02_key-features.md\" target=\"_blank\"><u>Click Link2</u></a>'\"\"\")\n",
        "  with gr.Row():\n",
        "    question = gr.Textbox(label = 'Type in your questions about Gradio here', placeholder = 'What is the role of \"every\" argument in a component')\n",
        "    openai_api_key = gr.Textbox()\n",
        "  state = gr.State()\n",
        "  chatbot = gr.Chatbot()\n",
        "  question.submit(chat, [question, state], [chatbot, state])\n",
        "  #button_gradio_bot = gr.Button('Get Help!')\n",
        "  #button_gradio_bot.click(chat, [question, state], [chatbot, state])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6e4ojyZyexU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_K-vHfcyeuU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AD4c56NsyepQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rTjUffMyemd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHjozG6VkC_3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jczyVOPWkC9S"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyPFTJ29UZjNcxgcu+NlM5dD",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}